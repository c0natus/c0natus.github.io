---
title: "BPR: Bayesian Personalized Ranking from Implicit Feedback, (UAI'09)"
categories: [Paper, RecSys]
tags: [BPR]
img_path: /assets/img/posts/paper/recsys/bpr/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Implementation][2]{:target="_blank"}|

# Abstract

MF(Matrix Factorization)나 kNN(adaptive k-nearest-neighbor) 같은 implicit feedback을 위한 item 추천 방법론이 많다.
- 이들은 개인화된 순위의 item 예측을 위해 만들어졌지만, 순위에 직접적으로 최적화되지 않는다.

해당 논문에서는 개인화된 순위에 사용될 <span class="text-color-yellow">범용적인 최적화 기준: BPR-OPT를 제시</span>한다.
- BPR-OPT는 Bayesian 분석에서 도출된 MAP(maximum A posterior estimator)이다.
- 또한, BPR-OPT와 관련해 모델을 최적화하는 학습 알고리즘을 제공한다.


# Ⅰ. Introduction

본 논문에서는 item의 집합에 대한 사용자별 순위를 생성하는 item 추천을 집중적으로 다룬다.
- User의 과거 상호 작용으로 item에 대한 users의 선호도를 학습할 수 있다.

실세계에선 평점을 매기는 explicit feedback보다 자동으로 수집되는 implicit feedback이 대부분이다.   
본 논문에서는 개인화된 순위를 학습하는 모델의 범용적인 방법론을 제시하며, contribution은 다음과 같다.
1. 최적의 개인화된 순위를 위해 MAP로부터 도출된 범용적 최적화 기준인 BPR-OPT를 제시한다. 그리고 AUC(Area Under the ROC Curve)를 최대화하는 것과 BPR-OPT의 유사성을 보여준다.
2. BPR-OPT를 최대화하는 범용적 학습 알고리즘인 LEARN BPR를 제시한다. LEARN BPR은 부트스트랩 샘플링을 이용한 training triples의  SGD 기반으로 만들어졌다.
3. LEARN BPR을 MF, kNN에 적용하고, 다른 학습 방법론보다 뛰어남을 보여준다.

# Ⅱ. Related Work

KNN CF의 유사도 matrix는 Pearson correlation과 같이 heuristics하게 계산되었다. 하지만, 유사성 matrix는 학습 되어야 할 parameter로 여겨진다.   
초기에는 SVD(Singular Value Decomposition)로 feature matrices를 학습했지만, SVD로 학습된 MF는 overfitting되는 경향을 보여줬다.   
이외에도, Case weight와 함께 정규화된 least-square 최적화인 WR-MF, a probabilistic latent semantic 모델, multi-class 문제로 변한 등의 논문도 있다.   
- 앞의 방법론들은 <span class="text-color-yellow">순위를 위해 모델의 parameter를 직접적으로 최적화하지 않는다.</span>
- Item이 선택될 것인지 아닌지를 예측하기 위해 모델의 parameter를 최적화한다.

본 논문에서는 <span class="text-color-yellow">items의 쌍(즉, 두 item의 사용자별 순서)에 기초한 개인화된 순위에 대한 최적화 기준을 도출</span>한다.
- 본 논문은 offline learning에 집중하고 있다.
- Online 학습 시나리오 방법론으로 확장하기 위해, 기존에 연구된 방법론과 같은 전략을 적용할 수 있다.

Non-collaborative 모델을 사용해 순위를 학습하는 것도 있지만, 오직 1개의 순위만 학습하게 되므로 비개인화이다.
- BPR 모델이 전형적인 추천 시스템 환경에서도 비개인화된 순위보다 성능이 좋다.

# Ⅲ. Personalized Ranking

Implicit feedback에서는 오직 관측된 user-item 쌍인 positive feedback만 사용가능하다.
관측되지 user-item 쌍은 negative feedback과 missing  value로 혼합되어 있다.
- Negative feedback이란 user가 item에 흥미가 없다는 것이다.
- Missing value는 user가 item을 미래에 살지도 모르는 것이다.

따라서 이 두가지 경우를 모두 고려하여 모델링 하는 것이 핵심이다.

## ⅰ. Formalization

$U$를 모든 user의 집합, $I$를 모든 item의 집합이라 두자.
- Implicit feedback $s \in S, \ S \subseteq U \times I$로 표현할 수 있다.

본 논문의 목표는 user별 <span class="text-color-yellow">personalized total ranking인 $>_{u} \subset I^{2}$을 구하는 것</span>이다.
- 예를 들어 5개의 item 집합 $I = \{ I_{1}, I_{2}, I_{3}, I_{4}, I_{5} \}$이 있다고 할 때, personalized total ranking이란, user가 선호할 만한 item을 순서대로 예측하는 것이다.
- 만약 $I_4, I_2, I_1, I_3, I_5$ 순대로 선호한다면 $I_4 >_u I_2 >_u I_1>_u I_3 >_u I_5$와 같이 표현 가능하다.
- $I_4 >_u I_1$는 $>_u \subset I^2$의 한 가지 예가 된다. 여기서 $>_u$는 $_5\mathrm{C}_2=10$개 만큼 존재한다.

$>_u$는 다음과 같은 속성을 만족한다.
    
$$
\begin{align*}
\forall i,j \in I &: i \neq j  \Rightarrow i >_{u} j \ \vee \ j >_{u} i \ \ &\text {(totality)} \\ 
\forall i,j \in I &: i >_{u} j \ \wedge \  j >_{u} i \Rightarrow  i = j \ \ &\text {(antisymmetry)} \\ 
\forall i,j \in I &: i >_{u} j \ \wedge \  j >_{u} k \Rightarrow  i >_{u} k \ \ &\text {(transitivity)} 
\end{align*}
\\
$$
    
편의를 위해 다음과 같이 정의한다.
    
$$
\begin{align*}
I_u^+ &:= \{ i \in I : (u,i) \in S \}\\ 
U_i^+ &:= \{ u \in U : (u,i) \in S \}\\ 
\end{align*}
$$
    
- $I_u^+$는 user $u$가 선호하는 item의 집합이다.
- $U_i^+$는 item $i$를 선호하는 user의 집합이다.

## ⅱ. Analysis of the problem setting

Missing value 문제를 해결하는 가장 일반적인 방법은 이들을 모두  negative feedback으로 간주하는 것이다.
- 하지만 그 후 일반적인 ML 모델은 negative feedback과 missing value를 구별할 수 없기 때문에 학습을 할 수가 없게 된다.

Item 추천의 일반적인 접근법은 item에 대한 user의 선호도를 반영하는 개인화된 점수 $\hat{x}_{ui}$를 예측해서 sorting하는 것이다.

![](1.jpg){:w="550"}
_Figure 1: On the left side, the observed data S is shown. Learning directly from S is not feasible as only positive feedback is observed. Usually negative data is generated by filling the matrix with 0 values._

Item 추천에 관한 ML 접근법은 Figure 1과 같이, $(u,i)\in S$를 positive class label로 두고 <span class="text-color-yellow"> $(U\times I) \ \backslash \ S$에 해당하는 모든 combination을 negative class label로 생각</span>해서 training data를 생성한다. 이 같은 training data에 모델을 훈련시키면, 모델은 $S$에 있는 $(u,i)$의 값을 1로 예측하고 나머지는 0으로 예측하도록 최적화된다.
- ‘+’가 관측된 상호 작용, ‘?’가 관측되지 않은 상호 작용이다. ‘+’는 1로, ‘?’는 0으로 mapping되는 것을 확인할 수 있다.

미래에 순위를 평가해야 할 모든 요소 $(U\times I) \ \backslash \ S$가 negative feedback으로 학습 알고리즘에 제시되어, 해당 데이터에 아주 적합한 표현력을 가진 모델은 0만을 예측하기 때문에 <span class="text-color-yellow">순위를 평가할 수 없다.</span>
- 순위를 예측할 수 있는 유일한 이유는 정규화처럼 overfitting을 방지하는 전략이 있기 때문이다.

이를 해결하기 위해 item 쌍을 training data로 사용해, item 하나에 대한 점수를 평가하는 대신 <span class="text-color-yellow">item 쌍의 선호도를 최적화 한다.</span>
- 이것은 missing value를 negative class로 대체하는 것보다 문제에 더 알맞는 접근법이다.
- $S$를 이용해 각 user의 $>_u$ 중 부분을 복원하는 것을 최적화 한다.

이를 위해서는 <span class="text-color-yellow">3가지 가정</span>이 필요하다.
- S1
    - User는 관측된 item을 관측되지 않은 모든 item보다 더 선호한다.
- S2
    - 관측된 item들에 대해서는 선호 강도를 추론할 수 없다. (즉 어떤 item을 더 선호하는지 알 수 없음)
- S3
    - 관측되지 않은 item들에 대해서도 선호강도를 추론할 수 없다. (즉 어떤 item을 더 비선호하는지 알 수 없음)

위의 가정들을 공식화한 training data를 $D_S: U \times I \times I \ \text{matrix}$로 정의한다.
    
$$
\begin {align*}
D_{S} &:= \{(u,i,j) \ | \ i\in I_{u}^{+} \wedge j\in I \setminus I_{u}^{+} \}
\end {align*}
$$
    
- $(u,i,j) \in D_{S}$는 <span class="text-color-yellow">user $u$가 관측되지 않은 item $j$보다 관츤된 item $i$를 선호한다는 의미</span>이다.
- $>_u$는 antisymmetric이기 때문에, negative는 implicitly하게 간주된다.
    - Antisymmetirc relation은 또 다르게 표현할 수 있다.
        
        $\text{if }_aR_b \text{ with } a \neq b \text{ then } _bR_a \text{ must not hold}$
        
    - 즉, $(u,i,j) \in D_s$일 때, $(u,j,i) \notin D_s$이다.
        
        이는 $(u,i,j) \in D_S$가 주어졌을 때,  $j$가 $i$보다 덜 선호된다는 것(negative)을 암묵적으로 이야기 해준다.
        
    

![](2.jpg){: w="450"}
_Figure 2: On the left side, the observed data S is shown. Our approach creates user specific pairwise preferences $i >_U j$ between a pair of items. On the right side, plus (+) indicates that a user prefers item i over item j; minus (–) indicates that he prefers j over i._

예를 들어 $u_1$를 살펴보자.
- Figure 2의 왼쪽 박스로부터 아래를 알 수 있다.
    - $I^+_{u_1} = \{ i_2, i_3 \}$
    - $I \backslash I^+_{u_1} = \{ i_1, i_4 \}$

- 이를 통해 다음과 같은 관계를 알 수 있다.
        
    $$
    \begin {align*}
    i_{2}, i_{3} > j_{1}, j_{4}   &\ \ \ \ \ \ \ \text{by S1} \\ 
    i_{2} \ ? \ j_{3} &\ \ \ \ \ \ \ \text{by S2} \\
    i_{1} \ ? \ j_{4} &\ \ \ \ \ \ \ \text{by S3}
    \end {align*}
    $$
        
    - 위의 관계는 Figure 2의 우측 상단의 matrix와 같고, ‘+’는 $i >_u j$, ‘-’는 $j >_u i$를 의미한다.

이와 같은 접근법은 2가지 이점을 가진다.
- Training data는 positive, negative 쌍과 missin values로 구성된다. 관측되지 않은 두 item 사이의 missing values는 향후 순위가 매겨져야 하는 item 쌍이다.
    - 즉, pairwise point 관점에서 <span class="text-color-yellow">training data $D_S$와 test data가 분리</span>된다.
    - 이는 $D_S$에 존재하는 $(u,i,j)$ 쌍이 향후 순위를 매겨야 하는 item 쌍이 될 수 없기 때문에 test data와 분리된다는 이야기 이다.
- Training data는 실제 목적인 순위를 위해 생성된다.
    - 즉, $>_u$의 $D_S$의 부분 집한인 관측된 $D_S$가 훈련 데이터로 사용된다.

# Ⅳ. BPR(Bayesian Personalized Ranking)

4장에서는 likelihood 함수인 $p(i>_u j\|\Theta)$를 활용한 베이지안 분석으로 도출되는 BPR-OPT와 모델 parameter에 대한 사전 확률을 살펴볼 것이다. 그리고 AUC와의 유사성, LEARN BPR 알고리즘, 마지막으로 BPR-OPT와 LEARN BPR을 MF, adaptive kNN 모델에 적용해 볼 것이다.

## ⅰ. BPR Optimization Criterion


$\Theta$ 같은 임이의 모델의 parameter vector를 나타낼 때, 아래와 같은 사후 확률을 최대화 하는 것이 개인화된 순위를 찾는 Bayesian 공식이다.
    
$$
\begin {align*}
& p(\Theta | >_{u})  \propto p(>_{u} | \Theta) \ p(\Theta) \\
\\
\because \ \ p(\Theta | >_{u}) & = \frac{p(\Theta , >_{u})}{ p(>_{u})} = \frac{p(>_{u} | \Theta) p(\Theta)}{ p(>_{u})}  \propto  p(>_{u} | \Theta) \ p(\Theta)
\end {align*}
\\
$$
    
- ‘사후 확률’이란 ‘어떤 정보’가 고려된 parameter에 대한 확률이다. 여기서 어떤 정보는 user의 선호 정보($>_u$)이다.
- 이에 대비되는 개념인 ‘사전 확률’은 위 식의 $p(\Theta)$로, 파라미터에 대한 사전 정보다. 사전 확률은 주어진 정보이므로, 사후확률과 달리 오직 파라미터에만 의존한다.
- MAP의 목표는 $>_u$ 정보가 주어졌을 때, 이를 최대한 잘 나타낼 수 있는 parameter를 추정하는 것이다. 사후 확률은 베이즈 정리에 의해 likelihood와 사전 확률의 곱으로 나타낼 수 있다.

Likelihood와 사전 확률을 자세히 살펴보기 전 <span class="text-color-yellow">2가지 가정</span>을 하고 가자.
1. 모든 user는 서로 독립적으로 행동한다.
2. User 별 items $(i,j)$ 쌍은 다른 모든 쌍의 순서와 독립적이다.

## ⅱ. Likelihood

Likelihood란 확률 분포의 parameter가, 어떤 확률변수의 표집값과 일관되는 정도를 나타내는 값이다. 즉, model의 parameter인 $\Theta$가 주어졌을 때, 수집된 data인 $>_u$가 해당 확률 분포에 존재할 가능성을 나타내는 값이다. Likelihood 함수는 확률 분포가 아니고, 합하여 1이 되지 않을 수 있다.

$>_u$는 $(u,i,j) \in D_S$의 집합으로 정의되기 때문에 $p(>_u)$는 $i >_u j$와 $j >_u i$ 두 가지 경우만 존재한다. 이는 베르누이 분포를 따른다고 볼 수 있다.
위에서 모든 user가 서로 독립이고, $(i,j)$도 서로 독립이므로, $p(>_u)$는 iid(independent and identically distriuted)를 만족한다. 이를 아래와 같이 표현할 수 있다.
    
$$
\begin{align*}
>_{u} \ := (u,i,j) \in D_S  \ \  &\Rightarrow \delta((u,i,j) \in D_{S}) \stackrel{iid}{\sim} Bern(p(i >_{u} j)) \\ 
\\
where, \ \ \ \delta(b) &:= 
\begin{cases}
1 & \text{if }b \text{ is true}\\
0 & \text{else}
\end{cases}
\end{align*}
$$
    
모든 user에 대한 likelihood function은 다음과 같다.
    
$$
\begin{align*}
\prod_{u \in U} p(>_{u}|\Theta)
&= \prod_{(u,i,j) \  \in\  U\times I \times I} p(i >_{u} j|\Theta)^{\delta((u,i,j) \in D_{S})} (1-p(i >_{u} j|\Theta))^{\delta((u,j,i) \notin D_S)}\\
&= \prod_{(u,i,j) \  \in\  D_S} p(i >_{u} j|\Theta) \ \ \ \ \ \ \ \ \ \because \text{totality and antisymmetry}
\end{align*}
\\
$$

$x\sim Bern(p) = p^x(1-p)^{1-x}$이다. 위의 식에서  $p, x, 1-x$에 해당하는 것은 다음과 같다.
- $p = p(i>_u j\|\Theta)$
- $x = \delta((u,i,j) \in D_{S})$
- $1-x = 1-\delta((u,i,j) \in D_{S}) = \delta((u,j,i) \notin D_{S})$

    > 의문점   
    > $\delta((u,j,i) \notin D_{S})$가 아니고 $\delta((u,i,j) \notin D_{S})$가 아닌가??   
    > $1-\delta((u,i,j) \in D_{S})$가   
    >   - $i=j$   
    >   - $i,j$ 둘다 관측   
    >   - $i,j$ 둘다 비관측   
    >   - $j$관측, $i$비관측   
    >   
    > 인 것을 의미하니 $\delta((u,i,j) \notin D_{S})$인 것 같다. 일단 이걸로 생각해야겠다.   
    > Figure 2를 보며 직접 계산해보면, ‘+’는 $p(i >_u j \| \Theta)(1-p(i >_u j \| \Theta))$로 계산되고??????, ‘-’는 무시되고, ‘?’는 $1-p(i >_u j|\Theta)$로 계산된다.

- Sound pair-wise 순서 구조를 가졌다면 $>_u$는 totality와 antisymmetry 성질을 가지므로 아래와 같이 간단하게 표현할 수 있다.

    $$\prod_{(u,i,j) \in D_S} p(i >_u j \| \Theta)$$

    > 의문점   
    > Totality의 또 다른 정의는  모든 item 쌍 $(i,j)$에 대해, $(u,i,j) \in D_s$이거나 $(u,j,i) \in D_s$ 또는 $i=j$인 것을 의미한다.   
    > 이는 Figure 2에서 ‘?’로 표시 되었어도  $i \neq j$이면 $(u,i,j) \in D_s$이거나 $(u,j,i) \in D_s$라는 뜻이다.   
    > Antisymmetry로 $(u,i,j) \in Ds$이고 $i \neq j$이면, $(u,j,i) \notin D_s$이다.  즉, $(u,i,j) \in Ds$이고, $(u,j,i) \in D_s$일 수 없다는 것이다.   
    > $i=j$일 때, $\delta((u,i,j) \notin D_{S})$가 참이므로 $1-p(i >_u j \| \Theta)$을 계산해야 한다. $i=j$이면 $p(i >_u j \| \Theta)$는 0이므로 최종 결과 값은 1이 된다.  $0^0=1$인가...?    
    > 실제로 관측된 $i$와 비관측된 $j$에 대해서도 $i=j$와 유사하게 최종 결과값이 1이 된다. $0^0=1$로 생각한다면... 

개인화된 순서를 보장하기 위해선 위에서 언급한 $>_u$의 속성 3가지(totality, antisymmetry, transitivity)를 만족시켜야 한다. 이를 위해 사용자가 item $j$보다 $i$를 선호하는 개별 확률을 다음과 같이 정의한다.
    
$$
\begin{align*}
p(i >_{u} j) := \sigma(\hat{x}_{uij}(\Theta))  ,\ \ \ 
\sigma(x) := \frac{1}{1+e^{-x}}
\end{align*}
\\
$$
    
$\hat{x}_{uij}(\Theta)$는 user $u$와 item $i,j$ 사이의 관계를 표현하는 모델의 parameter가 $\Theta$일 때, 모델이 출력하는 값이다.
- MF나 adaptive kNN을 이용해 추정하는 값이  $\hat{x}_{uij}(\Theta)$이다.
- 편의를 위해 $\Theta$를 생략하고 표기를 하겠다.

## ⅲ. Prior Probability


MAP를 최대화할 때 likelihood function과 함께 사전 확률도 필요하다. 특별한 사전 정보가 없다면 사전 확률변수의 확률 분포는 uniform이거나 noraml이다. 본 논문에서는 <span class="text-color-yellow">평균이 0이고, variance-covariance matrix $\sum_{\Theta}$인 정규분포</span>를 사용한다.
    
$$
p(\Theta) \sim N(0, \Sigma_{\Theta})
$$
    
BPR-OPT에서는 알려지지 않은 hyperparameters의 수를 줄이기 위해 $\Sigma_{\Theta} = \lambda_{\Theta}I$로 설정한다.

$$
\begin{align*}
p(\Theta) \sim N(0, \Sigma_{\Theta}) &= \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} exp(-\frac{1}{2}(\Theta-0)^{T} \Sigma^{-1}(\Theta-0)) \\
\\
&  \propto  exp(-\frac{1}{2}\Theta^{T} (\frac{1}{\lambda_{\Theta}}I) \Theta) \\
&= exp(-\frac{1}{2\lambda_{\Theta} }\Theta^{T}\Theta)  \simeq exp(- \lambda_{\Theta} \lVert \Theta \rVert^{2} ) 
\\
\end{align*}
$$

##  ⅳ. BPR-OPT

Likelihood와 사전 확률을 정의햇으므로, 이제 MAP를 최대화 하는 $\Theta$를 구해보자.

$$
\begin{align*}

\text{BPR-OPT} :&= \text{ln }p(\Theta|>_u)\\
&= \text{ln }p(>_u|\Theta)p(\Theta)\\
&= \text{ln }\prod\limits_{(u,i,j) \  \in\  D_S} \sigma(\hat{x}_{uij})p(\Theta)\\
&= \sum\limits_{(u,i,j) \  \in\  D_S} \text{ln }\sigma(\hat{x}_{uij})+\text{ln }p(\Theta)\\
&= \sum\limits_{(u,i,j) \  \in\  D_S} \text{ln }\sigma(\hat{x}_{uij})+\lambda_{\Theta}||\Theta||^2\\
\end{align*}
\\
\text{where } \lambda_{\Theta} \text{ are model specific regularization parameters}
$$

## ⅴ. Analogies to AUC optimization

BPR 구조를 보면 AUC와의 유사성을 쉽게 찾을 수 있다. 개인 user 별 AUC는 보통 아래와 같이 정의된다.
    
$$
\begin{align*}
\text{AUC}(u) &:= \frac{1}{|I^+_u| |I \backslash I^+_u|}\sum\limits_{i\in I^+_u}\sum\limits_{j\in|I\backslash I^+_u|}\delta(\hat{x}_{uij} > 0)\\
\text{average AUC} &:= \frac{1}{|U|}\sum\limits_{u\in U}\text{AUC}(u)
\end{align*}
$$
    
위의 식을 $D_s$로 표현하면 다음과 같다.
    
$$
\begin{align}
\text{AUC}(u)=\sum\limits_{(u,i,j))\in D_S}z_u\delta(\hat{x}_{uij} > 0)
\end{align}
$$
    
- $z_u$는 정규화 상수로 $z_u = \frac{1}{\| U \| \| I^+_u \| \|I \backslash I^+_u \|}$이다.

![](3.jpg){:w="550"}
_Figure 3: Loss functions for optimizing the AUC. The non-differentiable Heaviside $H(x)$ is often approximated by the sigmoid $\sigma(x)$. Our MLE derivation suggests to use ln $\sigma(x)$ instead._

식 (1)과 BPR-OPT의 유사성은 명확하다. 차이점은 2가지인데 바로 정규화 상수 $z_u$와 loss function로 사용될 때이다.
- AUC는 non-differentiable loss인 $\delta(x>0)$을 사용한다. 이는 Heaviside function과 동일하다.
        
    $$
    \delta(x>0) = H(x) := \begin{cases}
    1 & x>0\\
    0 & \text{else}
    \end{cases}
    $$
        
  - BPR-OPT에서는 differentiable loss인 ln $\sigma(x)$을 사용한다.

AUC 용으로 최적화할 때 미분 불가능한 Heaviside function를 교체하는 것이 일반적이다. 종종 치환의 선택은 휴리스틱이며 $\sigma$와 같은 모양의 함수가 사용된다.   
본 논문에서는 MLE에로 유도되는 alternative substitution ln $\sigma(x)$를 도출했다.

## ⅵ. BPR Learning Algorithm

보편적인 방법으로 위에서 정의한 criterion을 gradient descent로 최적화 하는 것은 개인적인 순위를 결정하는 문제에 적합하지 않다.
- <span class="text-color-yellow">Training triples의 bootstrap smapling에 기반한 SGD 알고리즘인 LEARN BPR을 제안</span>한다.
    - 현재는 컴퓨터 성능이 좋기 때문에 데이터를 버리는 bootstap smapling은 좋은 방법이 아닌 것 같다.

![](4.jpg){:w="550"}
_Figure 4: Optimizing models for BPR with bootstrapping based stochastic gradient descent. With learning rate $\alpha$ and regularization $\lambda$._

먼저 모델 parameters $\Theta$에 관해 BPR-OPT의 gradient와 gradient descent 방법론은 다음과 같다.
    
$$
\begin{align*}
\frac{\partial\text{BPR-OPT}}{\partial\Theta} &= \sum\limits_{(u,i,j)\in D_S}\frac{\partial}{\partial\Theta}\text{ln }\sigma(\hat{x}_{uij})-\lambda_{\Theta}\frac{\partial}{\partial\Theta}||\Theta||^2 \\
&\propto \sum\limits_{(u,i,j)\in D_S} \frac{-e^{-\hat{x}_{uij}}}{1+e^{-\hat{x}_{uij}}}\cdot\frac{\partial}{\partial\Theta}\hat{x}_{uij}-\lambda_{\Theta}\Theta &\text{(gradient)}
\\
\\
\Theta &\leftarrow \Theta - \alpha\frac{\partial\text{BPR-OPT}}{\partial\Theta} &\text{(gradient descent)}

\end{align*}
$$
    
Gradient descent를 위한 일반적인 알고리즘으로 full or stochastic gradient descent가 있다.   
Full gradient descent는 다음과 같은 단점이 있다.   
- 일반적으로 full gradient descent는 올바른 방향으로 가지만 $D_S$에 있는 training triples의 개수는 $O(\|S\|\|I\|)$이므로 <span class="text-color-yellow">수렴 속도가 느리다.</span>
- Training pairs의 skewness는 <span class="text-color-yellow">수렴 결과를 안 좋게 한다.</span>
    - Item $i$가 대부분의 users에게 positive로 판단된다고 해보자. 그러면 많은 user들이 모든 items $j_k$(지배 class)와 item $i$를 비교하기 때문에 $\hat{x}_{xij_k}$ 항이 많아진다. 그 결과  item $i$에 의존하는 모델 parpameter의 gradient가 gradient를 지배한다. 이는 매우 작은 learning rate $\alpha$를 선택해야 된다는 것을 의미한다.
- Gradients가 매우 달라지기 때문에 <span class="text-color-yellow">정규화가 어려워진다.</span>

따라서 본 논문에서는  stochastic gradient descent 방법을사용하는데, 이는 skew 문제를 해소하기에 좋은 접근법이다. 하지만, training pairs가 통과하는 순서는 매우 중요해진다.
- 데이터를 item 별로 또는 user 별로 탐색하는 일반적인 접근 방식은 동일한 user-item 쌍에 대해 연속적으로 업데이트가 너무 많기 때문에 수렴 결과가 좋지 않다. 즉, 하나의 user-item 쌍 $(u,i)$ 에 많은 $j \text{ with } (u,i,j) \in D_S$가 있다.

이 문제를 해결하기 위해 균등 분포를 따르도록 무작위로 triples를 선택하는 SGD 알고리즘을 제안한다. 이 방법에서는 연속적인 업데이트에서 동일한 user-item 조합을 선택할 수 있는 확률을 낮춘다.   
무작위로 선택하는 것 대신 <span class="text-color-yellow">어느 단계에서나 정지를 할 수 있는 bootstrap sampling 접근법을 대안으로 제안한다.</span>
- $(u,i,j) \in D_S$의 데이터에 대해선 full cycle을 포기하는 것이 특히 유용하다. 왜냐하면, data 수가 너무 많아 full cycle 중 일부만으로도 충분하기 때문이다.
- 관찰된 positive feedbask S의 수에 따라 평가의 single step 수를 선형적으로 선택한다.
    

![](5.jpg){:w="550"}
_Figure 5: Empirical comparison of the convergence of typical user-wise stochastic gradient descent to our LearnBPR algorithm with bootstrap sampling._

## ⅶ. Learning models with BPR

논문에서는 MF와 adaptive kNN 모델에 BPR을 적용하였다. 정리는 MF에 대해서만 하겠다.   
MF는 user-item 쌍 $(u,l)$ 마다 실수 값 $\hat{x}_{ul}$을 예측해 숨겨진 선호도를 찾는다.   

BPR은 triples $(u,i,j) \in D_S$를 가지기 때문에 $\hat{x}_{uij}$를 구성해야 한다. 정의는 다음과 같다.   
    
$$
\hat{x}_{uij} = \hat{x}_{ui} - \hat{x}_{uj}
$$
    
- 이는 MF뿐만 아니라 $\hat{x}_{ul}$을 예측하는 다른 CF 모델에도 BPR을 적용할 수 있게 한다.

다른 문제에 같은 모델을 사용하더라도 다른 criterion으로 최적화 한다는 점이 중요하다.
- 이는 ranking task에 대해서 BPR을 적용하고 그것이 잘 동작하는 이유이다.
- BPR criterion은 $\hat{x}_{ul}$을 예측하는 회귀하는 것이 아니라 두 예측의 차이를 분류하기 때문이다.

## ⅷ. MF

$\hat{x}_{ui}$를 예측하는 것은 matrix $X: U\times I$를 추정하는 것으로 볼 수 있다.
    
$$
\hat{X} := WH^T
$$
    
- $M$은 두 개의 low-rank matrices $W:= \|U\| \times k \text{ and } H:= \|I\| \times k$의 곱에 근사하게 된다.

MF의 모델 paramether $\Theta$는 $(W,H)$이다.
- 모델 parameter는 user의 관찰되지 않은 취향과 항목의 관찰되지 않은 item의 속성을 모델링하는 latent 변수로도 볼 수 있다.

일반적으로 least-square를 이용해 $\hat{X}$를 근사시키기 위해 SVD를 사용했다.
- ML 문제에서 SVD는 overfitting을 야기한다고 알려져 있다.
- 그래서 MF 모델에 관해 regularized least square optimization, non-negative factorization, maximum margin factorization 같은 방법론들이 제시되었다.

예측이 아닌 순위 문제에서는 BPR-OPT를 이용해 최적화 하는 것이 더 나은 접근법이다.   
LearnBPR로 모델 parameter $\theta$를 최적화할 때 $\hat{x}_{uij}$의 gradient를 알아야 한다.
    
$$
\frac{\partial}{\partial\theta}\hat{x}_{uij} = \begin{cases}
h_{if}-h_{jf} & \text{ if } \theta = w_{uf},\\
w_{uf} & \text{ if } \theta = h_{if}, \\
-w_{uf} & \text{ if } \theta = h_{jf}, \\
0 & \text{ else} \\ 
\end{cases}
$$
    
그리고 3개의 정규화 상수를 이용한다.
    
$$
\begin{align*}
\lambda_{W} &: \text{ for user feature } W \\
\lambda_{H^+} &: \text{ for positive updates on } h_{if} \\
\lambda_{H^-} &: \text{ for negative updates on } h_{jf}\\
\end{align*}
$$
    

# References

1. [https://leehyejin91.github.io/post-bpr/][3]{:target="_blank"}
2. [Antisymmetric relation][4]{:target="_blank"}
3. [Connected relation][5]{:target="_blank"}
4. [What is Bootstrap Sampling in Statistics and Machine Learning?][6]{:target="_blank"}
5. [What is the variance-covariance matrix?][7]{:target="_blank"}

[1]: https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf
[2]: https://github.com/c0natus/Paper-review-implements/tree/main/RecSys/BPR
[3]: https://leehyejin91.github.io/post-bpr/
[4]: https://en.wikipedia.org/wiki/Antisymmetric_relation
[5]: https://en.wikipedia.org/wiki/Connected_relation
[6]: https://www.analyticsvidhya.com/blog/2020/02/what-is-bootstrap-sampling-in-statistics-and-machine-learning/
[7]: https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/anova/supporting-topics/anova-statistics/what-is-the-variance-covariance-matrix/