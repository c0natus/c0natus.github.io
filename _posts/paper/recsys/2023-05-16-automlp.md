---
title: "AutoMLP: Automated MLP for Sequential Recommendations, (WWW'23)"
categories: [Paper, RecSys]
tags: [Sequential Recommendations, MLP, AutoML]
img_path: /assets/img/posts/paper/recsys/automlp/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|

## Abstract

Challenges
: 1. User의 long/short-term interests는 다음 item을 추천하는데 heterogeneous하기 때문에 구분해야 한다.
2. 기존의 방법에서는 short-term interest length를 heuristic하게 선택했다.
3. Transformer는 input 길이에 quadratic한 complexity를 가진다.

Address
: 1. Short-term을 automated and adaptive하게 search한다. ([DARTS][2]{:target="_blank"})
2. MLP만 사용해 성능은 유지한 채, linear한 complexity를 가지게 한다.

## Ⅰ. Introduction

Sequential recommendation은 sequntial information을 활용하기 때문에 static model보다 일반적으로 성능이 좋다.
Sequential recommendation에 필요한 information으로는 3가지가 있다.

1. Long-term user sequential dependency
: 상대적으로 static한 user의 interest에 대한 information. 
2. Short-term user sequential dependency
: User의 최근 interest에 대한 information.
3. Item feature
: User의 short-term interest를 파악하는데 중요.

![](1.png)
_Figure 1: Illustrative examples of users’ long/short-term interests. The target items of user 1 and 2 are related to their long- and short-term interests respectively, and user 3 is influenced by both._

User의 행동은 위의 그림과 같이 long/short-term interest 둘 다에 영향을 받는다.
그러나 기존 방법 대부분은 long-term을 잘 파악하지만, 상대적으로 dynamic한 short-term을 자세히 다루는 것은 별로 없다.

기존 방법의 한계점은 아래와 같다.
- RNN-related 방법들은 short-term dependency를 잘 파악한다.
하지만, RNN은 long sequences에 취약하다고 알려져 있다.
- Transformer는 큰 margin으로 성능을 높혔다.
하지만, self-attention은 input sequence를 고려하지 않기 때문에 sequential information을 얻기 위해선 positional embedding에 의존해야 한다.
때때로 positional embedding은 성능을 떨어뜨린다.
또한, computational complexity가 input sequence에 quadratic하다.
- Short-term sequence length를 empirical하게 고정된 값으로 선택한다.
서로 다른 추천 task나 scenarios에서 optimal short-term length는 달라지기 때문에 부족한 면이 있다.

이러한 한계점을 보완하기 위해 **Auto**mated Long-term Short-term **M**ulti-**L**ayer **P**erceptron for sequential recommendation (**AutoMLP**)를 제안한다.
- 오직 MLP blocks만 사용해 input sequences의 길이에 linear한 time, space complexity를 가진다.
- Long/short-term dependencies를 파악하기 위해 long/short-term interest module을 고안했다.
- Short-term session 학습하기 위해 DARTS의 방법론을 활용한다.  
→ Model generality를 강화한다.

## Ⅱ. Framework

AutoMLP는 user의 short-term interest length를 adaptive하게 선택한다.
그리고 long/short-term interests를 효율적으로 파악하기 위해 MLP block을 사용한다.

### ⅰ. Problem Formulation

User set $U$의 각 user $u$마다 interaction sequence $S_u$를 가진다.
- $S_u = $ { $i_1, \dots, i_t, \dots, i_T $ }

Sequential recommendation의 objective는 $S_u$가 주어졌을 때, 다음 item $i_{T+1}$을 추천하는 함수 $f$를 찾는 것이다.

### ⅱ. Framework Overview

![](2.png)
_Figure 2: Framework overview of AutoMLP._

AutoMLP는 MLP로만 이뤄진 long/short-term module로 이뤄져 있다.
그리고 서로 다른 추천 session마다, 각각의 short-term user interest length를 학습한다.
Length $k$는 DARTS 알고리즘으로 결정된다.

먼저 해당 논문은 [MLP-Mixer][3]{:target="_blank"}와 [DARTS][2]{:target="_blank"}을 적절히 활용한 것이다.
그래서 MLP-Mixer와 DARTS를 간단히 살펴보자.

> 논문에 안 나와있지만, 고정된 길이 $T$를 사용하기 위해 SASRec처럼 길이가 길면 짜르고 짧으면 'padding' embedding을 추가해주는 것 같다.

### ⅲ. MLP-Mixer (NeurIPS'21) 

![](3.png)
_Figure 3: MLP-Mixer consists of per-patch linear embeddings, Mixer layers, and a classifier head. Mixer layers contain one token-mixing MLP and one channel-mixing MLP, each consisting of two fully-connected layers and a GELU nonlinearity. Other components include: skip-connections, dropout, and layer norm on the channels._

해당 논문은 convolutions과 attention이 좋은 성능은 내지만, 필수는 아니라는 것을 보여준다.
MLP-Mixer는 2가지 type의 layer로 이뤄져있다.
이 두 가지 유형의 layer는 입력 차원 둘다(row, column)의 상호 작용을 활성화하기 위해 인터리브된다.

> 인터리브는 성능을 높이기 위해 데이터가 서로 인접하지 않도록 배열하는 방법이다.

- Token-mixing MLPs(왼쪽 부분)
: Image patches에 걸쳐 적용되는 MLPs("mixing" spatial information)  
- Channel-mixing MLPs(오른쪽 부분)
: Image patches에 독립적으로 적용되는 MLPs ("mixing" the per-location feature channels)  

ViT 처럼 image를 patch로 나눈 뒤, linear projection을 통해 $\text{patches} \times \text{channels}$ table로 만든다.
Mixer는 해당 table를 input으로 받고, channel-mixing MLPs와 token-mixin MLPs에 태운다.

Modern deep vision 구조는 주어진 spatial location에서 feature를 섞거나 (1), 서로다른 spatial locations 간의 features를 섞는 것 (2)이다.
CNNs에서 $1 \times 1$ convolution은 (1)과 같은 역할을 하고, $N \times N$ convolution, pooling은 (2)와 같은 역할을 한다.
그리고 더 큰 kernels은 (1), (2) 역할을 모두 수행한다.
ViT나 다른 attention-based 구조에서 self-attention layer는 (1), (2) 역할을 모두 수행 한다.
Mixer의 idea는 (1)과 (2)의 역할을 channel-mixing: per-location operations과 token-mixing: cross-location operations으로 구분하는 것이다.

같은 channel-mixing MLP (token-mixing MLP)는 $\textbf{X}$의 각 row(column)에 적용된다.
서로 다른 MLP를 적용하는 것과 크게 차이가 없다고 한다.

Token-mixing MLPs가 input position에 민감하므로 positional encoding이 불필요하다.

자세한 것은 논문을 참고하자.

### ⅳ. DARTS (ICLR'19)

![](4.png)
_Figure 4: An overview of DARTS: (a) Operations on the edges are initially unknown. (b) Continuous relaxation of the search space by placing a mixture of candidate operations on each edge. (c) Joint optimization of the mixing probabilities and the network weights by solving a bilevel optimization problem. (d) Inducing the final architecture from the learned mixing probabilities._

DARTS는 NAS(Neural Architecture Search) algorithm 중 하나로, discrete한 search space에 continuous relaxation (softmax)를 적용해 continuous하게 만들었다.

$$
\bar{O}^{(i,j)}(x) = \sum_{o \in \mathcal{O}} 
  \frac{\text{exp}(\alpha_o^{(i,j)})}
    {\sum_{o^\prime \in \mathcal{O}}\text{exp}(\alpha_{o^\prime}^{(i,j)})}
  O(x)
$$

$\mathcal{O}$는 operation set을 의미하고, $x$는 representation을 의미한다.
위의 수식은 각 operation 마다 학습 가능한 weight $\alpha$를 두어 operation 결과를 mixing하여 representation $i$에서 $j$를 구하는 것을 뜻한다.
그래서 마지막엔, 가장 weight가 높은 operation만 남겨두고 model을 재학습 시킨다. (Discretization step)

자세한 것은 논문을 참고하자.

### ⅴ. Detailed Architecture

**Embedding Layer.**
Sequential 추천 시스템에서 자주 사용되는 전략을 사용한다.
Lookup table로 item ID와 features를 embedding으로 바꾼다.
그리고 FC layer를 통해 하나의 embedding vector $\textbf{x}_t = [x_t^1, \dots, x_t^D] $로 만든다.
$T$ length의 user interaction sequence를 가지는 한 user에 대해 $T \times D$ 크기의 embedding table을 얻는다.

**Long-term Interest Module.**
User의 전체 interaction sequence를 입력으로 받고 prediction을 위한 hidden representation으로 interest를 encode한다.
Encoding process는 MLP layer, *i.e.* SRSMLP layer로 수행된다.

![](5.png)
_Figure 5: Architecture of Sequential Recommender System MLP Layer (SRSMLP Layer)._

SRSMLP layer는 fig. 5와 같이 sequence-mixer와 channel-mixer라 불리는 2개의 MLP blocks로 이뤄져 있다.
Sequence-mixer는 user interaction sequence에서 sequential correlations을 학습한다.
그리고 channel-mixer는 각 item embedding 마다 cross-channel correlations을 학습한다.

**Long-term Interest Module: Sequence-mixer.**

![](6.png){: w="500"}
_Figure 6: Sequence mixer. Channel mixer has a similar architecture, except for the input $x^d$ and output $\hat{x}^d$._

Layer $l$에서 input $x^d \in \mathbb{R}^T$을 아래의 식을 통해 output $\hat{x}^d$를 만든다.

$$
\hat{x}^d = x^d + W^2g^l(W^1\text{LayerNorm}(x^d)), ^\forall d \in [1, D]
$$

- $W^1 \in \mathbb{R}^{R_s\times T}, W^2 \in \mathbb{R}^{T\times R_s}$
  - $R_s$는 sequence-mixer의 tunable hidden size이다.
- $g^l$: non-linear activation function at layer $l$

이를 통해 sequence 내의 cross-item (sequential) information을 각 item의 embedding vector에 융항(fusing)한다.
즉, sequence 전체에서 user의 long-term interest evolution으로 알려진 sequential correlation을 학습할 수 있다.
MLP-mixer와 마찬가지로 layer normalization과 residual connection을 사용한다.

**Long-term Interest Module: Channel-mixer.**
Channel-mixer는 input과 output의 dimension을 제외하곤 fig. 4의 sequence mixer와 같은 구조를 가진다.
Sequence-mixer와 주된 차이점은 channel-mixer는 각 item embedding vector 내에서 correlation을 학습하는 것이다.
Embedding vector의 각 dimension은 보통 서로 다른 semantics를 표현하기 때문에,
그들의 representation을 집단적으로(collectively) 학습하는 것은 정보에 입각한 prediction을 하는 데 필수이다.
또한, channel-mixer는 sequence-mixer 이후 개별 embedding dimension에 있는 sequential information을 전달할 수 있다.
그래서 일관되게 (coherently) sequential information의 hidden representation을 학습한다.

Input $x^t \in \mathbb{R}^D$, output $\hat{x}^t \in \mathbb{R}^D$ dimension은 embedding vector의 size $D$와 같다.

$$
\hat{x}^t = x^t + W^4g^l(W^3\text{LayerNorm}(x^t)), ^\forall t \in [1, T]
$$

- $W^3 \in \mathbb{R}^{R_c\times D}, W^4 \in \mathbb{R}^{D \times R_c}$
  - $R_c$는 channel-mixer의 tunable hidden size이다.
- $g^l$: non-linear activation function at layer $l$

**Short-term Interest Module.**
Long-term interest module과 주요 차이점은 자동으로 optimal short-term interest length $k$를 찾는 부분이다.
그 외에 sequence-mixer과 channel-mixer를 포함하는 등 long-term interest module과 같다.

![](7.png)
_Figure 7: Short-term session length search process. K is the set of candidate lengths, represented by the highlight part._

> 따로 weight 추가한다는 말이 없으니 long-term module에서 사용하느 SRSMLP layer의 weight를 global하게 사용하는 것 같다.  
> 그리고 사용되지 않는 것은 'padding' embedding? 처럼 따로 처리하는 것 같다.

**Short-term Interest Module: Session Length Search.**
해당 부분은 DARTS를 사용했다.
먼저, fig. 7처럼 short-term length로 가능한 후보 $K = $ { $k_1, \dots, k_m, \dots, k_M$ }를 정의하고, M개의 SRSMLPs로 output embeddings를 얻는다.
그리고 학습 가능한 architecural weights $\textbf{A} = $ { $\alpha_1, \dots, \alpha_m, \dots, \alpha_M $ }을 각 outputs에 할당한다.
그 다음, softmax를 통해 continuous하고 미분 가능한 approximations를 얻는다.

> 후보 $K$는 어떻게 정하게 되는지 안 나와있다...

$$
p_m = \frac{\text{exp}(\alpha_m)}{\sum_{j=1}^M\text{exp}(\alpha_j)}
$$

$p_m$을 통해 short-term sequence length를 결정한다.
이를 통해 모든 length마다 model을 학습하지 않고, 효율적으로 local optimal user short-term interest length를 찾을 수 있다.

**Output Layer**
long-term interest module과 optimal short-term interest module에서 outputs $x_T^l, x_T^s$를 얻을 수 있다.
이들의 joint representation을 위해 FC layer를 사용한다.

$$
h_T = W^o\text{LayerNorm}(x_T^s; x_T^l) + b^o
$$

- $x_T^s, x_T^l$는 time step $T$에서의 short/long-term interest module의 output이다.
- $W^o \in \mathbb{R}^{D \times 2D}, b^o \in \mathbb{}R^D$는 학습 가능한 parameter이다.

$h_T$가 inference 시 다음 item을 예측할 때 사용된다.

### ⅵ. Training and Inference

대부분의 sequential recommendation처럼 Cross-Entropy loss function을 사용한다.

$$
\mathcal{L} = -\sum_{S_u \in S}\sum_{t\in[1,\dots,T]}[\text{log}(\sigma(r_{i_t,t})) + \sum_{j \notin S_n}\text{log}(1-\sigma(r_{i_j,t}))]
$$

- $S$: 모든 user의 interaction sequences를 포함한 superset.
- $r_{i_t, t}$: time $t$에서 ground-truth item $i_t$에 대해 model이 예측한 similarity.
- $r_{i_j, t}$: time $t$에서 negative sample item $i_j$에 대해 model이 예측한 similarity.

**Training.**
Training process는 2가지 phases를 포함한다.
첫 번째는 local optimal short-term length $\textbf{A}^*$를 찾는 search phase이다.
두 번째는 optimal short-term length로 AutoMLP를 retrain인 하는 것이다.

**Training: Search Phase.**
Architectural weights $\textbf{A}$와 AutoMLP의 $\textbf{W}$를 jointly 학습해야 한다.
Training process에서 $\textbf{W}$와 $\textbf{A}$는 서로 많이 dependent하기 때문에 함께 업데이트 하면 overfitting이 발생한다.
따라서 training dataset 으로 $\textbf{W}$를 최적화하고, validation dataset으로 $\textbf{A}$를 최적화 한다.
즉, DARTS와 같이 bilevel optimization을 한다.

$$
\begin{split}
&\underset{\textbf{A}}{\text{min }}\mathcal{L}_{val}(\textbf{W}^*(\textbf{A}), \textbf{A})\\
&s.t. \textbf{W}^*(\textbf{A}) = \underset{\textbf{W}}{\text{argmin }}\mathcal{L}_{train}(\textbf{W}, \textbf{A})
\end{split}
$$

그리고 $\textbf{W}^*$을 찾기 위해 수렴할 때까지 훈련을 해야 하므로 시간이 많이 걸린다.
그래서 DARTS와 같이 one-step approximation을 적용한다.

$$
\textbf{W}^*(\textbf{A}) \approx \textbf{W} - \xi\nabla_{\textbf{W}}\mathcal{L}_{train}(\textbf{W}, \textbf{A})
$$

- $\xi$: learning rate

자세한 알고리즘은 DARTS를 참고하자.
전체적인 flow는 아래와 같다.

![](8.png)
_Algorithm 1: Optimization for AutoMLP in Search Phase_

**Training: Retraining Phase**
Search stage에서 찾은 optimal을 제외한 다른 sequence는 model 성능에 안 좋은 영향을 끼치므로 optimal short-term sequence만 사용해 모델을 retrain한다.

> 직접 실험을 해봤을까? 오직 optimal한 것만 사용하는 게 DARTS의 단점이고, 이를 보완하는 논문이 있다고 [블로그][4]{:target="_blank"}에서 말하고 있는데...

잘 학습된 $\textbf{A}^*$에서 가장 높은 $\alpha_m$을 선택하고 나머지는 사용하지 않는다.
그리고 AutoMLP를 training set으로 retrain하여 최적의 $\textbf{W}$를 찾는다.

<!-- > Short-term length가 모든 session마다 동일하게 선택되는 것 같다. Session마다 다르게 선택되도록 하는 방법을 왜 안 하지?
{: .prompt-tip } -->

**Inference**
Sequential 추천 시스템에서 많이 사용되는, model의 ouput $h_T$와 모든 후보 items 간의 cosine similiarty를 통해 inference한다.

$$
p_i = \text{softmax }(h_T \cdot E_i^T) 
$$

가장 높은 $p_i$을 가지는 item $i$가 예측된 다음 interaction item $i_{T+1}$이다.

### ⅶ. Complexity Analysis
MLP의 한 layer의 complexity는 $O(\text{input units} \times \text{hidden units} \times \text{output units})$

Long-term의 sequence-mixer는 $O(T \times R_s + R_s \times T)$이다.
이때, $R_s$는 constant이므로 sequence length $T$인 $O(T)$가 된다.
유사하게 channel-mixer의 complexity는 $O(D)$이다.

Short-term의 sequence-mixer는 $O(k)$이고,
channel-mixer는 $O(D)$가 된다.

그러므로 AutoMLP의 complexity는 $O(T+D+k)$이다.
이는 3 변수에 linear하다.

## Ⅲ. Experiements

성능이 좋고 빠르다는 내용이 있다.

자세한 것은 논문을 참고하자.

## References

1. [Jinu's Blog, Differentiable Architecture Search (DARTS)][4]{:target="_blank"}



[1]: https://arxiv.org/pdf/2303.06337.pdf
[2]: https://arxiv.org/pdf/1806.09055.pdf
[3]: https://arxiv.org/pdf/2105.01601.pdf
[4]: https://ahn1340.github.io/neural%20architecture%20search/2021/05/03/DARTS.html