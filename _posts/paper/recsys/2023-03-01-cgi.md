---
title: "Contrastive Graph Structure Learning via Information Bottleneck for Recommendation, (NuerIPS'22: Spotlight)"
categories: [Paper, RecSys]
tags: [GNN, Popularity Bias, Interaction Noises, Contrastive Learning, Information Bottleneck]
img_path: /assets/img/posts/paper/recsys/cgi/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

# Abstract

High-order neighbors를 탐색하는 능력으로 GCNs는 추천에서 중요한 연구 주제로 여겨졌다.
하지만, popularity bias와 noisy interactions가 GCNs에 악영향을 끼친다.
Graph contrastive learning은 그러한 문제를 해결하기 위한 좋은 방법이다.
대부분의 기존 방법들은 edges/nodes를 random하게 drop하거나 미리 정의된 규칙으로 original graph의 다양한 view를 생성하기 위해 graph augmentation을 수행한다.
이러한 views는 그것과 대응되는 augmented graph의 정확도를 최대화 함으로써 보조 task로 사용된다.
하지만 저자들은 이러한 방법들은 suboptimal이고 추천과 관련 없는 정보를 포함한 representation을 강제한다고 지적한다.
따라서 저자들은 Contrastive Graph Structure Learning via Information Bottleneck (CGI)를 제안한다.
- optimized graph를 얻기 위해 어떤 edge/node를 drop할 지 adaptively하게 학습한다.
- Contrastive learning process에 Information Bottleneck을 도입한다.

# Ⅰ. Introduction

최근 multi-hop neighbors를 node representation learning에 포함시키는 효과적인 방법으로서, GCNs는 추천 시스템에서 큰 성능 향상을 보여주었다.
하지만, <span class="text-color-yellow">input graph의 품질에 취약하다고 알려진 GCN</span> 기반 model에는 2가지 limitations이 있다. 

Popularity Bias.
: Items는 본직절으로 서로 다른 customer sizes를 가진다. 
예를 들어, 스마트폰 vs 전기톱처럼 말이다. 
그리고 이러한 불균형은 잠재적으로 popularity bias를 초래한다.
유사하게 대부분의 users는 과거 interactions data가 거의 없다.
이처럼 치우친 data distribution은 GCN 기반 models이 multi-hop convolution 동안 active user와 popular item에 편향되도록 만든다.

Interaction Noises.
: Implicit feedbacks scenarios에서 user-item interactions에 많은 noise가 있다.
실수로 item을 클릭할 수 있고, item 구매 후 심심해서 다른 item을 찾을 수 있다.
이러한 bipartite graph에서 noisy edges는 user preferences로 간주되어선 안된다.

최근 graph contrastive learning에선 popularity bias를 완화하고 noise에 robust한 training 체계(scheme)를 보여주었다.

> IB를 사용하면, 단순 contrastive learning보다 더 많이 완화되나...?

![](1.jpg)
_Figure 1: A possible illustration of some user’s interactions and preference. Dotted circles denote possible augmentation representations._

그럼에도 기존의 연구들엔 2가지 limitations이 있다.
첫 번째로, 대부분 방법론들은 randomly dropping edges/nodes, shuffling the embeddings, predefined rules로 data augmentation을 수행한다.
하지만, unsupervised settings에서 이러한 vanilla 접근법으로 생성된 structures는 suboptimal이고, vanilla 접근법이 어떻게 문제점들을 완화하는 지에 대한 설득력 있는 근거가 부족하다.

Fig. 1에서 *NO.1*처럼 vanila 접근법으로 생성된 structures는 optimal 영역을 벗어난다.
두 번째로, 대부분의 methods는 생성된 multiple views 간 node representation의 일치를 최대화하는 보조 task로만 views를 사용한다.
이는 서로 다른 views의 user 또는 item representation이 추천과 관련 없는 정보를 capture하도록 강제한다.
따라서 저자들은 Fig 1의 *NO.2*처럼 좋은 augmentation이 불필요한 정보를 줄이기 위해 가능한 작으면서 최적의 영역을 최대한 커버할 수 있다고 생각한다.

이를 위해 본 논문에서는 2가지 key components를 포함한 Contrastive Graph Structure Learning via Information Bottleneck (CGI)를 제안한다.

Learnable graph augmentation
: 이웃 node 또는 edge를 random으로 drop하는게 아니라 어떤 것을 drop할지 학습한다.
그 결과 popular nodes의 영향력을 줄여 <span class="text-color-yellow">popularity bias를 완화</span>한다.
직관적으로 말하면, popular nodes는 drop되어도 다른 nodes를 통해 정보가 전파될 가능성이 높다.
따라서 node의 degree를 고려해 dropout을 진행한다고 생각할 수 있다.


Information bottleneck contrastive learning
: Contrastive learning은 다른 views를 compact한 representation으로 통합해 model의 robustness를 향상시킨다.
그렇지만, random하게 augment된 다른 view와 단순히 mutual information을 최대화하는 것은 downstream task와 관련이 없는 정보를 capture하게 만든다.
Information Bottleneck (IB)는 downstream task에 필요한 minimum sufficient information을 capture하도록 representations를 학습시킨다.
<span class="text-color-yellow">주어진 task와 관련 없는 정보를 버림으로써 model의 robustness를 올린다.</span>
본 논문에서는 recommendation의 성능을 유지하면서 original graph와 생성된 views간의 mutual information을 최소화하기 위해 IB를 활용한다.
이를 통해 original graph에서 <span class="text-color-yellow">noisy interactions 없애는 것을 학습</span>할 수 있다.

> 각 view와 original graph와 mutual information을 최소화하여 dependency를 낮춘다.
> 그리고 recommendation loss 또한 최소화해 recommendation 성능은 유지한다.
> 즉, prediction에 정말 필요한 정보(minium sufficient information)만 표현한다.

# Ⅱ. Related Work

기존의 contrastive learning과 다른 점은 본 논문에서는 original graph와 augmentation views간 differences를 장려한다.

기존의 IB와 다른 점은 본 논문에서는 optimal graph를 찾는 것이 아니라 original graph에 도움을 주는 veiws를 찾는 것이다.
즉, contrastive learning에 IB를 활용한 점이 다른 IB 논문들과의 차이점이다.

저자들은 처음으로 graph-based recommendations에 IB principle을 활용했다고 주장한다.

> 하지만 [openreview.net][8]{:target="_blank"}을 참고해보면 graph에서 IB를 사용하는 논문이 다수 존재한다고 한다.

자세한 것은 논문 참고하자.

# Ⅲ. Preliminaries 

[LightGCN][3]{:target="_blank"}을 대략적으로 살펴보고 오자.

- $\mathcal{U} = $ { $u_1, \cdots, u_m$ }: users
- $\mathcal{I} = $ { $i_1, \cdots, i_n$ }: items
- $\mathcal{G} = $ { $\mathcal{V}, \mathcal{E}$ }: user-item bipartite graph
- $\textbf{A}_{\mathcal{G}}$: 인접행렬
- $\textbf{D}_{\mathcal{G}}$: 대각행렬, 인접행렬의 $i$ 번째 row에서 nonzero entries의 개수

자세한 것은 논문 참고하자.

# Ⅳ. Methodology

![](2.jpg)
_Figure 2: The overview the CGI framework. We integrate both the node-dropping and edge-dropping views together for a more comprehensive representation, though they can be applied separately._

지금까지 얘기했던 것처럼 $\textbf{A}_{\mathcal{G}}$는 bias와 noisy를 많이 포함하고 있다.
그리고 random dropout은 popularity bias와 noises를 완화하기에 충분하지 않다.
그래서 저자들은 <span class="text-color-yellow">layer-wise optimized augmentation views를 생성하기 위해 parameterized network를 활용</span>한다.

## ⅰ. Node-Dropping View

$$
\begin{align}
  \mathcal{G}_{ND}^{(\ell)} &= \{ 
    \{
      v_i \odot \rho_i^{(\ell)} | v_i \in \mathcal{V}
    \}, \mathcal{E}
  \}\\
  w_i^{(\ell)} &= MLP(\textbf{e}_i^{(\ell)})
\end{align}
$$

$\rho_i^{(\ell)} \sim Bern(w_i^{(\ell)})$는 0 또는 1로 node $v_i$를 유지할 확률을 의미한다.
$w_i^{(\ell)}$이 learnable parameter이다.

Node drop은 popular item, active user처럼 영향력 있는 nodes를 mask한다.

> Noisy item은 edge drop으로 완화된다.

이때 drop으로 선택된 node $v$와 관련된 edges를 모두 없애면 $w^{(w_i^{(\ell)})}$의 trainig이 unstable하다.
이를 방지하기 위해, 선택된 node $v$를 random walk로 형성된 subgraph의 nodes들의 representation을 mean pooling한다.

> 쉽게 말해, random walk로 adjacency matrix(subgraph)를 만들고 drop할 node $v$와 연결된 모든 node의 평균값을 $v$의 representation으로 사용한다.  
> Degree가 작은 node가 많이 반영되도록 하는 효과도 있을 것 같다...?

$$
\begin{equation}
  \textbf{E}^{(\ell)}_{ND} = GCN(\textbf{E}^{(\ell - 1)}_{ND}, \mathcal{G}_{ND}^{(\ell)})
\end{equation}
$$

이후 LightGCN을 통해 message propagation을 수행한다.
그리고 L개의 layer를 weighted sum해서 final representation $\textbf{E}_{ND}$을 구한다.

> LightGCN과 같이 L개 layer의 평균값을 구한다.

## ⅱ. Edge-Dropping Veiw

$$
\begin{align}
  \mathcal{G}_{ED}^{(\ell)} &= \{
    \mathcal{V},
    \{
      e_{ij} \odot \rho_{ij}^{(\ell)} | e_{ij} \in \mathcal{E}
    \}
  \}\\
  w_{ij}^{(\ell)} &= MLP(\textbf{e}_i^{(\ell)};\textbf{e}_j^{(\ell)})
\end{align}
$$

Edge drop은 noisy item을 filtering하고 popular nodes의 영향력을 줄인다.
Node drop과 유사하게 $\rho_{ij}^{(\ell)} \sim Bern(w_{ij}^{(\ell)})$는 0 또는 1로 edge $e_{ij}$를 유지할 확률을 의미한다.

$$
\begin{equation}
  \textbf{E}^{(\ell)}_{ED} = GCN(\textbf{E}^{(\ell - 1)}_{ED}, \mathcal{G}_{ED}^{(\ell)})
\end{equation}
$$

그리고 LightGCN을 통해 message propagation을 수행하고 L개 layer의 평균값을 final representation $\textbf{E}_{ED}$으로 사용한다.

## ⅲ. Reparameterization Trick

VAE에서 sampling이 포함되어 있을 때, end-to-end로 학습하기 위해 reparameterization trick을 사용했다.
본 논문에서도 categorical distribution에서 sampling할 때, end-to-end로 학습가능하게 해주는 [gumbel softmax][4]{:target="_blank"}를 사용한다.

$$
\begin{equation}
  \rho = \sigma((\text{log }\varepsilon - \text{log }(1 - \varepsilon) + w)/\tau)
\end{equation}
$$

- $\sigma(\cdot)$: sigmoid function
- $\varepsilon \sim U(0,1)$
- $\tau \in \mathbb{R}^+$: temperature

Inference할 땐, drop probability를 0.5보다 작도록 한다.

> 구현한 코드 상에선 해당 내용을 찾을 수가 없었다.

## ⅳ. Information Bottleneck Constrastive Learning

간단하게 $\textbf{E}_{ND/ED}$ 대신 $\tilde{\textbf{E}}$로 표기하자.

각 view에서 recommendation에 필요한 minimum sufficient information을 얻기 위해 Informaiton Bottleneck principle을 사용한다.
기존 contrastive learning과 다른 점은 augmentation view와 original graph representation 사이의 divergence를 독려한다는 것이다.

$$
\begin{equation}
  \underset{(\textbf{E}, \tilde{\textbf{E}})}{\text{min }}\tilde{\mathcal{L}}_{rec} + I(\textbf{E}; \tilde{\textbf{E}})
\end{equation}
$$

$\tilde{\mathcal{L}}_{rec}$는 augmentation view의 BPR loss이고 $I(\textbf{E}; \tilde{\textbf{E}})$는 original graph와 augmentation view의 mutual information을 나타낸다.

[InfoGraph][5]{:target="_blank"}에서 [InfoNCE loss][6]{:target="_blank"}를 최소화 하는 것은 mutual information의 lower bound를 최대화하는 것과 같다고 말하고 있다.
그래서 본 논문에서는 mutual information을 추정하기 위해 negative InfoNCE를 사용한다. [참고: slide 8][10]{:target="_blank"}

> Negative infoNCE를 최소화, 즉 infoNCE를 최대화하므로 lower bound가 낮아진다.  
> Lower bound가 낮다고 mutual information이 작아지지 않는다. 그래서 성능이 엄청 높지 않은 것 같다.

$$
\begin{align}
I(\textbf{E}; \tilde{\textbf{E}}) 
  &= I(\textbf{E}_u; \tilde{\textbf{E}}_u) 
    + I(\textbf{E}_i; \tilde{\textbf{E}}_i)\\
I(\textbf{E}_u; \tilde{\textbf{E}}_u) 
  &= \sum_{v_i \in \mathcal{U}} \text{ log }
  \frac{\text{exp }(s(\textbf{e}_i, \tilde{\textbf{e}}_i)/\tau^\prime)}
  {\sum_{v_j \in \mathcal{U}} \text{ exp }(s(\textbf{e}_i, \tilde{\textbf{e}}_j)/\tau^\prime)}
\end{align}
$$

- Positive pair: {$(\textbf{e}_i, \tilde{\textbf{e}}_i) \| v_i \in \mathcal{U}$ }
- Negative pair: {$(\textbf{e}_i, \tilde{\textbf{e}}_j) \| v_i, v_j \in \mathcal{U}, i \neq j$ }
- $s(\cdot)$: cosine similarity
- $\tau^\prime$: temperature

## ⅴ. Optimization

$$
\begin{equation}
\mathcal{L}
  = \mathcal{L}_{rec}
    + \mathcal{L}_{rec}^{ND}
    + \mathcal{L}_{rec}^{ED}
    + \lambda(I(\textbf{E}, \textbf{E}_{ND}), I(\textbf{E}, \textbf{E}_{ED}))
    + \beta ||\Theta||^2_2
\end{equation}
$$

마지막 term은 $L_2$ regularization이고 $\lambda, \beta$는 hyper-parameter이다.

## ⅵ. Proposition 1.

$\tilde{\mathcal{G}}$를 학습된 augmentation view, $\mathcal{G}^\prime$은 noisy graph structure, downstream recommendation information (minimum sufficient information)을 $Y_{Rec}$이라고 하자.

[Markov chain assumption][7]{:target="_blank"}에 따라 $\mathcal{G}$는 $Y_{Rec}$과 $\mathcal{G}^\prime$로 정의된다고 가정하자.

$$
(Y_{Rec}, \mathcal{G}^\prime) \rightarrow \mathcal{G} \rightarrow \tilde{\mathcal{G}}
$$

Data processing inequality(DPI)에 따라 다음을 알 수 있다.
: $$
\begin{split}
&(Y_{Rec}, \mathcal{G}^\prime) \rightarrow \mathcal{G} \rightarrow \tilde{\mathcal{G}}
 &\therefore (Y_{Rec}, \mathcal{G}^\prime) \perp \tilde{\mathcal{G}} | \mathcal{G} \text{ and } 
 I((Y_{Rec}, \mathcal{G}^\prime) ;\tilde{\mathcal{G}}|\mathcal{G}) = 0\\
&I(\tilde{\mathcal{G}};(Y_{Rec}, \mathcal{G}^\prime), \mathcal{G}) 
  &= I(\tilde{\mathcal{G}};(Y_{Rec}, \mathcal{G}^\prime)) 
    + \underbrace{I(\tilde{\mathcal{G}};\mathcal{G}|(Y_{Rec}, \mathcal{G}^\prime))}_{\ge 0} \because \text{chain rule of MI}\\
& &= I(\tilde{\mathcal{G}};\mathcal{G}) 
    + \underbrace{I(\tilde{\mathcal{G}};(Y_{Rec}, \mathcal{G}^\prime)|\mathcal{G})}_{=0} = I(\tilde{\mathcal{G}};\mathcal{G})\\
& &\therefore I(\mathcal{G};\tilde{\mathcal{G}}) \ge I((Y_{Rec}, \mathcal{G}^\prime);\tilde{\mathcal{G}})
\end{split}
$$

> [Markov chain assumption][7]{:target="_blank"}의 proposition 3.1의 Appendix C.2와 conditional mutual information 참고.

$$
\begin{split}
I(\mathcal{G};\tilde{\mathcal{G}}) 
  &\ge I((Y_{Rec}, \mathcal{G}^\prime);\tilde{\mathcal{G}}) &\because \text{DPI}\\
  &= I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) + I(Y_{Rec}; \tilde{\mathcal{G}}|\mathcal{G}^\prime) &\because \text{chain rule} \\ 
  &= I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) + H(Y_{Rec}|\mathcal{G}^\prime) - H(Y_{Rec}|\mathcal{G}^\prime;\tilde{\mathcal{G}}) &\because \text{condition mutual information}\\
  &\ge I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) + H(Y_{Rec}) - H(Y_{Rec}|\tilde{\mathcal{G}}) &\because Y_{Rec}, \tilde{\mathcal{G}} \text{ is independent}\\
  &= I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) + I(Y_{Rec};\tilde{\mathcal{G}}) &\because \text{By MI definition}\\
  &\propto I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) - \tilde{\mathcal{L}}_{rec}\\
\end{split}
$$

$$
\therefore  I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) \le I(\mathcal{G};\tilde{\mathcal{G}}) + \tilde{\mathcal{L}}_{rec}
$$

$\mathcal{G}^\prime, Y_{Rec}$은 independent하기 때문에 $H(Y_{Rec}\|\mathcal{G}^\prime) = H(Y_{Rec})$이다.
그리고 $H(Y_{Rec}\|\mathcal{G}^\prime;\tilde{\mathcal{G}}) \le H(Y_{Rec}\|\tilde{\mathcal{G}})$은 straitghtforward하다.

> $H(Y_{Rec}\|\mathcal{G}^\prime;\tilde{\mathcal{G}}) = H(Y_{Rec}, \tilde{\mathcal{G}}), H(Y_{Rec}\|\tilde{\mathcal{G}}) = H(Y_{Rec}, \tilde{\mathcal{G}}) - H(Y_{Rec})$

따라서 최종적으로 다음과 같은 결과를 얻을 수 있다.

$$
\begin{equation}
I(\mathcal{G}^\prime;\tilde{\mathcal{G}}) \le I(\mathcal{G};\tilde{\mathcal{G}}) - I(Y_{Rec};\tilde{\mathcal{G}})
\end{equation}
$$

여기서 $I(Y_{Rec};\tilde{\mathcal{G}})$는 Eq. 8의 $-\tilde{\mathcal{L}}_{rec}$에 비례한다.
따라서 Eq. 8을 최적화하는 것은 <span class="text-color-yellow">augmentation view와 noisy structure 사이의 mutual information을 최소화</span>하는 것과 같다.

> Information theory에 관한 자세한 내용은 아래의 reference를 참고하자.

# Ⅴ. Experiments

![](3.jpg)
_Table 1: Comparison among models. Boldface denotes the highest score and underline indicates the best result of the baselines._

## ⅰ. Ablation Studies

![](4.jpg){: w="500"}
_Table 2: Comparison among models._

model-ND는 node-dropping view만 사용한 것을 의미하고 model-ED는 edge-dropping view만 사용한 것을 의미한다.

1. CGI/SGL 변형을 비교하면 CGI 성능이 더 좋다. 즉, Contrastive learning에 IB를 사용하는 것이 좋다.
2. CGI는 CGI-ND, CGI-ED 둘 보다 성능이 좋다. 
  - CGI에서 각 layer가 서로 다른 semantics 정보를 capture해서 robust하기 때문이라고 주장한다.
3. Sparse한 dataset 'Yelp2018'에선 CGI-ED가 CGI-ND보다 성능이 좋고 dense dataset 'Movielens-1M'에선 CGI-ND 성능이 더 좋다.
  - Sparse dataset에서 popular users or items와 그와 관련된 edge를 모두 없애면 복원하기 어렵기 때문이다.

> 2에 대한 더 자세한 설명이 있었으면 좋겠다. 뭔가 부족하다.

## ⅱ. Accuracy against Popularity Bias

![](5.jpg){: w="500"}
_Figure 3: Performance of different item groups_

Popularity에 따라 item set $I$를 5개 group으로 나눴다.
그리고 [SGL][9]{:target="_blank"}와 같이 각 item group 별 RECALL@10 성능을 측정한다.

$$
\begin{equation}
  \begin{split}
    \text{Recall}^{(g)} &= \frac{1}{M} \sum_{u=1}^M\frac{|(\mathcal{I}_{rec}^u)^{(g)} \cap \mathcal{I}_{test}^u|}{|\mathcal{I}^u_{test}|} \\
    \text{Recall} &= \frac{1}{M}\sum_{u=1}^M \frac{\sum_{g=1}^5\big|(\mathcal{I}^u_{rec})^{(g)} \cap \mathcal{I}^u_{test}\big|}{|\mathcal{I}^u_{test}|} =\sum_{g=1}^5\text{Recall}^{(g)}
  \end{split}
\end{equation}
$$

Eq. 13에서 $\text{Recall}^{(g)}$는 group $g$의 성능을 의미한다. 

각 user $u$의 test item 집합 $\mathcal{I}^u_{test}$이 있을 때, 추천된 item 중 group $g$에 해당 하는 item 집합이 $(\mathcal{I}_{rec}^u)^{(g)}$이 test item 집합에 속하는 item 개수의 평균 값이다.

Fig. 3을 살펴보면 long-tail items에 대해선 CGI의 성능이 SGL 또는 LightGCN보다 높다.
그렇지만 popular한 item에 대해선 성능 차이가 거의 없다.

## ⅲ. Robustness to Interaction Noises

![](6.jpg)
_Figure 4: Performance comparison over different noise ratio. The bar represents the NDCG@10 and the line represent the performance degradation ratio._

Negative interaction 5%, 10%, 15%, 20%을 임의로 생성해 training set을 오염시키고 본래의 test set에 대한 성능을 실험했다.
Fig. 4를 보면, CGI가 다른 model보다 degradation이 낮은 것을 볼 수 있다.
그리고 noise가 많아 질수록 그 gap이 더 커진다.

![](7.jpg)
_Figure 5: Effect of Information Bottleneck on Yelp2018_

GL은 graph learning으로 LightGCN을 의미한다. GCL은 mutual information을 최소화하지 않고 최대화한다. 즉, $\text{min }\tilde{\mathcal{L}}_{rec} - I(\textbf{E};\tilde{\textbf{E}})$이다.

Fig. 5의 training step을 GCL은 CGI보다 loss가 높은데 빠르게 수렴하는 경향을 보인다. 
이는 CGI가 더 나은 local optimum으로 수렴할 가능성이 더 높다는 것을 보여준다.
그리고 이것이 Fig. 5의 오른쪽 그림처럼 CGI의 성능이 좋은 이유가 될 것이다.

## ⅳ. Performance with Other GNNs

![](8.jpg)
_Table 3: Performance with Other GNN variants._

LightGCN 이외에 다른 backbone(GM-MC, NGCF)에서도 잘 동작한다.

# Reference
1. [Kevin P. Murphy. (2023). Probabilistic Machine Learning: Advanced Topics, MIT Press][11]{:target="_blank"}

[1]: https://openreview.net/forum?id=lhl_rYNdiH6
[2]: https://github.com/weicy15/CGI
[3]: https://c0natus.github.io/posts/lightgcn/
[4]: https://arxiv.org/pdf/1611.01144.pdf
[5]: https://arxiv.org/pdf/1908.01000.pdf
[6]: https://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf
[7]: https://arxiv.org/pdf/1706.01350.pdf
[8]: https://openreview.net/forum?id=lhl_rYNdiH6
[9]: https://arxiv.org/pdf/2010.10783.pdf
[10]: https://people.ee.duke.edu/~lcarin/Jiachang3.20.2020.pdf
[11]: https://probml.github.io/pml-book/book2.html