---
title: Variational Autoencoders for Collaborative Filtering, (WWW'18)
categories: [Paper, RecSys]
tags: [Collaborative Filtering, Implicit Feedback, Variational Autoencoder]
img_path: /assets/img/posts/paper/recsys/multvae/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

# Abstract

Challenges
: 1. 기존의 CF model non-linearity 없음.  
2. Ranking과 관련된 metric(mAP, NDCG)를 활용해 직적접으로 optimization하기 어려움.

Address
: 1. Linear latent-factor를 일반화하면서 non-linear probabilistic latent-variable models을 탐색.  
2. [Multinomial][3]{:target="_blank"} likelihoods는 implicit feedback에서, 일반적으로 사용되는 loss보다 상대적으로 ranking loss에 더 가까운 proxy.  
3. 추천의 성능을 위해 KL annealing을 통해 regularization term의 strength을 통제한다.

# Ⅰ. Introduction

적절한 non-linear features를 latent factor model에 추가하면 추천 성능이 높아진다.
하지만, CF를 활용한 matrix factorization (MF) 등 기존의 works의 linear latent factor model은 non-linearity가 없어 modeling capacity를 제한한다.

추천 시스템에는 mAP, NDCG 등 주로 ranking과 관련된 metric으로 성능을 평가한다.
이러한 metric은 미분이 불가능하고 decomposability가 불가능해 간단한 gradient 방법으로 최적화하기 어렵다.

본 논문에서는 implicit feecback을 위한 CF에 multinomial likelihoods를 사용한 VAE를 활용한다.
VAE는 linear latent factor model을 일반화하고, non-linear probabilistic latent-variable model을 탐색할 수 있도록 한다.
<span class="text-color-yellow">Multinomial likelihoods는 implicit feedback data를 modeling하는 데 더 적합하고 일반적으로 사용되는 Gaussian이나 logistic likelihood functions보다 ranking loss에 더 가까운 proxy이다.</span>

많은 users와 items로 추천 시스템은 big-data problem으로 생각될 수 있지만, 저자들은 sparsity 때문에 추천 시스템은 'small-data' problem이라고 주장한다.
Sparse signals을 활용하면서 overfitting을 피하기 위해 저자들은 probabilistic latent-variable model을 설계했다.
경험적으로 Bayesian approach(ELBO)는 data의 sparsity와 관계없이 더 robust하다.

추가로 본 논문에서 VAE objective function은 over-regularized되어 있다고 판단해 KL term에 $\beta$를 곱해 regularization을 조절한다.
저자들은 이것을 information-bottleneck principle과 maximum-entropy discrimination과 연관짓는다.

# Ⅱ. Method

Notation
: $$
\begin{split}
  &\text{Users: } u \in {1, \dots, U}\\
  &\text{Item: } i \in {1, \dots, I}\\
  &\text{Click matrix: } \textbf{X} \in \mathbb{N}^{U \times I}\\
  &\text{Click items of user } u \text{: } \textbf{x}_u = [\dots, x_{ui} , \dots]^\top \in \mathbb{N}^I
\end{split}
$$

간단하게 click matrix는 0 또는 1로 이뤄져 있다고 생각한다.
Count data로 진행해도 된다.

## ⅰ. Model

알고리즘의 흐름은 아래와 같다.

- 각 user $u$마다 Gaussian prior에서 $K$-dimensional latent representation $\textbf{z}_u$를 sampling한다.

$$ \textbf{z}_u \sim \mathcal{N}(0, I_K) $$

- 전반적인 $I$개 items에 대한 확률 분포를 얻기 위해, non-linear function $f_\theta(\cdot) \in \mathbb{R}^I$으로 latent representation을 변환한다.  
$\pi \in \mathbb{S}^{I-1}$이다. $\mathbb{S}^{I-1}$는 $I-1$ simplex를 뜻한다.
$I-1$ 차원의 [simplex][4]{:target="_blank"}는 Euclide space에서 합이 1인 $I$ 개의 element를 가지는 vector를 뜻한다.
쉽게 말해 각 items를 소비할 확률로 해석할 수 있다.

$$
\pi(\textbf{z}_u) = \text{softmax}(f_\theta(\textbf{z}_u)) \propto \text{exp}\{f_\theta(\textbf{z}_u)\}
$$

- User $u$의 총 click 수인 $N_u = \sum_i x_{ui}$가 주어졌을 때, $\textbf{x}_u$는 parameter $\pi(\textbf{z}_u)$를 가지는 multinomial distribution에서 sampling된 것이다.
  - $f_\theta$ 대신 dot product, multinomial likelihood 대신 Gaussian likelihood(MSE loss)를 사용하면 matrix factorization이 된다.

$$
\textbf{x}_u \sim \text{Mult}(N_u, \pi(\textbf{z}_u))
$$

Multinomial의 parameter이자 latent representation인 $\textbf{z}_u$가 주어졌을 때, log-likelihood는 다음과 같다.
Multinomial distribution은 multi-class classification을 위한 cross-entropy loss로 사용된다.

$$
\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u) \overset{c}{=} \sum_i x_{ui}\text{ log }\pi_i(\textbf{z}_u)
$$

- 상수($\frac{N_u!}{x_{u1}!\cdots x_{uI}!}$)는 생략.

Section 4에서 아래의 Gaussian과 logistic likelihoods와 비교를 진행한다.

$$
\begin{split}
\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u) &\overset{c}{=} - \sum_i \frac{c_{ui}}{2}(x_{ui}-f_{ui})^2 &\rightarrow \text{Gaussian}\\
\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u) &= \sum_i x_{ui}\text{ log }\sigma(f_{ui}) + (1-x_{ui})\text{ log }(1-\sigma(f_{ui})) &\rightarrow \text{Logistic}
\end{split}
$$

- $f_{ui} \equiv f_\theta(\textbf{z}_u)_i$
- $c_{ui} \equiv c_{x_{ui}}$: $c_1 > c_0$인 confidence weight. 
  - Sparsity 때문에 data가 적은, 과거에 interaction이 있었던 entry에 더 많은 weight를 부여한다.
- $\sigma(\cdot)$: sigmoid function.

## ⅱ. Variational inference

기존 VAE와 마찬가지로 $f_\theta$의 parameter인 $\theta$를 학습하기 위해 interactable한 posterior distribution인 $p(\textbf{z}_u\|\textbf{x}_u)$에 근사하기 위해 variational inference를 사용한다.

Variational inference에서는 단순한 variational distribution $q(\textbf{z}_u)$를 true intractable posterior $p(\textbf{z}_u\|\textbf{x}_u)$에 근사시킨다.

$$
q(\textbf{z}_u) = \mathcal{N}(\mu_u, \text{diag}\{\sigma^2_u\}), \ \ \mu_u, \sigma_u \in \mathbb{R}^K\\
\text{min }\text{KL}(q(\textbf{z}_u||p(\textbf{z}_u|\textbf{x}_u)))
$$

<span class="text-color-bold">**Amortized inference and the variational autoencoder.**</span>
Variational inference로 users의 수만큼 $q(\cdot)$의 parameter인 $\mu_u, \sigma_u$를 구해야 한다.
이는 user의 수가 많은 추천 시스템에서는 bottleneck이 될 수 있다.
그래서 data-dependent function($g_\phi$: inference model)으로 user의 variational parameters를 구한다.

$$
g_\phi \equiv [\mu_\phi(\textbf{x}_u), \sigma_\phi(\textbf{x}_u)] \in \mathbb{R}^{2K}\\
q_\phi (\textbf{z}_u|\textbf{x}_u) = \mathcal{N}(\mu_\phi(\textbf{x}_u), \text{diag}\{\sigma^2_\phi(\textbf{x}_u)\})
$$

![](1.jpg)
_Figure 1: A taxonomy of autoencoders. The dotted arrows denote a sampling operation._

Inference model $g_\phi(x_u)$의 output인 $\mu_\phi, \sigma_\phi$는 $q_\phi(z_u\|x_u)$의 parameter가 되고, $q_\phi(z_u\|x_u)$는 interactable posterior distribution $p(z_u\|x_u)$에 근사하게 된다. 

Fig. 1c와 같이 $q_\phi(z_u\|x_u)$와 $p_\theta(z_u\|x_u)$를 동시에 사용한다.
이는 autoencoder의 구조와 닮아 variational autoencoder라고 부른다.

VAE는 inference $g_\phi$를 재사용하면서, $x_u$를 입력으로 받아 $z_u$를 만드는 amortized inference를 사용한다.
이는 과거 경험으로 추론된 비슷한 patterns를 활용하는 CF와 유사하다.

<span class="text-color-bold">**Learning VAE.**</span>
기존의 VAE의 objective는 log marginal likelihood의 lower-bound(ELBO)를 높힌다.

$$
\begin{equation}
  \begin{split}
    \text{log }p(\textbf{x}_u;\theta) &\geq \mathbb{E}_{q_\phi(\textbf{z}_u|\textbf{x}_u)}[\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u)] - \text{KL}(q_\phi(\textbf{z}_u|\textbf{x}_u)||p(\textbf{z}_u))\\
    &\equiv \mathcal{L}(\textbf{x}_u;\theta, \phi)
  \end{split}
\end{equation}
$$

Optimization을 위해 stochastic gradient ascent를 할 때, reparameterization trick을 사용한다.

자세한 것은 [여기][5]{:target="_blank"}를 참고하자.

<span class="text-color-bold">**Alternative interpretation of ELBO.**</span>
Eq. 1에서 첫 번째 term을 (negative) reconstruction error, 두 번째 term을 regularization으로 해석할 수 있다.
이 관점에서 regularization의 strength를 조절하기 위해 hyper-parameter $\beta$를 적용하는 것도 가능하다.

$$
\begin{equation}
\mathcal{L}_\beta(\textbf{x}_u;\theta,\phi) \equiv \mathbb{E}_{q_\phi(\textbf{z}_u|\textbf{x}_u)}[\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u)] -\beta \cdot \text{KL}(q_\phi(\textbf{z}_u|\textbf{x}_u)||p(\textbf{z}_u))
\end{equation}
$$

그렇다면 추천 시스템에서 generative model을 위해 statistical properties가 *모두* 필요한지 한번 생각해봐야 한다.
만약 ancestral sampling 성능 (regularization) 을 희생하면, 추천 성능(reconstruction)을 높일 수 있지 않을까?

> Ancestral sampling이란, $p(x), p(y\|x)$를 알고 있을 때 $p(x,y)$를 파악하기 위해 $p(x)$에서 먼저 sampling (ancestral sampling) 한 후 $p(y\|x)$에서 sampling하는 것을 의미한다.  
> 즉, $q_\phi(z_u\|x_u)$에서 sampling 후 $p_\theta(x_u\|z_u)$에서 sampling하는데, $q_\phi(z_u\|x_u)$의 성능을 희생시킨다는 뜻이다. 성능이라 함은 prior $p(z_u)$와의 유사성이 크면 좋다고 볼 수 있다.

만약 $\beta < 1$이면, KL term이 약화된다.
즉, prior constraint $\frac{1}{U} \sum_u q(z\|x_u) \approx p(z) = \mathcal{N}(z;0, I_k)$이 약화되어 ancestral sampling으로 새로운 user histories를 덜 생성하게 된다.

추천 시스템은 상상의 user histories를 생성하는 것이 아니기 때문에 KL term을 약화하는 것이 더 적합하다.

> Regularization을 약화해 training data에 있는 interaction을 복구하는 것에 더 중점을 둔다.

<span class="text-color-bold">**Selecting $\beta$.**</span>
저자들은 $\beta$를 0에서 1로 조금씩 증가시키면서 KL term을 강화(annealing)하고, 최고의 성능을 내는 $\beta$를 기록한다.

> 초기에 $\beta$를 0으로 둠으로써 $\textbf{z}$에 더많은 과거 interaction 정보가 담기도록 한다.

![](2.jpg)
_Figure 2: Validation ranking metrics with different annealing configurations. For the green dashed curve, $\beta$ reaches 1 at around 80 epochs._

Fig. 2는 validation dataset에 대한 ranking metric이다.
파란 선은 KL annealing이 없는 것이고 초록 점선은 $\beta = 1$까지 KL annealing을 한 것이다.
KL annelaing에서 $\beta$가 1에 가까워 질수록 validation 성능이 떨어지고 KL annealing이 없는 것과 성능 차이가 별로 없다.

그래서 저자들은 최적의 $\beta$를 기록한 다음 그 $\beta$까지 KL annealing하는 훈련을 다시 시켰고, 빨간 점선이 그 결과이다.
Greedy search의 sub-optimal일 수 있지만 훨씬 효율적이다.
물론 다시 훈련시키지 않고, validation metric이 떨어지려고 할 때 $\beta$ 증가를 멈출 수도 있다.
이는 기존의 VAE의 learning time과 같다.

저자들은 이처럼 VAE에 partially regularization 하는 것을 Mult-VAE$^\text{PR}$이라고 표기한다.

<span class="text-color-bold">**Computational Burden.**</span>

- Negative sampling이 필요 없다.
- Item의 개수가 많으면 multinomial 확률인 $\pi(z_u) \in \mathbb{R}^I$를 계산하는 데 오래 걸린다.

자세한 내용은 논문을 참고하자.

## ⅲ. A taxonomy of autoencoders

일반적인 autoencoder의 MLE는 다음과 같다.

$$
\begin{split}
  \theta^\text{AE}, \phi^\text{AE} &= \underset{\theta,\phi}{\text{argmax }}\sum_u\mathbb{E}_{\delta(\textbf{z}_u - g_\phi(\textbf{x}_u))}[\text{log }p_\theta(\textbf{x}_u|\textbf{z}_u)]\\
  &= \underset{\theta,\phi}{\text{argmax }}\sum_u\text{log }p_\theta(\textbf{x}_u|g_\phi(\textbf{x}_u))
\end{split}
$$

- $q_\phi(z_u\|x_u) = \delta(z_u - g_\phi(x_u))$으로 $\delta(z_u - g_\phi(x_u))$는 delta variational distribution이다. 즉, $z_u = g_\phi(x_u)$이면 1 $z_u \neq g_\phi(x_u)$이면 0을 가진다.

> Sampling 하지 않고 입력 data로 나온 $g_\phi$의 출력값만 사용하겠다는 뜻이다.  
> 일반적인 AE를 VAE 관점으로 설명하려니 delta variational distribution 개념을 사용한 것 같다.  

Autoencoder는 쉽게 overfitting하는 경향이 있다.
Dropout과 denoising autoencoder (DAE)를 사용하면 그 경향이 줄어든다.
Section 4에서 Mult-DAE에서의 point-estimation과 Mult-VAE$^\text{PR}$에서의 per-user variance를 explicit하게 parameterizing함으로써 얻는 장/단점을 비교한다.

> 쉽게 말해 Mult-DAE와 Mult-VEA$^\text{PR}$의 장/단점을 비교한다는 뜻이다.

AE, DAE, VAE의 차이점은 Fig. 1에서 직관적으로 확인할 수 있다.
VAE는 delta variational distribution $\delta(z_u - g_\phi(x_u))$ 대신 inference model $q_\phi(z_u\|x_u)$을 사용한다.

논문을 참고하자.

## ⅳ. Prediction

Mult-VAE$^\text{PR}$과 Mult-DAE의 prediction은 같은 방식을 사용한다.
User의 click history $\textbf{x}$가 주어지면 un-normalized predicted multinomial probability $f_\theta(\textbf{z})$를 통해 items의 ranking을 매긴다.

기존의 MF 방식은 새로운 user의 history가 생기면 이를 반영하기 위해 optimization을 다시한다.
Item-based AE 계열은 MF보단 더 효율적으로 반영한다.

> 새로운 item이 생기면 Item-based AE나 MF나 새로 훈련 해야할 것 같다.

# Ⅲ. Related Work

<span class="text-color-bold">**VAEs on sparse data.**</span>
VAE는 large, sparse, high-dimensional data를 modeling할 때 underfitting에 고통받는다는 것이 알려졌다.
Click history는 sparse하기 때문에 저자들은 KL annealing을 사용한다.

<span class="text-color-bold">**Information-theoretic connection with vae.**</span>
Eq. 2는 maximum-entropy discrimination과 유사한다.
Maximum-entropy discrimination은 discriminative estimation을 Bayesian inference, generative modeling과 결합시키는 것이다.
Eq. 2에서 $\beta$는 discriminative (reconstruct error)와 generative (regularization) 측면의 균형을 맞추는 역할을 한다.

Alemi 등은 information bottleneck principle의 variational approximation인 deep variational information bottleneck을 제안한다.
그들은 $\beta < 1$일 때 supervised classification 성능이 더 robust해진다고 주장한다.
이는 본 논문의 저자들이 주장하는 것과 같다.

Higgins 등은 images에서 disentangled representation(shape, scale, color, 등)을 학습하기 위해 $\beta$-VAE를 사용한다.
Higgins는 본 논문과 다르게 $\beta \gg 1$로 설정해 latent $z$와 독립적인 prior distribution을 더욱 강조한다.

> 자세한 내용은 각 논문을 살펴봐야 겠다.  
> VAE가 요즘 관심있는 IB principle, disentangled과 관련이 있는 것 같다.

<span class="text-color-bold">**Neural networks for collaborative filtering.**</span>
CF에 NNs을 사용한 연구를 소개해준다.

자세한 것은 논문을 참고하자.

# Ⅳ. Empirical study

Datasets, metrics, experimental setup, baselines은 논문을 참고하자.

![](3.jpg)
_Table 1: Attributes of datasets after preprocessing. Interactions are non-zero entries. % ofinteractions refers to the density ofthe user-item click matrix $\textbf{X}$. # ofthe held-out users is the number of validation/test users out of the total number of users in the first row._

## ⅰ. Experimental results and analysis

Reconstruction error와 regularization 대신 BRP을 사용했을 때 성능은 좋지 않았다고 한다.

이번 section에서는 아래의 2가지 물음에 대한 답을 empirical 결과를 통해 살펴본다.

1. Multinomial likelihood와 다른 likelihood 비교.
2. Mult-VAE$^\text{PR}$과 Mult-DAE 비교.

![](4.jpg)
_Table 2: Comparison of Mult-vae$^\text{PR}$ and Mult-dae with different likelihood functions at the output layer on ML-20M. The standard error is around 0.002 (the results on the other two datasets are similar.) The multinomial likelihood performs better than the other two commonly-used likelihoods from the collaborative filtering literature._

Table 1은 각 likelihood에 대한 성능이다.
Hyper-parameter $\beta$를 tuning했을 때, Gaussian과 logistic은 큰 변화가 없었다고 한다.

> Likelihood가 다르면 reconstruction error가 달라진다.

Mult-(D)VAE$^\text{PR}$과 Logistic-(D)VAE$^\text{PR}$의 성능 차이가 별로 안 나는 이유는 multinomial lkielihood가 individual binary logistic likelihood로 근사될 수 있기 때문이다.
저자들은 data에 알맞는 likelihood을 선택해야 한다고 주장한다.

![](5.jpg)
_Figure 3: NDCG@100 breakdown for users with increasing levels of activity (starting from 0%), measured by how many items a user clicked on in the fold-in set. The error bars represents one standard error. For each subplot, a paired t-test is performed and * indicates statistical significance at $\alpha$ = 0.05 level, ** at $\alpha$ = 0.01 level, and *** at $\alpha$ = 0.001 level. Although details vary across datasets, Mult-vae$^\text{PR}$ consistently improves recommendation performance for users who have only clicked on a small number of items._

Mult-VAE$^\text{PR}$이 Mult-DAE보다 sparse한 user-item interaction data에 대해서 더 robust하다.

Fig. 3은 user의 activity 정도에 따라 group을 나눈 것이다.

Active한 user에 대해선 Mult-DAE가 Mult-VAE$^\text{PR}$보다 성능이 좋다.
이는 user에 관한 data가 많을 땐, prior assumption이 성능에 방해된다고 해석할 수 있다.

Inactive한 user에 대해선 Mult-VAE$^\text{PR}$가 성능이 더 좋다.
Fig. 3(b)에서 0% ~ 20%에서 두 model의 성능이 유사한 이유는 MSD에서 inactive한 user를 제거했기 때문이다. 
즉, MSD에서 user는 적어도 20개의 interactions를 가진다.
반면에 ML-20M에서는 각 user마다 적어도 5개의 interactions가 보장된다.

결론을 말하자면, 전반적으로 data sparsity와 관계없이 Mult-VAE$^\text{PR}$가 Muilti-DAE보다 더 강건한다.

> 흠 이부분은 약간 어색하다. Interaction이 많으면 Mult-DAE가 더 성능이 좋은데 data sparsity와 관계가 없다니...?

그리고 무엇보다 Mult-VAE$^\text{PR}$가 hyper-parameter tuning에 시간을 덜 써도 된다.
Weight decay는 Mult-DAE에 중요하다.

Mult-DAE는 Mult-VAE$^\text{PR}$보다 bottleneck(encoder) 부분에서 최적화해야 할 parameter의 개수가 더 적다는 것이 장점이다.

나머지 실험에 대한 자세한 내용은 논문을 참고하자.

[1]: https://dl.acm.org/doi/pdf/10.1145/3178876.3186150
[2]: https://github.com/dawenl/vae_cf
[3]: https://c0natus.github.io/posts/discrete/#%E2%85%B3-multinomial
[4]: https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%B2%B4_(%EC%88%98%ED%95%99)
[5]: https://c0natus.github.io/posts/vae/
