---
title: "Graph Convolution Machine for Context-aware Recommender System, (Front. Comput. Sci.'22)"
categories: [Paper, RecSys]
tags: [CARS, GNN]
img_path: /assets/img/posts/paper/recsys/gcm/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

<!-- |[Implementation][2]{:target="_blank"}| -->

# Abstract

NGCF, LightGCN 등으로 graph convolutions이 user, item representations 학습에 도움이 된다는 것이 보여졌다.
하지만, 그러한 model은 context 정보를 활용하지 않는 collaborative filtering (CF)에 관한 방법론이다.
본 논문은 graph convolution의 장점을 context-aware recommender system (CARS)에 적용한 *Graph Convolution Machine* (GCM)을 제안한다.
GCM은 encoder, graph convolution (GC) layers, decoder로 구성되어 있다.

# Ⅰ. Introduction

추천 시스템에서 핵심 data는 user-item interactions이다.
이를 활용한 CF는 추천을 위한 보편적인 solution을 제공하지만, context 정보를 활용하는 데는 부족하다.
다양한 시나리오에서, 현재 context는 user의 선택에 많은 영향을 끼친다.
따라서 context 정보를 user의 선호도 예측에 사용하는 CARS가 발전되었다.

MF를 CARS로 확장시킨 tensor factorization은 높은 complexity를 가진다. 
이후 나온 factorization machines (FM)은 처음으로 일반적인 supervised learning 관점으로 CARS를 해결한 model이다. 
FM의 일반성과 효율성으로 neural network를 이용한 FM의 후속 연구가 많이 진행되었다.

하지만, 현재 존재하는 CARS는 data instance간 interaction을 무시한다는 공통된 단점이 존재한다.
즉, MF에서 CF signal을 활용하기 위해 NGCF가 등장했듯 FM에서도 CF signal을 직접적으로 활용한다면 그 성능이 높아질 것이다.
게다가, FMs(xDeepFM, Convolutional FM, etc.)은 item에 대한 평점을 예측하려면, 각 item마다 feature interaction을 파악하기 위해, deep model에 feed되어야 하므로 CF(embeddings의 내적)보다 효율성이 떨어진다.
따라서 실제로 쓰일 수 없다.

본 논문에서는 위의 2가지 문제점을 해결한 새로운 CARS model GCM을 제안한다. 
Data에 존재하는 users와 items의 side information은 node features로 표현되고, contexts는 edge feature로 표현된다 (Fig. 1). 
그리고, GCM은 3가지 요소(encoder, GC layers, decoder)로 이뤄진 end-to-end model이다 (Fig. 2).

Encoder는 users, items, contexts를 embedding vectors로 project하고, GC layers는 user-item intearctions를 활용해 graph convolutions으로 embeddings를 개선한다. 마지막으로 decoder는 FM으로 embeddings간 interactions을 modeling하여 score를 prediction한다. Online serving 에서 GCM은 embeddings를 serving 전 미리 계산해 FM과 같은 time complexity를 가질 수 있다.

# Ⅱ. Related Work

기존의 FM과 관련된 연구들(FM, NFM, AFM, xDeepFM, Convolutional FM)은 user interactions을 개별적으로 다룬다는 것을 지적한다.
동일한 시간 및 위치에서 발생한 한 명의 user 행동은 user의 선호도를 반영할 가능성이 높다.
따라서 저자들은 user의 행동들 간 관계를 파악하는 것을 목표로 한다.

NGCF, Fi-GNN, GIN, 등에서 graph convolution을 통해 multi-hop neighbors의 정보를 aggregate해서 더 좋은 representations를 얻었다.
따라서 graph learning이 interactions간 관계를 적절히 model하기 위한 solution이란 점은 합리적이다.


# Ⅲ. Problem Definition

![](1.jpg)
_Fig. 1 The data used for building a CARS. The mixture data of interaction tensor and user/item/context feature matrices are converted to an attributed user-item bipartite graph without
loss of fidelity._

Fig. 1처럼, CARS에 쓰이는 main data는 4가지 유형(users, items, contexts, interactions)으로 분류된다.
Sparse tensor에서 nonzero entry ($u, i, c$) 즉, $y_{uic} = 1$은 user $u$가 context $c$에서 item $i$와 interaction한 것을 의미한다.
$u, i, c$는 각각 user/item/context multi-hot feature $\textbf{u, i, c}$와 연관되어 있다. 
- $\textbf{u}$는 user의 성별, 관심등록 tag 등 정적인 profile을 포함한다.
- $\textbf{i}$도 유사하게 item의 정적인 attribute(category, 가격, 등)을 포함한다.
- $\textbf{c}$는 현재 장소 및 시간 등 동적인 contexts를 포함한다.

GCM에 feed되려면, 이러한 data가 주여졌을 때 attributed user-item bipartite graph를 생성한다.
각 node는 한명의 user 또는 하나의 item을 표현하고, 각 edge는 하나의 user-item interaction을 표현한다.
User는 다른 context 하에 같은 item과 여러 번 interaction을 할 수 있기 때문에, 하나의 user-item pair는 여러 개의 edges를 가질 것이다. 모든 edges, user $u$의 이웃 nodes, item $i$의 이웃 nodes의 notation은 다음과 같다.

$$
\begin{align*}
\text{All edges }: &\text{ set } \mathcal{Y} = \{(u,i,c)|y_{uic}=1\}\\
\text{Neighbors of the user }u: &\text{ set } \mathcal{N}_u = \{(i,c)|y_{uic}=1\}\\
\text{Neighbors of the item }i: &\text{ set } \mathcal{N}_i = \{(u,c)|y_{uic}=1\}\\
\end{align*}
$$

User-item-context interactions $\mathcal{Y}$를 입력으로 주고 user가 item과 상호작용할 가능성을 나타내는 real value를 출력한다.

# Ⅳ. Graph Convolution Machine (GCM)

해당 section에서는 제안된 GCM에 대해서 알아보자.

![](2.jpg)
_Fig. 2 The Graph Convolution Machine model._

Fig 2에서 볼 수 있듯이, GCM은 encoder, GC layers, decoder로 이뤄져 있다.

## ⅰ. Encoder

Encoder는 user/item/context-field features 각각을 하나의 embedding vector로 mapping한다.
이때, user/item-field는 ID feature를 가져야 하지만, context는 ID feature가 필수는 아니다.
- 같은 profile(attribute)를 가지더라도 user(item)은 다를 수 있다.
- 같은 context는 같은 embeddings를 가진다.

> 의문점  
> Context는 global한 성향이 더 강해서 그런가?
> 예를 들면, 금요일 저녁은 술집을 추천하든지...
> 하지만, 사람마다 다를텐데 ID가 있으면 더 좋은 것일까?
> 아닌가... user/item-field feature로 이런 개인 성향을 충분히 다룰 수 있으려나?
> Context는 단순히 시간, 장소를 의미하는 정보만 전달하면 되려나?

User-field features를 encoder하는 과정은 아래와 같다.

$$
\begin{equation}
\mathbf{p}_u^{(0)} = \frac{1}{|\mathbf{u}|}\mathbf{P}^{\top}\mathbf{u}
\end{equation}
$$

- $\|\mathbf{u}\|$는 feature $\mathbf{u}$에서 nonzero feature의 수를 의미한다.
- $\mathbf{P} \in \mathbb{R}^{U \times D}$는 user features의 embedding matrix를 의미한다.
  - $U$는 user features의 total number를 의미하고, $D$는 embedding size를 의미한다.
- $\mathbf{p}_u^{(0)}$는 $u$의 initial representation vector를 의미한다.

유사하게, item의 initial representation vector를 얻을 수 있다.
본 논문에서는 average pooling을 선택했지만, 다른 pooling mechanisms을 선택할 수도 있다.
GCM에서는 pooling에 따른 성능 차이가 나지 않아 가장 간단한 average pooling을 선택했다.

GC layers에서는 context representation을 update하지 않기 때문에 context-field는 pooling을 하지 않는다.

> 의문점  
> GC layers에서 update하면 pooling이 필요한 이유는 뭐지...?

본 논문에서 context-field embeddings를 $\mathcal{V}_c = ${$\mathbf{v}_s\|s \in \mathbf{c}$}로 표기한다.
$s \in \mathbf{c}$는 feature $\mathbf{c}$에서 nonzero인 feature를 의미하고, $\mathbf{v}_s$는 context feature $s$의 embedding vector를 의미한다.

## ⅱ. Graph Convolution Layers

CF signal을 이용해 user, item representations을 개선시킨다.
GC의 일반적인 message propagation framework는 다음과 같다.

$$
\begin{equation}
  \mathbf{p}_u^{(\ell + 1)} = 
    \sum_{i \in \mathcal{N}_u} 
      g(\mathbf{p}_u^{(\ell)}, \mathbf{q}_i^{(\ell)})\\
  \mathbf{q}_i^{(\ell + 1)} = 
    \sum_{u \in \mathcal{N}_i} 
      g(\mathbf{q}_i^{(\ell)}, \mathbf{p}_u^{(\ell)})
\end{equation}
$$

$g(\cdot)$은 self-defined function을 의미한다.
이처럼, 일반적인 GC는 edge feature를 고려하지 않는다.
본 논문에서 제시하는 user-item graph에서는 edge가 context features를 전달한다.
따라서 context features를 적절히 통합할 수 있는 새로운 GC operation을 아래와 같이 제시한다.

$$
\begin{equation}
  \mathbf{p}_u^{(\ell + 1)} = 
    \sum_{(i, c) \in \mathcal{N}_u} 
      \frac{1}{\sqrt{|\mathcal{N}_u|}}
      ( \mathbf{q}_i^{(\ell)} 
        + \frac{1}{|\mathcal{V}_c|}\sum_{\mathbf{v}_s \in \mathcal{V}_c}\mathbf{v}_s
      )\\
  \mathbf{q}_i^{(\ell + 1)} = 
    \sum_{(u, c) \in \mathcal{N}_i} 
      \frac{1}{\sqrt{|\mathcal{N}_i|}}
      ( \mathbf{p}_u^{(\ell)} 
        + \frac{1}{|\mathcal{V}_c|}\sum_{\mathbf{v}_s \in \mathcal{V}_c}\mathbf{v}_s
      )
\end{equation}
$$

- User embedding 측면.
  - $\|\mathcal{N}_u\|$는 user $u$와 연결된 edge 개수로 GC로 인해 embedding의 크기가 커지는 것을 방지하는 normalization term$\big(\frac{1}{\|\mathcal{N}_u\|}\big)$에 사용된다.
  - Context features의 embeddings를 평균을 내고 user와 연결된 item embedding에 더한다.
- Item embedding도 user embedding을 구하는 것과 유사하다.

GC layers를 쌓음으로써 multi-hop neighbors로 user/item representation을 정제할 수 있다.
서로 다른 layers는 다른 semantics를 전달하므로 모든 layers의 representation을 결합하여 보다 범용적인 representation을 형성한다.

$$
\begin{equation}
  \mathbf{p}_u = \sum_{\ell = 0}^L \alpha_{\ell}\mathbf{p}_u^{(\ell)}; \ \ \ \ \ 
  \mathbf{q}_i = \sum_{\ell = 0}^L \alpha_{\ell}\mathbf{q}_i^{(\ell)}
\end{equation}
$$

- $\alpha_{\ell}$은 $\ell$번째 layer의 weight로 hyper-parameter이다.
  - $\alpha_{\ell} \ge 0$, $\sum_{\ell=0}^L \alpha_{\ell} = 1$
  - Grid search로 tune할 수 있지만 layer개수에 따라 workload가 지수적으로 증가한다.
  - $\alpha_{\ell} = 1/(L+1)$로 setting하면 만족스러운 결과를 얻을 수 있다.

구현을 할 땐, matrix 형태가 필요하다.
- User-item interaction matrix: $\mathbf{R}_{ui} \in \mathbb{R}^{N \times M}$
  - $N, M$은 users와 item의 수를 의미한다.
  - $r_{ui} \in \mathbf{R}_{ui}$는 user $u$와 item $i$가 interaction한 수를 의미한다.
- User-context interaction: $\mathbf{R}_{uc} \in \mathbb{R}^{N \times K}$
- Item-context interaction: $\mathbf{R}_{ic} \in \mathbb{R}^{M \times K}$

User-item-context graph의 adjacency matrix는 다음과 같이 정의한다.

$$
\begin{equation}
\mathbf{A} = 
  \begin{pmatrix}
    \mathbf{0} & \mathbf{R}_{ui} & \mathbf{R}_{uc} \\
    \mathbf{R}_{ui}^{\top} & \mathbf{0} & \mathbf{R}_{ic} \\
    \mathbf{0} & \mathbf{0} & 2\mathbf{I} \\
  \end{pmatrix}
\end{equation}
$$

- $\mathbf{A} \in \mathbb{R}^{(N+M+K) \times (N+M+K)}$
- $\mathbf{A}$에 $2\mathbf{I}$가 있는 이유는 아래에서 다시 살펴 보겠다.

$\mathbf{D}$를 $\mathbf{A}$의 diagonal degree matrix라 하자. 
즉, $\mathbf{D}$의 $t$번째 diagonal element와 normalized adjacency matrix는 다음과 같다.

$$
\begin{equation}
  \begin{split}
    \mathbf{D}_{tt} &= \sum_j\mathbf{A}_{tj}\\
    \hat{\mathbf{A}} &= \sqrt{2}\mathbf{D}^{-1/2}\mathbf{A}
  \end{split}
\end{equation}
$$

$\mathbf{I}$가 필요한 이유는 eq. 3에서 알 수 있듯이, GC로 인해 contexts의 embedding은 update되지 않기 때문이다.
즉, layer-wise propagation에서 contexts의 embedding은 그대로 유지되어야 한다.

이제 $\sqrt{2}$를 곱해주는 이유를 생각해보자.
$\sum_j\mathbf{A}_{tj}$는 $2\|\mathcal{N}_t\|$을 의미한다.
따라서 $\mathbf{D}^{-1/2}$는 $\sqrt{2\|\mathcal{N}_t\|}$이므로 normalized adjacency matrix를 구할 때 $\sqrt{2}$를 곱해준다.
그 결과, $\mathbf{I}$에 2를 곱해주게 되는 것이다.

Eq. 3을 matrix form으로 나타낸 layer-wise propagation rule은 다음과 같다.

$$
\begin{equation}
  \mathbf{E}^{\ell} = \hat{\mathbf{A}}\mathbf{E}^{(\ell - 1)}
\end{equation}
$$

> 의문점  
> Edge마다 active한(값이 1인) context가 하나면 $\|\mathcal{V}_c\| = 1$이니까 고려 안 해도 되는데, 그게 아니면...?
>
> 예를 들어, $u_1, i_1$ 사이에 1개의 edge가 있고 active한 context 개수는 2(장소, 시간)라 해보자.  
> 그러면 $\mathbf{D}_{u_1u_1} = 3$이므로 다음과 같이 된다.
>
> $$
\mathbf{p}_{u_1} = \mathbf{q}_{i_1} + \frac{1}{2} \sum \mathbf{v}_{s}\\
\downarrow\\
\mathbf{p}_{u_1} = \sqrt{\frac{2}{3}} \big(\mathbf{q}_{i_1} + \sum \mathbf{v}_{s}\big)
> $$
>
> Context가 시간에 관한 것만 있으려나...?

$\mathbf{E}^{\ell} \in \mathbb{R}^{(N+M+K) \times D}$는 encoder로 얻은 user, item, context embedding matrix를 concatenate한 것이다. 초기 embedding tables는 다음과 같다.

$$
\begin{equation}
  \mathbf{E}^0 = \big[
    \underbrace{\mathbf{p}_{u_1}^0, \cdots, \mathbf{p}_{u_N}^0}
      _{\text{user embeddings}},
    \underbrace{\mathbf{q}_{i_1}^0, \cdots, \mathbf{q}_{i_M}^0}
      _{\text{item embeddings}},
    \underbrace{\mathbf{r}_{c_1}^0, \cdots, \mathbf{r}_{c_K}^0}
      _{\text{user embeddings}}
    \big]^{\top}
\end{equation}
$$

각 layer마다 weight를 줘 최종 embedding matrix를 얻는다.

$$
\begin{equation}
  \begin{split}
    \mathbf{E} &= \alpha_0\mathbf{E}^0 + \alpha_1\mathbf{E}^1 + \cdots + \alpha_L\mathbf{E}^L \\
    &= \alpha_0\mathbf{E}^0 + \alpha_1\hat{\mathbf{A}}\mathbf{E}^0 + \cdots + \alpha_L\hat{\mathbf{A}}^L\mathbf{E}^0
  \end{split}
\end{equation}
$$

## ⅲ. Decoder

Decoder의 역할은 정제된 representation으로 prediction score를 얻는 것이다.
Decoder는 일반적으로 multi-layer perceptron (MLP)로 구현되지만, 오직 implicit 방식으로 feature interaction을 modeling하기 때문에 본 논문에선 적절하지 않다.
- NFM에서 explicit하게 feature interaction을 modeling하는 것이 중요하다고 말하고 있다.

따라서 간단하고 효율적인 FM을 GCM의 decoder로 채택한다.
- 정제된 user, item과 contexts간 pairwise interaction을 explicit하게 modeling하고 inner product로 prediction한다.

구체적으로 다음과 같다.

$$
\begin{equation}
  \hat{y}_{uic} = \frac{1}{2}
    \bigg( 
      \sum_{\mathbf{v}_s \in \mathcal{V}}\sum _{\mathbf{v}_t \in \mathcal{V}} \mathbf{v}_s^{\top}\mathbf{v}_t
      -
      \sum_{\mathbf{v}_s \in \mathcal{V}}\mathbf{v}_s^{\top}\mathbf{v}_s
    \bigg)
\end{equation}
$$

- $\mathcal{V} = \mathcal{V}_c \cup $ { $\mathbf{p}_u, \mathbf{q}_i$ }
- User, item, context feature의 bias term은 생략.

Vanilla FM과 다른 점은 user/item-field 내부의 interactions을 고려하지 않는다는 것이다.
Dataset에 user/item feature가 존재하면 FM은 user/item feature간 interactions을 modeling하지만, GCM의 decoder는 user/item embedding과 context feature간 interaction만 modeling한다.
즉, user/item-field 내부의 feature간 interactions은 modeling하지 않는다.

이를 통해 user (item)과 context features간 interactions에 더 집중을 할 수 있다.


## ⅳ Complexity and Optimization

GCM의 complexity는 FM과 같다.
자세한 것은 논문을 참고하자.

> 의문점  
> User/item-field 내부의 interactions을 계산하지 않는데 왜 더 느리지?
> Inference에서 FM이 더 빠른데 이건 self-interaction이 계산 되냐 안 되냐의 차이인가...?

GCM의 optimization은 point-wise log loss를 활용한다.
$\mathcal{Y}^-$는 negative set으로, observed instance $(u,i,c) \in \mathcal{Y}$마다 random하게 2 또는 4개를 sample한다.
Objective function는 다음과 같다.

$$
L = - \sum_{(u,i,c) \in \mathcal{Y}}\text{log}\sigma(\hat{y}_{uic}) 
  - \sum_{(u,i,c) \in \mathcal{Y}^-}\text{log}(1 - \sigma(\hat{y}_{uic}))
  + \lambda ||\Theta||^2_2
$$

# Ⅴ. Experiments

다양한 ablation study에 대한 설명이 있다.
- 다양한 layer 깊이, nomarlization 기법, decoder 등

자세한 것은 논문을 살펴보자.




[1]: https://dl.acm.org/doi/abs/10.1007/s11704-021-0261-8
[2]: https://github.com/wujcan/GCM