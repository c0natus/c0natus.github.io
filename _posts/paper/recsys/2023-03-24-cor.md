---
title: Causal Representation Learning for Out-of-Distribution Recommendation, (WWW'22)
categories: [Paper, RecSys]
tags: [Causal Representation Learning, OOD Recommendation, User Feature Shifts, CARS]
img_path: /assets/img/posts/paper/recsys/cor/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

## Abstract

Challenges
: 1. User attribute의 변화(OOD)에 robust한 그리고 빠르게 adaptation이 가능해야 함.
2. FM 계열은 disentangle이 되어 있지 않아 충분하지 않고, VAE 계열은 user attribute를 활용하지 않는다.

Address
: 1. User attribute에 영향을 받는 것과 받지 않는 user preference representation을 학습한다. 즉, 2 가지 type으로 disentangle한다.
2. OOD generalization을 위해 counterfactual inference를 사용하고, fast adaptation을 위해 fine-tuning 전략을 사용한다.

## 1. Introduction

기존의 대부분 연구들은 training과 testing 기간에 있는 interactions이 IID 라고 가정한다.
하지만 현실에선 선호도에 영향을 줄 수 있는 user의 attribute(e.g., 수입 증가)가 변경되는 것은 흔한 현상이다.
이처럼 user의 attribute가 변하는 OOD 환경은 user간 unfairness 문제(유명한 issue)로 이어지기 때문에, 기존의 recommender model의 성능이 떨어질 수밖에 없다.

![](1.png)
_Figure 1: Examples of OOD recommendation._

User attritube shifts를 다룰 가능성이 있는 기존의 방법으론 3가지 categories가 있다.
1. Feature-based models
  - User의 attribute를 바꿔 inference 시 OOD 환경에 적응할 수 있지만, 해당 user attribute가 interaction에 끼치는 영향이 disentagle되어 있지 않기 때문에 충분하지 않다.
2. Disentangled recommendation
  - Distribution shifts에 robust할 수 있는 user 선호도 factorization을 학습하지만, user attribute를 사용하지 않고 out-of-date(변경된 distribution에서 벗어난) interactions으로 학습을 진행한다.
3. Model re-training
  - Adaption을 용이하게 하지만, re-training 주기와 computation cost간의 dilemma가 있다. 그리고 user attribute가 변경된 후의 interactions data를 수집해야 한다. 즉, 바뀐 user attribute와 관련된 새로운 data를 수집하기 전까지 Fig. 1과 같이 적절하지 않은 items이 추천된다.

> Sequential recommendation랑 차이점은 re-training처럼 attribute가 바뀐 후 data가 충분히 수집되어야 하는 문제인가...?  
> 본 논문의 방법은 data가 충분하지 않아도 적절한 추천이 가능한 느낌...?  
> Sequential recommendation이 disentangled된 느낌인가...?  
> Sequential recommendation도 각 interaction들이 IID라고 가정 하지 않는다고 보는게 맞나...?

저자들은 추천 시스템을 강화하기 위해 두 가지 목적을 고려한 user 선호도 representation learning이 필요하다고 주장한다.
1. Strong OOD generalization
  - OOD 환경에 직접적으로 적응할 수 있는 가장 최신의 user attribute을 가지고 user 선호도를 정확히 추론해야 한다.
2. Fast adaption
  - OOD 환경을 반영한 새로운 interaction data가 거의 수집되지 않아도, model을 빠르고 정확하게 업데이트하는 것을 의미한다.

이 두 가지 목적을 이루기 위해 필요한 것은 다음과 같다.
1. 변경된 attribute가 선호도에 끼치는 영향을 이해할 수 있는 mechanism.
2. OOD 추천에서 out-of-date interactions의 영향 완화.
3. Adaption을 빠르게 하기 위해 변경되지 않은 user representation 재사용.

![](2.png)
_Figure 2: Causal graph of the interaction generation process._

3 가지 요소를 달성하기 위해, 저자들은 Fig. 2에 있는 causal graph처럼 interaction 생성 과정에서의 cause-effect와 causal language를 활용한다.
Causal graph는 user feature $E_1, E_2$에서 user preference $Z_1, Z_2$ 및 user interactions $D$까지의 causal relationships를 설명한다.
저자들은 user feature를 observed group $E_1$과 unobserved group $E_2$로 나눈다. 
그리고 $E_1$에 영향을 받는 user 선호도 feature는 $Z_1$이라 하고, 그렇지 않은 feature는 $Z_2$라고 한다.
- 기존의 방법들은 $E_1$과 $D$ 모두를 활용해 preference representation $Z$를 학습하기 때문에 OOD에서 out-of-date에 고통받는다.

Causal 관점으로 OOD recommendation은 interaction probabilities의 post-intervention inference $P(D\|do(E_1=\textbf{e}^\prime_1), E_2)$이다.
Observed user feature $E_1 = \textbf{e}_1$이 $E_1 = \textbf{e}^\prime_1$으로 변경되는 것이 intervention으로 probability에 반영되고, 이에 영향을 받지 않는 $Z_2$를 재사용함으로써 fast adaptation을 용이하게 한다.

본 논문에서는 causal graph를 따르는 interaction generation procedure를 modeling하는 Causal OOD Recommendation (COR) framework를 제안한다.
이 framework에서 unobserved features $E_2$를 추론하기 위해 [variational inference][3]{:target="_blank"}를 사용한다.
즉, VAE 구조에서 encoder로 $E_2$를 추론한다.
- Encoder는 interaction $D$와 observed $E_1$으로 $E_2$를 modeling $P(E_2\|D, E_1)$.
- Decoder는 $E_1, E_2$로 $D$를 추정 $P(D\|E_1, E_2)$.

학습이 완료되면 최신 user feature $\textbf{e}^\prime_1$를 encoder에 feeding하여 post-intervention inference를 수행한다.
그리고 $D$에 있는 out-of-date의 영향을 줄이기 위해 counterfactual inference를 사용한다.
새로운 interaction에 빠르게 적응하기 위해, $Z_2$은 재사용하고 $Z_1$만 fine-tuning으로 update한다.
또한 COR이 $E_1, E_2$와 $Z_1$ 사이의 보다 세분화된 causal relationships을 capture할 수 있음을 입증하기 위해 extension을 설계한다.

직접 만든 dataset 1개와 real-world dataset 2개에 대해 실험을 진행한다.

## 2. Recommendation Re-formulation

이번 section에서 interaction 생성 과정을 살펴보고, causal view로 OOD recommendation을 formulate한다.

### 2.1. Causal View of User Interaction Generation

Fig. 2에서 causal graph로 interaction 생성 과정을 간단하게 봤다.
이제 그것의 합리성을 살펴보자.

개인 정보 제약 또는 장치적 한계 때문에 대부분 추천 시스템은 user feature 중 일부분에만 접근 가능하다.
그래서 $E_1$는 관찰할 수 있는 user features(age, 수입, etc.)을 표현하고 $E_2$는 관찰할 수 없는 user features(conformity, social networks, etc.)를 표현한다.

User 선호도를 표현하는 latent vector는 $E_1$에 영향을 받는 $Z_1$과 그렇지 않는 $Z_2$로 구분된다.
$E_1$의 영향을 받지 않는 user 선호도가 항상 존재하기 때문에 $Z_1$과 $Z_2$로 분리된다.

$D$는 item에 대한 user의 interaction 상태를 나타낸다.

$(E_1, E_2) \rightarrow Z_1$과 $E_2 \rightarrow Z_2$는 user feature로 결정되는 user 선호도를 나타낸다.
예를 들어, 수입(income)은 가격(price)와 brand에 대한 선호도에 영향을 준다.

$(Z_1, Z_2) \rightarrow D$는 user의 interaction이 user 선호도로 결정된다는 것을 의미한다.


### 2.2. Formulation of OOD Recommendation

- User: $u \in $ { $1,\dots,U$ }
- Item: $u \in $ { $1,\dots,I$ }
- User preference representation: $\[\textbf{z}_1, \textbf{z}_2\]$
  - User preference representation는 관찰된 user의 feature $E_1 = \textbf{e}_1$와 user의 interaction인 multi-hot vector $D=\textbf{d}=$ { $1,\dots,I$ }$^I$로 학습된다.

Model은 $\[z_1, z_2\]$에 기반해 interaction probabilities를 추론한다.
본 논문에서는 이전 work에선 볼 수 없었던 OOD recommendation 문제를 연구한다.
Causal 관점에서 feature shift를 intervention이라 하고, $do(E_1=\textbf{e}^\prime_1)$로 표기한다.
따라서 추천 model은 $D$의 post-intervention 분포를 추론할 수 있어야 한다.

OOD 추천 성능을 평가하기 위해 아래의 2 가지 task를 제안한다.
1. OOD generalization
  - Intervention $do(E_1=\textbf{e}^\prime_1)$은 알지만, 그 후의 user interactions이 없을 때 model의 성능을 평가.
2. Fast adaptation
  - OOD 환경에서 intervention 이후 아주 적은 interaction을 수집했을 때, model이 OOD 환경에 얼마나 빨리, 정확하게 적응하는지 평가.

## 3. Causal OOD Recommendation

저자들은 OOD generalization을 위해 causal inference를 하고, fast adaptation을 위해 fine-tuning 전략을 선택한다.
마지막으로 세분화된 causal graph를 COR로 인코딩하는 extension을 고안합니다.

### 3.1. Causal Representation Learning

$$
\begin{equation}
\begin{cases}
  \textbf{e}_2 \sim \mathcal{N}(0, \textbf{I}_K), \\
  \textbf{z}_1 \sim \mathcal{N}\big(\boldsymbol{\mu}_{\theta_1}(\textbf{e}_1, \textbf{e}_2), \text{diag}\{\boldsymbol{\sigma}^2_{\theta_1}(\textbf{e}_1, \textbf{e}_2)\}\big), \\
  \textbf{z}_2 \sim \mathcal{N}\big(\boldsymbol{\mu}_{\theta_2}(\textbf{e}_2), \text{diag}\{\boldsymbol{\sigma}^2_{\theta_2}(\textbf{e}_2)\}\big), \\
  \textbf{d} \sim \text{Mult}(N, \pi(f_{\theta_3}(\textbf{z}_1, \textbf{z}_2)))
\end{cases}
\end{equation}
$$

- $\textbf{e}_2$
  - Standard Gaussian prior에서 sampling되는 unobserved feature를 의미하는 latent vector.
- $\textbf{z}_1, \textbf{z}_2$
  - $\textbf{e}_1$과 $\textbf{e}_2$로 계산한 분포에서 sampling된 user preference를 의미하는 latent vector.
  - Mult-VAE$^\text{PR}$ 처럼 user preference $\textbf{z}_1, \textbf{z}_2$는 factorized Gaussian에서 sampling된다.
- $\textbf{d}$
  - $I$개의 items에 대한 interaction 확률 $\textbf{d}$을 의미한다.
  - Mult-VAE$^\text{PR}$ 처럼 interaction $\textbf{d}$은 multinomial에서 sampling된다.
  - $\pi(\cdot)$은 $f_{\theta_3}$의 output을 normalize하는 softmax이다.

Model parameter $\theta_1, \theta_2, \theta_3$를 최적화하기 위해, VAE처럼 interaction history $\textbf{d}$를 reconstruction한다.
즉, log-likelihood $\text{log }p(\textbf{d}\|\textbf{e}_1)$를 최대화한다.

$$
\begin{equation}
\begin{split}
\text{log }p(\textbf{d}|\textbf{e}_1)
  &= \text{log} \int p(\textbf{d}, \textbf{e}_2|\textbf{e}_1) d\textbf{e}_2\\
  &= \text{log} \int p(\textbf{d}|\textbf{e}_1, \textbf{e}_2)p(\textbf{e}_2) d\textbf{e}_2
\end{split}
\end{equation}
$$

Unobserved features $\textbf{e}_2$에 대한 integral이 intractable하기 때문에 variational inference를 사용한다.

> $\textbf{e}_1, \textbf{d}$의 특징을 반영하고 있는 $p(\textbf{e}_2)$를 알 수 없다.  
>
> 그래서 이를 반영 distribution $q$를 위해 encoder $q_\phi(\textbf{e}_2\|\textbf{e}_1, \textbf{d})$가 필요하다.  
> 그리고 이왕이면 다루기 쉬운 distribution $\mathcal{N}(0, \textbf{I}_K)$과 비슷하길 원한다. (KL term 계산 용이)

$$
\begin{equation}
\begin{split}
\text{log }p(\textbf{d}|\textbf{e}_1) 
  &= \text{log }\int p(\textbf{d}|\textbf{e}_1, \textbf{e}_2)p(\textbf{e}_2)\frac{q_\phi(\textbf{e}_2|\cdot)}{q_\phi(\textbf{e}_2|\cdot)}\\
  &\geq \mathbb{E}_{q_\phi(\textbf{e}_2|\cdot)}\bigg[ \text{log }\frac{p(\textbf{d}|\textbf{e}_1, \textbf{e}_2)p(\textbf{e}_2)}{q_\phi(\textbf{e}_2|\cdot)} \bigg] &\text{ by jensens's inequality}\\
  &= \mathbb{E}_{q_\phi(\textbf{e}_2|\cdot)}[\text{log }p(\textbf{d}|\textbf{e}_1, \textbf{e}_2)] - \text{KL}(q_\phi(\textbf{e}_2|\cdot)||p(\textbf{e}_2)) &\rightarrow \text{ELBO}
\end{split}
\end{equation}
$$

Eq. 3의 ELBO를 계산하여 $q_\phi, p_\theta$를 modeling하기 위해 encoder, decoder networks를 선택한다.

![](3.png)
_Figure 3: Illustration of the encoder and decoder networks._

<span class="text-color-bold">**Encoder Network.**</span>
관찰할 수 있는 data(나이, 과거 interactions)는 관찰할 수 없는 data(conformity: 추천 결과에 순응)를 반영하고 있을 수 있다.
그래서 $\textbf{e}_1, \textbf{d}$로 $\textbf{e}_2$를 예측하고 효율을 위해 [amortized inference][3]{:target="_blank"}를 사용한다.

> 엥 그럼 Eq. 2에서 $\textbf{e}_1$과 $\textbf{e}_2$는 서로 독립이라고 보고 있지...?  
> $p(\textbf{d}, \textbf{e}_2 \|\textbf{e}_1) = p(\textbf{d}\|\textbf{e}_1, \textbf{e}_2)p(\textbf{e}_2\|\textbf{e}_1)$ 인데...?

$$
\begin{equation}
q(\textbf{e}_2 | \textbf{d}, \textbf{e}_1) = \mathcal{N}\bigg( \textbf{e}_2;\boldsymbol{\mu}_\phi(\textbf{d}, \textbf{e}_1), \text{diag}\{\boldsymbol{\sigma}_\phi^2(\textbf{d}, \textbf{e}_1)\} \bigg)
\end{equation}
$$

- $\boldsymbol{\mu}, \boldsymbol{\sigma}$는 encoder($g_\phi(\textbf{d}, \textbf{e}_1)$: MLP)로 구한다.

<span class="text-color-bold">**Decoder Network.**</span>
Fig. 3b에서 볼 수 있듯이, $p(\textbf{d}\|\textbf{e}_1, \textbf{e}_2)$를 Eq. 1에 따라 아래와 같이 factorize한다.

$$
\begin{align}
p(\textbf{d}|\textbf{e}_1, \textbf{e}_2) &= \int \int p(\textbf{z}_1|\textbf{e}_1, \textbf{e}_2)p(\textbf{z}_2|\textbf{e}_2)p(\textbf{d}|\textbf{z}_1, \textbf{z}_2)d\textbf{z}_1d\textbf{z}_2\\
\nonumber p(\textbf{z}_1|\textbf{e}_1, \textbf{e}_2) &= \mathcal{N}\big(\boldsymbol{\mu}_{\theta_1}(\textbf{e}_1, \textbf{e}_2), \text{diag}\{\boldsymbol{\sigma}^2_{\theta_1}(\textbf{e}_1, \textbf{e}_2)\}\big)\\
\nonumber p(\textbf{z}_2|\textbf{e}_2) &= \mathcal{N}\big(\boldsymbol{\mu}_{\theta_2}(\textbf{e}_2), \text{diag}\{\boldsymbol{\sigma}^2_{\theta_2}(\textbf{e}_2)\}\big)
\end{align}
$$

- $\mu_{\theta_1}, \sigma_{\theta_1}$은 $f_{\theta_1}(e_1, e_2)$: MLP로 구한다.
- $\mu_{\theta_2}, \sigma_{\theta_2}$은 $f_{\theta_2}(e_2)$: MLP로 구한다.

<span class="text-color-bold">**Approximation of $p(\textbf{d}\|\textbf{e}_1, \textbf{e}_2)$**</span>
$p(z_1\|\cdot), p(z_2\|\cdot)$를 추정했더라도, latent variables $z_1, z_2$에 대한 integral은 비용이 많이 든다.
따라서 효율을 위해 Monte Carlo (MC) sampling으로 근사치를 구한다.

$$
\begin{equation}
p(\textbf{d}|\textbf{e}_1, \textbf{e}_2) \approx \frac{1}{L}\frac{1}{M}\sum_{a=1}^L\sum_{b=1}^Mp(\textbf{d}|\textbf{z}_1^a, \textbf{z}_2^b)
\end{equation}
$$

그렇지만, conditional probability를 $L \times M$만큼 계산해야 하기 때문에 여전히 비용이 많이 든다.
그래서 아래와 같이 널리 사용되는 approximation을 사용한다.

$$
\begin{equation}
p(\textbf{d}|\textbf{e}_1, \textbf{e}_2) 
  \approx p\bigg(\textbf{d}\bigg|\frac{1}{L}\sum_{a=1}^L\textbf{z}_1^a, \frac{1}{M}\sum_{b=1}^M\textbf{z}_2^b\bigg)
  = p(\textbf{d}|\bar{\textbf{z}}_1, \bar{\textbf{z}}_2)
\end{equation}
$$

Approximation error(Jensen gap)는 $p(d\|\bar{z}_1, \bar{z}_2)$를 계산하는 대부분의 함수에 대해 잘 제한(bound)될 수 있다. [참고][4]{:target="_blank"}

그 후, $p(d\|\cdot)$의 parameter는 MLP $f_{\theta_3}$으로 추정한다.

$$
\begin{equation}
\text{log }p(\textbf{d}|\bar{\textbf{z}}_1, \bar{\textbf{z}}_2) \overset{c}{=} \sum_{i=1}^I d_i \text{ log }\pi_i (f_{\theta_3}(\bar{\textbf{z}}_1, \bar{\textbf{z}}_2))
\end{equation}
$$

- 상수 생략.
- $d_i$: user $u$가 item $i$를 소비했으면 1, 아니면 0.
- $\pi_i$: item $i$에 대한 예측 점수.

<span class="text-color-bold">**COR Optimization.**</span>
COR의 parameter를 optimizat하기 위해 Eq. 3의 ELBO를 SGD를 통해 maximize한다.
역전파를 위해 re-parameterization trick을 사용하고, Mult-VAE$^\text{PR}$처럼 KL annealing을 사용한다.
Training 동안의 전반적인 objective는 모든 user에 대한 ELBO의 평균값이다.

$$
\begin{equation}
  \mathbb{E}_{q_\phi(\textbf{e}_2|\textbf{d}, \textbf{e}_1)}[\text{log }p_\theta(\textbf{d}|\textbf{e}_1, \textbf{e}_2)] - \beta \cdot \text{KL}(q_\phi(\textbf{e}_2|\textbf{d}, \textbf{e}_1)||p(\textbf{e}_2))
\end{equation}
$$

Inference 시 $d^\prime = f_{\theta_3}(\bar{z}_1, \bar{z}_2)$로 items에 대한 rank를 매긴다.

> 일반적인 MultVAE나 MacridVAE 처럼 IID로 훈련하는 것과 같다.  
> FM과의 차이점은 causal graph 관점으로 disentangle했다는 점이다.  
> MacridVAE와의 차이점은 추론할 때 알 수 있다.


### 3.2. Causal Inference for OOD Recommendation

Post-intervention interaction probability를 추론하는 직관적인 방법은 $d, e_1^\prime$을 encoder $g_\phi$에 feed하여 $e_2$를 sampling한 뒤, $d^\prime$을 계산하기 위해 $e_1^\prime$과 $e_2$를 decoder에 feed한다.

![](4.png)
_Figure 4: Illustration of counterfactual inference._

<span class="text-color-bold">**Counterfactual Inference.**</span>
위에서 살펴본 직관적인 방법은 encoder로 $e_2$를 추론할 때 과거 interactions을 입력으로 사용하기 때문에 out-of-date interaction이 영향을 끼칠 위험이 있다.
변경된 feature $e_1^\prime$과 충돌이 있는 out-of-date 정보를 피하기 위해 $e_2$가 $z_1$에게 끼치는 나쁜 영향 차단(action)을 차단해야 한다.
그리고 $z_2$는 OOD 환경에서 안정적이어야 하고 post-intervention이 $z_2$에 영향을 주지 않기 때문에, $e_2$가 $z_2$에 끼치는 좋은 영향은 유지(abduction)해야 한다.

이를 위해 저자들은 $z_1$이 $d$의 영향을 받지 않는다면 예측된 user interaction $D$가 어떨지 상상하는 counterfactual inference 전략을 제시한다.

Counterfactual inference의 3 가지 step 정의에 따라 본 논문에서는 아래와 같이 inference 전략을 제시한다.

1. **Abduction**
  - Fig. 4a처럼 factual $D=d$에 기반해 $z_2$를 추정해, $d$의 좋은 영향을 유지한다.
2. **Action**
  - Fig. 4b처럼 $do(D=0)$을 수행해 $e_2^\prime, z_1^\prime$을 추정한다. $do(D=0)$은 empty interaction history를 의미한다. 즉, $z^\prime_1$이 out-of-date interactions $\textbf{d}$에 자유롭다.
  - 가장 최근의 interaction은 사용함으로써 성능을 올릴 수도 있지만, 본 논문에서는 모든 interactions를 0으로 둔다.
    > Adaptive하게 interaction을 포함시키는 것도 가능할 것 같다...?
3. **Prediction**
  - Fig. 4c처럼 $z_1^\prime, z_2$를 사용해 interaction probability $d^\prime = f_{\theta_3}(z^\prime_1, z_2)$를 계산한다.

자세한 과정은 아래의 Algo. 1을 참고하자.

![](5.png)
_Algorithm 1: Inference Pipeline of COR for OOD Generalization._

### 3.3. Fine-tuning for Fast Adaptation

OOD 환경에서 새로운 user interactions가 수집됐을 때 model은 빠르게 적응해야 한다.
핵심 요소는 $e_1$에 영향을 받지 않아, 변경되지 않는 user representation $z_2$를 최대한 재사용 하는 것이다.
따라서 저자들은 $z_2$는 재사용하고 오직 $z_1$만 fine-tune으로 update한다.

VAE의 functions은 causal relationships를 기반으로 한다.
[이전 연구: Towards Causal Representation Learning][5]{:target="_blank"}에서 알 수 있듯이 이러한 기능은 intervention 시 본질적으로 더 안정적이며, IID에서 OOD 환경으로의 parameter의 deviation(편차)를 조정하는 데 더 적은 데이터가 필요하다.

> 즉, VAE가 fast adaptation이라는 뜻이다.

### 3.4. COR with Fine-grained Causal Graph

![](6.png)
_Figure 5: Illustration of fine-grained causal graph and NCM._

저자들은 OOD generalization에 도움이 되는, $e_1, e_2$과 $z_1$ 사이의 더 세분화된 causal graph를 추가적으로 고려했다.
- Fig. 5a 처럼 user의 수입은 size에 대한 선호도보다 price, brand에 대한 선호도에 더 많은 영향을 끼칠 것이다.
- 물론 세분화된 causal graph를 만드려면 전문가의 경험이 필요할 것이다.

저자들은 MLP를 Neural Causal Models (NCM)으로 대체함으로써, 세분화된 causal relationships을 decoder에 반영한다.

저자들은 <span class="text-color-yellow">$z_1$의 factor가 item feature (예: price)에 대한 선호도와 관련있다고(align) 가정한다.</span>
$z_1$의 한 factor에 대해, NCM은 causal graph 기반으로 parents의 representation의 합을 입력으로 받는다.

<span class="text-color-yellow">Item feature에 대한 선호도와 $z_1$간의 관련성(alignment)은 세분화된 causal graph에 기반해 training 동안 implicit하게 학습된다.</span>

NCM에서 MLP의 parameter는 모든 $z_1$의 factors간에 공유된다.
NCM은 다른 구성 요소를 변경하지 않고 COR framework에 삽입될 수 있다.

> 모든 parameter가 공유되면, 중복되는 factor가 많을 수 있지 않나...?  
> Fig. 5b에서 parameter를 공유하면 price와 brand의 평균, 분산 값이 무조건 같게 나올 것 같은데...?  
> Sampling이라서 다른가...? 그렇다면 굳이...?

## 4. Experiments

다음의 research questions에 답하기 위해 실험을 수행하였다.

- RQ1: Baselines과 비교해 OOD generalization에서의 COR 성능은 어떠한가?
- RQ2: Fast adaptation 관점에서 COR의 fine-tuning의 효과는?
- RQ3: Counterfactual inference, 세분화된 causal graph의 효과는?

### 4.1. Experimental Settings

하나의 synthetic(인조, 합성) dataset과 2개의 real-world dataset에 대해 실험을 진행한다.
Rating이 4이상인 interactions를 positive samples로 다룬다.
각 dataset의 IID/OOD를 8:1:1 비율로 training, validation, test sets로 나눈다.
$e_1, e_2$와 $z_1$ 사이의 세분화된 causal graph는 synthetic data에서는 가능하지만, real-world datasets에서는 불가능하다.
3 개의 datasets에 대한 통계량은 아래와 같다.

![](9.png)
_Table 1: Statistics of the three datasets. Note that "int." denotes "interactions"._

<span class="text-color-bold">**Synthetic Data.**</span>

![](7.png)
_Figure 6: Illustration of constructing synthetic data._

Fig. 6의 user interaction generation process에 따라 아래 과정으로 synthetic dataset을 만든다.

![](8.png){: w="500"}
_Algorithm 2: Synthetic Data Construction._

1. User/item feature sampling
: 1000명의 users와 items가 있다고 가정한다. 
  User는 하나의 observed features(수입)와 10개의 unobserved features를 가진다. 
  Item은 8개의 observed features(price, brand, type)와 2개의 unobserved features를 가진다. 
  User/item의 unboserved feature는 standard Gaussian $\mathcal{N}(0,1)$에서 sampling된다.
  User 수입은 $\mathcal{N}(-1,1)$에서 sampling된다.
  Item의 observed feature는 causal 관계에 기반해 Bernoulli에서 sampling된다.
  예를 들어, Apple과 phine은 high price로 이어지기 쉽다.

2. User preference estimation
: Sampling된 user features가 주어지면, user 선호도($z_1, z_2$)를 추정해야 한다.
  User 선호도는 item feature에 대한 선호도를 나타내는 8 dimension과 unknown preference를 나타내는 2 dimension, 총 10 dimension으로 이뤄져 있다.
  User의 선호도를 추정할 때, prior knowledge(사전 지식)을 활용해 feature와 선호도간의 세분화된 causal relationships을 가정한다.
  이러한 causal relationships에는 2 가지 type: positive, negative이 있다.
  예를 들어, 수입이 늘면 high price에 대한 선호도가 증가한다는 것는 positive causal relationship이다.
  이러한 relationship에 따라 positive/negative weight로 user features를 합해 user 선호도를 구한다.
  구해진 선호도에 sigmoid function을 사용해 non-linear complexity를 증가시킨다.
  > Sampling된 수입과 high price는 positive weight를 곱하고 low price는 negative weight를 곱한다.
  > 그럼 수입이 양수면 high price dimension 값은 올라갈 것이고 low price dimension 값은 내려갈 것이다.
  > 수입이 음수면 그 반대이다.  
  > Algo. 2을 살펴보면 이 과정이 Gaussian의 평균을 계산하는 데 반영된다. 수입이 양수이면 high price dimension의 평균값이 높아진다.

3. User interaction sampling
: User preference $z$와 item features $i$을 내적한 뒤 sigmoid function을 사용해 user-item relevance $r$을 구한다.
  그리고 Bernoull 분포 $Bern(r)$로 interaction을 sampling한다.

4. OOD data collection
: OOD 환경에서 user interaction을 수집하기 위해 각 user의 수입 분포를 $\mathcal{N}(-1,1)$에서 $\mathcal{N}(1,1)$로 바꾼다.
  그 후, item features는 고정시킨 채 새로운 step 2, 3을 반복한다.


<span class="text-color-bold">**Meituan(메이퇀).**</span>
User consumption level, food price 등 풍부한 user/item features를 가지는 음식 추천 dataset이다.
저자들은 평일과 주말간 평균 consumption level의 변화를 고려한다.
대부분의 user가 평일 대비 주말의 consumption level이 낮게든 높게든 변한다.
그래서 평일 user interactions를 IID로 고려하고, 주말 user interactions를 OOD로 고려한다.

<span class="text-color-bold">**Yelp(옐프).**</span>
User location을 변경되는 feature로 다룰 수 있는 restaurant 추천 dataset이다.
저자들은 location이 변경되는 users를 선택하고 timestamps 기준으로 정렬한다.
그리고 변경되는 feature에 기반해 두 part로 나누고 각각을 IID, OOD interactions로 사용한다.

<span class="text-color-bold">**Baselines.**</span>
- FM, NFM
: CARS(context-aware recommender system) model로 OOD 환경에서 변경된 user features를 사용할 수 있다.
- MultiVAE
: Causal relationships을 무시한 interaction generation model이다.
  > context 정보는 사용하지 않는 것 같다.
- MacridVAE
: Disentangled 추천 시스템이다.
- MacridVAE + FM
: MacridVAE는 context 정보를 활용하지 않는다.
  그래서 저자들은 re-ranking을 위한 late-fusion 방식으로 MacridVAE와 FM의 예측 점수를 선형 결합한다.
  > 선형 결합이 weighted sum을 의미하는 것 같은데, 여기선 0.1, 0.2, ... , 0.9로 tuning했다고 한다.


<span class="text-color-bold">**Evaluation.**</span>
OOD generalization task에선 OOD 환경에서의 user interactions를 사용할 수 없기 때문에 IID validation으로 models의 hyper-parameter를 tuning한다.
Fast adaptation task에서는 OOD validation으로 tuning한다.

성능 평가로는 Recall@K와 NDCG@k를 사용한다.
이들은 all-ranking protocol로 측정된다.
Synthetic data는 K로 10과 20을 사용하고, Meitunan과 Yelp는 50과 100을 사용한다.
이는 real-world dataset엔 items의 수가 많기 때문이다.

> [All-ranking protocol][6]{:target="_blank"}이란 user와 interaction이 없는 모든 item에서 선택된 상위 K item을 평가하는 것이다.  
> 음... 다른 models는 이렇게 안 하나...?

### 4.2. Overall Performance (RQ1 & RQ2)

![](10.png)
_Table 2: The comparison of OOD generalization performance between the baselines and COR on the three datasets. %improve. represents the relative improvement achieved by COR over the best results of the baselines. The best results are highlighted in bold while the second best ones are underlined._

<span class="text-color-bold">**OOD Generalization.**</span>
Models를 IID interactions으로 training하고 IID, OOD test dataset으로 평가한다.
성능은 table 2에 나와있다.
IID의 성능은 비슷한 양상을 보이기 때문에 Recall@20만 표시한다.
Table 2에서 다음과 같은 사실을 알 수 있다.

> Yelp에서 IID보다 recall 성능이 더 좋은 게 가능한가...? 좀 충격이네. 일반화가 잘 됐나보다.

- IID에서 OOD로 갈 때 성능이 급격히 감소한다.
  이는 OOD 환경에서 distribution이 많이 변하기 때문이다.
  게다가, IID에서는 다른 model의 성능이 비슷하지만 OOD에서는 분산이 크다.
  이것은 추천 model들이 IID 환경에서 비슷한 representation 능력을 가지지만, OOD generalization 능력은 상당히 다르다는 것을 나타냅니다.
- COR은 interaction generation 과정의 causal modeling에 의지하고 post-intervention interaction 확률을 구한다.
  게다가 counterfactual inference로 out-of-date interaction에 영향을 받지 않는다.
  이러한 이유들로 다른 baselines보다 OOD에서 성능이 뛰어나다.
- OOD 환경에서 FM과 NFM은 synthetic data와 Yelp에서 VAE-based 보다 성능이 좋지만 Meituan은 그렇지 않다.
  그 이유로는 feature 변화가 synthetic(featuer: 수입)과 Yelp(feature: 위치)에서는 중요하지만, Meituan(consumption level)에서는 비교적 덜 중요하기 때문이다.
  따라서 주목할만한 feature 변화가 있으면 CARS가 더 낫고 그렇지 않다면 interaction generation 과정을 modeling하는 VAE 계열이 더 낫다.
- MacridVAE는 대부분의 경우, 특히 feature 변화가 큰 OOD test에서, MultiVAE 보다 성능이 더 좋다.
  이 현상은 MacridVAE가 주장하는 'user의 feature가 변화되면 오직 represenations의 일부부만 update되어야 한다'는 learning disentangled representations의 합리성을 정당화한다.
- MacridVAE + FM의 성능을 살펴보면 단순히 다양한 추천 models를 합치는 것은 OOD generalization 능력을 강화하지 않는다는 것을 알 수 있다.

<span class="text-color-bold">**Fast Adaptation.**</span>
Training 동안 OOD validation set과 OOD training data의 일부분을 사용할 수 있다고 가정하자.
IID로 잘 훈련된 models을 OOD training data의 일부분으로 fine-tune하고 OOD validation data로 성능이 가장 높은 model을 선택한다.
COR에서는 $z_2$는 재사용하고 $z_1$과 관련된 VAE parameters를 최적화한다.
OOD training data를 사용하는 비율을 0%에서 30%까지 다양하게 준다.

![](11.jpg)
_Figure 7: Fine-tuning performance of the baselines and COR w.r.t. different proportions of new user interactions collected from the OOD environment. We omit the performance of MacridVAE+FM because it is between the results of MacridVAE and FM._

Fig. 7을 살펴보면 user interactions를 덜 사용해도 OOD 성능이 더 낫다. 특히, sparse한 real-world datasets에서 더 그렇다.
이는 causal modeling과 fast adaptation에서 $z_2$를 재사용하는 것의 효과를 증명한다.

비율이 증가할수록 COR과 다른 models간의, 특히 dense synthetic data에서, 성능 차이가 줄어든다.
왜냐하면 OOD의 user interactions이 더 많아지면, OOD가 점점 새로운 IID 환경이 되기 때문이다.
그리고 IID 환경에서는 table 2와 같이 models의 성능이 유사하다.
그리고 synthetic data는 dense하고 interaction pattern이 더 명확(clear)하기 때문에 더 빠르게 새로운 IID 환경이 된다.

Meituan과 Yelp에서 VAE 계열이 FM 계열보다 성능이 더 빠르게 증가하는데 이는 FM 계열의 embedding이 out-of-date interactions에 더 많은 영향을 받는 user-based 추천 모델이기 때문이다.


### 4.3. In-depth Analysis (RQ3)

<span class="text-color-bold">**Ablation Study.**</span>

![](12.png)
_Table 3: OOD performance of COR with (w/) and without (w/o) counterfactual inference on the three datasets._

- Ablation of Counterfactual Inference
: Counterfactual inference에서 $D=0$ 대신 $D=d$를 사용해 $z_1$을 추정한다.
Table 3을 보면 counterfactual inference를 사용해 out-of-date interactions $d$가 $z_1$에 영향을 끼치지 않도록 하는 게 좋은 것을 알 수 있다.

![](13.png)
_Table 4: Effect of the fine-grained causal graph (FGCG)._

- Ablation of Fine-grained Causal Graph (FGCG)
: FGCG가 없다면 IID, OOD test에서 성능이 모두 떨어진다.
이때, IID에 비해 OOD에서 떨어지는 폭이 더 큰데 이는 OOD generalization에서 causal 관계의 효과를 부분적으로 보여준다고 할 수 있다.
FGCG가 없어도 table 2의 best baseline보다 성능이 더 뛰어나다.
이를 통해 synthetic dataset에서의 성능이 FGCG으로만 기인한 것이 아님을 알 수 있다. 

<span class="text-color-bold">**Case Study.**</span>

Synthetic dataset에 있는 특정 user에 관한 models의 추천 결과를 분석한다.
처음에는 low-income을 가지지만, OOD 환경에서 threshold(2) 보다 큰 수입 증가를 가지는 users 447명을 선택하고 IID/OOD test set에서 그들의 positive item을 수집한다.

![](14.png)
_Figure 8: Visualization of the recommendations changed from IID to OOD environments._

Fig. 8은 FM, MacridVAE, COR로 추천된 top-20 item에 대해 high/low-price 분포를 시각화한 것이다.
IID/OOD test set을 보면 user들이 수입이 증가함에따라 positive item 중 high price items의 비율이 높아진다.
IID에서 FM, MacridVAE, COR 모두 low-price item에 대한 비율이 높기 때문에 IID 환경에서 models들이 잘 동작한다고 볼 수 있다.

하지만, MacridVAE는 변경된 user feature를 반영하지 않기 때문에 OOD에서 MacridVAE는 IID와 같은 비율을 보인다.
그리고 FM은 변경된 user feature를 반영하지만 out-of-date interactions에 영향을 받아 여전히 low-price items를 많이 추천한다.

반면에 COR로 추천되는 high-price item 비율은 ODD test와 같다.
이는 income에 영향을 받지 않는 invariant causal relationships을 capture할뿐만 아니라 out-of-date interactions의 영향을 완화한다는 것을 보여준다.

![](15.png)
_Figure 9: Visualization of user representations varying from IID to OOD environments. Best view in color._

추가적으로 저자들은 t-SNE로 COR의 user/item representations을 시각화한다.
이전에 고른 447명의 users 중 임의로 3명을 골라 시각화한다.
User representation으로 $z_1, z_2$를 사용하고, items representation으로 $f_{\theta_3}(\cdot)$의 마지막 layer의 weight를 사용한다.
- $z_1, z_2 \underset{f_{\theta_3}}{\rightarrow} p(d\|e_1, e_2)$

> 마치 user representation과 inner product된 것과 비슷하다.

Fig. 9를 보면 high/low price가 잘 disentangle되어 있고, OOD 환경에서 user representation이 high-price items 쪽으로 이동하는 것을 알 수 있다.
이는 OOD 환경에서 COR의 성능을 직관적으로 보여준다.

## 5. Related Work

### 5.1. Causal Recommendation

많은 추천 시스템 IID 가정하는데, 아래와 같은 문제점들이 있다.
- training data의 bias를 확대
- unfairness 유도
- filter bubbles 일으킴
- OOD 환경에서의 일반화 능력 감소

이를 완화하기 위해 많은 연구들이 causality를 포함하려고 하였다.
이러한 causal recommender model은 2가지 framework이 있다.
- potential outcome framework
: Explicit, implicit feedback의 debias에 널리 사용된다.
두 가지 대표 기술은 inverse propensity scoring과 doubly roubst이다.

- structural causal models.
: Intervention 또는 counterfactual inference를 활용하고, causal graph를 통해 causal relationships을 면밀히 조사한다.(scrutinize)
이를 통해 debiasing, fairness, explanation을 위한 causal effect를 추정한다.

하지만, 이전 연구들의 causal model은 OOD 추천 문제를 무시하고 있어 OOD 환경에서의 일반화에 약하다.

### 5.2. Disentangled Recommendation

기존의 disentangle은 user-item interaction에 숨어있는 복잡한 factor를 capture하기 위해 factorized user/item representation을 학습한다.
Disentangled representations는 분포 변화에 더 robust하다.

하지만 causuality를 무시하고 interaction data $D$만으로 user의 representation $z_1, z_2$을 학습하기 때문에, anti-causal modeling에 많이 의존한다.
그래서 out-of-date interactions에 영향을 받는다.

### 5.3. Model Adaptation in Recommendation

추천 시스템에서 분포 변화는 흔하게 존재한다.
가장 많이 쓰이는 방법은 model을 re-training하는 것이다.
그렇지만 training time에 사용할 새로운 interactions이 충분하다는 전제가 필요하다.

그래서 cross-domain recommendation이나 cold-start problem에서 적은 data로 adaptation을 향상시키기 위해 model adaption가 제안되었다.
- 대부분 parameter patch, feature transformation, meta learning으로 model adaption을 구현했다.

본 논문은 cross-domain recommendation과 달리 single domain에서의 OOD 추천에 집중하고 있다.
게다가, 오직 부분적으로만 user features와 선호도가 바뀌는데 이는 cold-start 문제와 다르다.

그렇기 때문에 user feature 변화에 따라 추천 모델의 OOD generalization 및 fast adation 능력을 개선하는 방법은 현재까지 아직 개발되지 않았다.

## 6. Conclusion And Futurework

Causal 관점으로 OOD 추천 문제를 formulate했다.
그리고 OOD 추천을 위한 2 가지 objectives(strong OOD generalization, fast adaptation)를 제안한다.
마지막으로 feature에서 interaction으로 이어지는 generation 과정을 조사했고 COR framework를 제안했다.
- Post-intervention inference와 counterfactual inference를 활용해 out-of-date interaction 효과를 완화했다.
- Fast adaptation을 위해 fine-tuning 전략을 적용했다.

Futurework로는 다음과 같다.
- Unobserved user feature의 변화를 반영하기.
- 본 논문에서는 user feature 간의 causal relationship과 서로 다른 user 선호도 간의 관계를 고려하지 않는다.
이런 세분화된 causal relationship을 발견하는 방법은 가치 있다.
- Item feautre를 COR에 통합하는 것은 item categories에 대한 user 선호도를 capture하는데 도움이 될 수 있다.


[1]: https://dl.acm.org/doi/pdf/10.1145/3485447.3512251
[2]: https://github.com/Linxyhaha/COR
[3]: https://c0natus.github.io//posts/vae/##%E2%85%B1-variational-inference
[4]: https://arxiv.org/pdf/1712.05267.pdf
[5]: https://arxiv.org/pdf/2102.11107.pdf
[6]: https://arxiv.org/pdf/2007.01764.pdf