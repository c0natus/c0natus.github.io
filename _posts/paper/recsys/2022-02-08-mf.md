---
title: Matrix Factorization Techniques For Recommender System, (2009)
categories: [Paper, RecSys]
tags: [Matrix Factorization, Collaborative Filtering]
img_path: /assets/img/posts/paper/recsys/mf/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Implementation][2]{:target="_blank"}|

# Abstract

Netfilx Prize competition에서는 matrix factorization models가 **암묵적 피드백(implicit feedback)**, **시간적 효과(temporal effects)** 및 **신뢰 수준(confidence levels)**과 같은 추가 정보의 통합을 허용하기 때문에, 제품을 추천하는 데 있어서 기존의 nearest-neighbor 기술보다 성능이 더 좋다고 말한다.

# Ⅰ. Introduction

좋은 추천 시스템은 또 다른 차원의 사용자 경험(user experience)를 주기 때문에, 아마존이나 넷플리스 같은 e-commerce 선두자들은 추천 시스템을 웹 사이트의 중요한 부분으로 여긴다.

# Ⅱ. Recommender System Strategies

크게 보면, RecSys는 두 개의 전략(content filtering, collaborative filtering) 중 하나에 기반을 두고 있다.

## ⅰ. Content Filtering

Content filtering은 사용자나 상품의 특징을 나타내는 profile을 만든다.

예를 들어, 한 영화의 profile에는 장르, 출연 배우, 흥행 정도 등이 포함될 것이다. **고객의 profile**에는 적절한 설문지에 제공된 인구통계학적 정보(demographic ingormation: 나이, 성별 등)나 답변(answer)가 포함될 수 있다.

Content-based 전략은 수집하기 어려운 외부 정보를 모아야 한다. 

## ⅱ. Collaborative Filtering

Content filtering의 대안으로 명시적(explicit)인 profile이 필요 없지만, 거래 정보나 평점(rating) 등 과거의 사용자 행동이 필요한 collaborative filtering이 있다. 

Collaborative filtering은 **사용자들 간의 관계**와 **사용자와 제품간 상호 의존성**을 분석하여, 사용자가 새롭게 사용할 만한 물건을 알아낸다.

Collaborative filtering의 가장 큰 장점은 domain-free라는 것이다. 즉, 특정한 분야에 대한 지식이 필요하지 않다. Content filtering은 profile을 만들기 위해 domain 지식이 필요하다.

일반적으로 content filtering보다 정확하지만, 새로운 사용자와 아이템을 다루기에 부적합하다는 ***cold star*** 문제를 갖고 있다.

Collaborative filtering에서 중요한 2가지 분야는 neighborhood methods와 latent factor models이다.

- **Neighborhood Methods**

  Neighborhood methods는 항목들(items) 간의 관계에 중점을 두고 있는데, 대신에 사용자 간 관계에 초점을 맞출 수 있다. 전자를 item-oriented approach, 후자를 user-oriented approach라고 한다.

  Item-oriented approach에서는 고객 한 명이 평가한 제품들의 선호도를 바탕으로 다른 제품에 대한 해당 고객의 선호도를 평가한다. 

  고객이 평가한 한 제품의 ‘이웃’ 제품들은 해당 고객에 의해 비슷하게 평점이 매겨질 것이다.

  ![](1.jpg)

  위의 그림은 user-oriented approach를 나타낸다. User-oriented approach에서는 서로의 평점을 보완할 수 있도록, 같은 생각을 가진 사람들을 알아낸다.

- **Latent factor models(잠재 요인 모델)**

  Latent factor는 평점 매기는 패턴에서 추론된 20 ~ 100개의 요인(factor)으로, 항목들과 사용자들을 특징 지어서(characterizing) 평점 매긴 것(rating)을 설명하려는 대안법이다.

  영화의 경우 발견된 요인들은, 코미디 vs 드라마, 액션의 양, 아이들의 성향과 같은 분명한 차원과 등장인물의 성격 발달 과정(chracter development)이나 등장인물의 유별남(character quirkiness)의 깊이 같은 잘 정의되지 않는 차원, 또는 완전히 해석할 수 없는 차원을 측정할 수 있다.

  시청자의 경우, 각 요인은 시청자가 해당되는 영화 요인에서 높은 점수를 받은 영화를 얼마나 좋아하는지를 측정한다. 어떤 의미에서, 그러한 요인들은 앞서 언급한 인간이 만든 profile에 대한 전산화된(computerized) 대안을 구성한다.

  ![](2.jpg)

  위의 그림은 여성 지향적 vs 남성 지향적과 serious vs escapist로 특징 지어지는 가상의 **2차원**을 가지는 **latent factor model**에 대한 간단한 예시이다.

  위 그림은 일부 유명한 영화들과 가상의 시청자들이 2차원에서 어디에 위치해 있는지를 보여준다.

  해당 모델에서 영화의 평균 평점의 관점에서 봤을 때, 그 영화에 대한 한 시청자의 예상 평점은 그래프 상에서 영화와 사용자 위치의 내적과 동일한 것이다. 

  - *Gus*는 *Dumb and Dumber*를 좋아하고(*Gus*와 *Dumb and Dumber*의 내적값이 크다.), *The Color Purple*를 싫어하고, *Braveheart*는 평균이라고 평가할 것이다.
  - *Ocean’s 11*과 *Dave* 같은 일부 영화와 시청자는 상당히 중립적인 것으로 특징지어질 것이다.

# Ⅲ. Matrix Factorization Methods

가장 성공적인 latent factor model 구현 중 일부는 matrix factorization을 기반으로 한다.

Matrix factorization의 기본적인 형태에서, 항목과 사용자는 평점 패턴에서 추론된 요인(factor) vector들에 의해 특징진다. 

항목과 사용자 요인들 사이의 높은 일치는 추천으로 이어진다.

추천 시스템은 서로 다른 형태의 input data에 의존한다.

- input data는 종종 user와 items of interest를 가지는 2차원 행렬로 표현된다.

가장 편한 data는 높은 품질의 ***explicit feedback***이다.

- 한 사용자는 존재하는 모든 항목 중 평점을 매긴 항목의 비율이 작기 때문에 explicit feedback는 sparse matrix로 구성된다.

Matirx factorization의 강점 중 하나는 추가 정보의 통합을 허용한다는 것이다.

- Explicit feedback이 없을 때, 추천시스템은 ***implicit feedback***을 사용해서 사용자의 선호도를 추론할 수 있다.

Implicit feedback은 일반적으로 한 event의 실행 여부를 나타내기 때문에 대부분 densely filled matrix로 표현된다.

# Ⅳ. A Basic Matrix Facotization Model

MF 모델은 사용자와 항목을 모두 $f$ 차원의 공동 잠재 요인 공간에 매핑하고, 그결과 사용자-항목 상호작용을 해당 잠재 요인 공간에 내적을 수행하여 모델링한다.

따라서, 각 항목 $i$는 vector $\boldsymbol{q}_i\in\mathbb{R}^f$와 연관이 있고, 각 사용자 $u$는 vector $\boldsymbol{p}_u\in\mathbb{R}^f$와 연관되어 있다. 주어진 항목 $i$의 경우, vector $\boldsymbol{q}_i$의 원소들은 항목이 positive 또는 negative factor를 얼마나 가지는지를 측정한다. 주어진 사용자 $u$의 경우, vector $\boldsymbol{p}_i$의 원소들은 positive 또는 negative factor가 높은 항목에 대해 얼마나 선호를 가지는지를 측정한다.

내적 결과 $\boldsymbol{q}_{i}^{T}\boldsymbol{p}_u$는 사용자와 항목 사이의 상호작용을 포착한다. 항목의 특징에 대한 사용자의 전반적인 관심을 나타내는 것이다.  

이것은 $r_{ui}$로 표시된 항목 $i$에 대한 사용자 $u$의 등급을 근사한 것으로 아래와 같이 추정할 수 있다.


$$
\begin{align}
\hat{r}_{ui} = \boldsymbol{q}_i^T\boldsymbol{p}_u
\end{align}
$$

주요 과제는 각 항목과 사용자를 요인 vector $\boldsymbol{q}_i\boldsymbol{p}_u \in \mathbb{R}^f$로 매핑하는 것이다. 추천 시스템이 매핑을 완료한 후, 수식 (1)을 사용해 사용자가 어떤 항목에 매길 등급을 쉽게 추정할 수 있다. 이러한 모델은 특이값 분해(SVD, Singular Value Decomposition)와 밀접하게 관련이 있다. SVD는 정보 검색에서 잠재 의미 요인(latent semantic factors)을 식별하는 잘 구축된 기법이다.

Collaborativ filtering 도메인에 SVD를 적용하려면, 사용자-항목 rating matrix를 factoring해야 한다. 사용자-항목 rating matrix의 sparseness로 인한 높은 결측치 비율로 인해, factoring하는 것이 어렵다. 전통적인 SVD는 행렬에 대한 knowledge가 불완전할 때 정의되지 않는다. 

게다가, 상대적으로 알려진 갯수가 적은 entry만을 부주의하게 다루는 것은 과적합되기 굉장히 쉽다. 이전 시스템은 누락된 평점을 채우고 rating matirix를 밀도(dense)있게 만드는 imputation에 의존했다. 하지만, imputation(결측값 대체)은 데이터의 양을 상당히 증가시켜 비용이 굉장히 많이 들 수 있고, 정확하지 않은 imputation은 데이터를 상당히 왜곡시킬 수 있다.

따라서, 최근 연구들은 정규화된 모델을 통해 과적합을 피하면서, 관찰된 등급만 직접 modeling하는 것을 제안한다. Latent vectors $\boldsymbol{p}_u, \boldsymbol{q}_i$를 학습하기 위해, 이 시스템은 알고 있는 평점 집합에서 regularized 제곱 오류를 최소화한다. 

$$
\begin{align}
\underset{q*,p*}{min}\sum\limits_{(u,i)\in\mathcal{K}}(r_{ui} - \boldsymbol{q}_i^T\boldsymbol{p}_u)^2 + \lambda(||\boldsymbol{q}_i||^2+||\boldsymbol{p}_u||^2)
\end{align}
$$

- $\mathcal{K}$는 $r_{ui}$로 알려진 $(u, i)$ 집합 (training set)이다.

이 시스템은 이전에 관찰된 등급을 적합하여(fitting) 모델을 학습한다. 하지만, 목표는 이러한 이전 평점을 미래 즉, 알지 못하는 등급을 예측하는 방식으로 일반화하는 것이다.

따라서, 이 시스템은 규모(magnitude)에 패널티를 준 학습된 파라미터를 정규화하여 관찰된 데이터에 과적합 되지 않도록 해야 한다.

상수 $\lambda$는 정규화 정도를 조절하며, 보통 교차 검증(Cross-Validation)으로 결정된다.

- Ruslan Salakhutdinov와 Andriy Mnih가 쓴 [Probabilistic Matrix Factorization][3]{:target="_blank"}는 정규화를 위한 확률론적 기초 지식을 제공한다.

# Ⅴ. Learning Algorithms

식 2를 최소화 하는 방법으로 *stochastic gradient descent*와 *alternating least squares*가 있다.

## ⅰ. Stochastic gradient descent

각 training case에 관해 $r_{ui}$를 예측하고 error를 계산한다. 그리고 gradient(식 2를 $\boldsymbol{p}$와 $\boldsymbol{q}$에 관해 미분)의 반대 방향으로 $\gamma$에 비례하는 크기만큼 parameter를 수정한다.

$$
\begin{align*}
e_{ui} &\overset{def}{=} r_{ui}-\boldsymbol{q}_i^T\boldsymbol{p}_u \\
\boldsymbol{q}_i &\leftarrow \boldsymbol{q}_i+\gamma \cdot(e_{ui} \cdot \boldsymbol{p}_u-\lambda\cdot \boldsymbol{q}_i) \\
\boldsymbol{p}_u &\leftarrow \boldsymbol{p}_u+\gamma \cdot(e_{ui} \cdot \boldsymbol{q}_i-\lambda\cdot \boldsymbol{p}_u)
\end{align*}

$$

## ⅱ. Alternating least squares

식 2는 미지수가 2개이므로 convex하지 않다. 만약 2개의 미지수 중 하나를 고정시킨다면 최적화 문제는 quadratic이되고 optimally하게 해결될 수 있다.

ALS는 기법은 $\boldsymbol{p}_u$와 $\boldsymbol{q}_i$를 번갈아 고정한다.

- $\boldsymbol{p}_u$가 모두 고정이 되면, 시스템은 least-squares 문제를 해결함으로써 $\boldsymbol{q}_i$를 계산한다. 그 반대도 마찬가지다. 이는 식 2를 단계별로 감소시켜 수렴을 보장한다.

일반적으로 SGD가 ALS보다 구현이 쉽고 빠르지만, 2가지 상황에서는 ALS가 유리하다.

1. 병렬화를 사용할 수 있는 경우
    - ALS는 각 $\boldsymbol{p}_u$를 다른 user의 factor와 독립적으로 계산하고, 각 $\boldsymbol{q}_i$를 다른 item의 factor와 독립적으로 계산한다.
    - 이는 ALS의 대규모 병렬화를 제공한다.
2. Implicit data를 중심으로한 경우
    - Training set이 sparse하다고 생각될 수 없기 때문에, gradient descent처럼 각 single training case를 looping하는 것은 실용적이지 않다.
    - ALS는 implicit data인 경우를 효과적으로 다룬다.

# Ⅵ. Adding Biases

Collaborative filtering를 위한 matrix factorization의 장점 중 하나는, 다양한 데이터 측면 및 기타 애플리케이션별 요구사항을 유연하게 다룰 수 있는 것이다. 이는 동일한 학습 framework 내에서 식 1에 맞춰져야 한다는 것을 말한다.

식 1은 다른 rating 값을 가지는 user들과 item들 사이에서 interaction을 포착하려고 노력한다. 그러나  대부분의 rating value의 변동은 interaction과 무관한 *biases* 또는 *intercepts*라고 알려진, user 또는 item과 관련된 효과 때문이다.

- 예1) 몇몇 user들이 다른 user들보다 평균적으로 더 높은 rating을 부여하는 성향
- 예2) 몇몇 item들이 다른 item들보다 평균적으로 더 높은 rating을 받는 성향

따라서 모든 rating을 $\boldsymbol{q}_i^T\boldsymbol{p}_u$의 형태의 interaction으로 설명하는 것은 현명하지 않다. 

대신, data의 ture interaction 부분만 factor modeling에 적용하려면, user 또는 item들이 개별적으로 가지는 biases를 설명할 수 있는 변수들의 일부분(portion)을 식별해야 한다.

 Rating $r_{ui}$와 관련된 bias의 1차 근사식(first-order approximation)은 다음과 같다.

$$
\begin{align}
b_{ui} = \mu + b_i + b_u
\end{align}
$$

- $b_{ui}$: $r_{ui}$와 관련된 bias이고, user와 item의 영향
- $\mu$: 전체 평균 등급
- $b_u$: 관측된 user $u$의 평균으로부터의 편차.
- $b_i$: 관측된 item $i$의 평균으로부터의 편차.
- 예를 들어, Joe가 *Titanic*에 부여할 평점의 1차 추정(first-order estimate)를 한다고 가정하자.
    
    전체 영화의 평균 $\mu$가 3.7이고, *Titanic*이 일반적인 영화보다 더 재밌어 평균적으로 평점을 0.5 더 받는 경향이 있다. 반면에, Joe가 비판적인 user라 평균적으로 평점을 0.3 더 낮게 준다고 가정하자.
    
    즉, $\mu = 3.7, b_i = 0.5, b_u = -0.3$이므로, Joe가 부여할 *Titanic* 평점의 first-order estimate는 3.9(3.7+0.5-0.3)이다.
    

Biases를 고려한 수식 1은 다음과 같다.

$$
\begin{align}
\hat{r}=\mu+b_i+b_u+\boldsymbol{q}_i^T\boldsymbol{p}_u
\end{align}
$$

관찰된 평점이 4가지 부분으로 나뉘고, 이들은 자신과 관련된 signal 부분만 설명할 수 있다.

- global averge($\mu$), item bias($b_i$), user bias($b_u)$, user-item iteraction($q_i^Tp_u)$

손실 함수는 다음과 같다.

$$
\begin{align}
\underset{p*, q*, b*}{min}
\sum\limits_{(u,i) \in \mathcal{K}}
(r_{ui}-\mu-b_u-b_i-\boldsymbol{q}_i^T\boldsymbol{p}_u)^2
+\lambda(||\boldsymbol{p}_u||^2+||\boldsymbol{q}_i||^2+b_u^2+b_i^2)
\end{align}
$$

Bias는 관측된 signal의 많은 부분을 포착하는 경향이 있기 때문에 정확한 모델링이 필수적이다. 따라서, 다른 연구들은 더 정교한 편향 모델을 제공한다.

# Ⅶ. Additional Input Sources

추천 시스템은 일반적은 결론에 도달하는 것을 방해하는 cold start 문제를 다뤄야 한다. 이 문제를 완화하기 위해선 user 또는 item에 관한 추가적인 정보를 통합하는 것이다.

## ⅰ. Implicit Feedback

추천 시스템은 user 선호도에 대한 insight를 얻기 위해, user의 검색 또는 구매 이력 등의 implicit feedback을 활용할 수 있다. 

단순하게, Boolean implicit feedback이라 하고, user를 profiling해보자.

- $N(u)$를 user $u$가 implicit 선호도를 표현한 items의 집합이라고 하고, item $i$와 관련된 factor를 $x_i \in \mathbb{R}^f$라 하자.
- 그러면 user $u$는 자신이 표현한 implicit 선호도인 $N(u)$를 통해 $\sum\limits_{i\in N(u)}x_i$과 같은 벡터 표현될 수 있다.
- $\|N(u)\|^{-0.5}\sum\limits_{i\in N(u)}x_i^{4.5}$과 같이 합을 normalizing하는 것은 종종 도움이 된다.

## ⅱ. User Attributes

다른 추가적인 정보로는 demographics(성별, 나이, 지역, 수입 수준 등)같은 user 속성이 있다. 

Implicit feedback과 마찬가지로 Boolean attribute라 해자.

- $A(u)$를 user $u$와 연관된 attribute이고, attribute $a$와 관련된 factor를 $y_a\in \mathbb{R}^f$라 하자.
- 그러면 user $u$는 $A(u)$와 $y_a$로 $\sum\limits_{a\in A(u)}y^a$와 같이 묘사될 수 있다.

Matrix factorization model은 모든 signal source를 활용해 다음과 같이 user 표현력을 높여야 한다.

$$
\begin{align}
\hat{r}=\mu+b_i+b_u+\boldsymbol{q}_i^T
[ \boldsymbol{p}_u + 
|N(u)|^{-0.5}\sum\limits_{i\in N(u)}x_i^{4.5} +
\sum\limits_{a\in A(u)}y^a ]
\end{align}
$$

Item의 표현력을 높이기 위해 같은 방법을 사용할 수 있다.

# Ⅷ. Temporal Dynamics

지금까지의 모델은 정적이었다. 하지만, 현실에서는 새로운 선택이 나타나면 item의 인식과 인기가 변하고 user의 경향 또한 진화해 그들의 취향(taste)을 재정의해야 한다.

따라서 추천 시스템은 user-item interactions의 동적이고 시간에 따라 변화하는(time-drifting) 속성을 반영하는 시간적 영향(temporal effects)를 설명해야 한다. MF는 정확도를 올릴 수 있는 이러한 시간적 영향을 잘 나타낼 수 있다.

식(4)처럼 rating을 별개의 terms로 분해하는 것은 시간적 양상을 분리해서 다룰 수 있게 해준다. 구체적으로 item의 편차 $b_i(t)$, user의 편차 $b_u(t)$, user의 선호도 $\boldsymbol{p}_u(t)$가 시간에 따라 달라진다. 

- 예로 들어, 탑건 2 개봉으로 탑건 1의 평점이 높아지거나: $b_i(t)$,  user가 영화를 많이 볼수록 평균 평점이 내려가거나: $b_u(t)$, user의 선호도 장르가 변하는: $\boldsymbol{p}_u(t)$ 등이 있다.

반면, 사람과 다르게 item은 정적이기 때문에 $\boldsymbol{q}_i$로 표기한다.

이러한 시간적 영향을 식 4에 반영하면 다음과 같아진다.

$$
\begin{align}
\hat{r}(t)=\mu+b_i(t)+b_u(t)+\boldsymbol{q}_i^T\boldsymbol{p}_u(t)
\end{align}
$$

# Ⅸ. Inputs With Varying Confidence Levels

관찰된 모든 rating이 같은 가중치 또는 신뢰도를 갖지 않는다. 예를 들어, 광고는 특정 item에 영향을 줄 수 있지만 장지적인 특성을 적절히 반영하지 못한다. 유사하게 특정 items에 편파적인 rating을 하려는 악성 user가 있을 수도 있다. 그리고 implicit feedback 같은 경우 user의 정확한 선호도 수준을 수치화하기 어렵다. 따라서 ‘상품을 좋아할 것 같다’ 또는 ‘상품에 관심이 없을 것 같다’를 나타내는 cruder binary 표현을 같이 사용한다.

$$
\begin{align}
\underset{p*, q*, b*}{min}
\sum\limits_{(u,i) \in \mathcal{K}}
c_{ui}(r_{ui}-\mu-b_u-b_i-\boldsymbol{q}_i^T\boldsymbol{p}_u)^2
+\lambda(||\boldsymbol{p}_u||^2+||\boldsymbol{q}_i||^2+b_u^2+b_i^2)
\end{align}
$$

식 8은 식 5에 추정된 선호도의 신뢰 점수($c_{ui}$)를 부여한 것으로, Matrix factorization 모델은 다양한 신뢰 수준을 쉽게 수용할 수 있다.

신뢰 점수는 동작의 빈도수를 설명하는 수치적인 값에서 비롯될 수 있다. user의 선호도와 관련없는 다양한 factors는 일회성 event을 유발할 수 있지만, 반복적인 사건은 user의 의견을 반영할 가능성이 더 높다. 예로 들어, user가 특성 item을 자주 소비한다면 신뢰 값은 높을 것이다.

# Ⅹ. Netflix Prize Competition

![](3.jpg)

위 그림은 matrix를 분해 했을 때 중요한 factor 2개를 선택해 시각화 한 것이다. Factor vector 1은 영화 남성향 여성향을 나타내는 것으로 낮을수록 저속한 코미디 및 공포 영화이고 높을수록 진지한 톤의 드라마 및 코디이 영화이다. Factor vector 2는 영화의 독창성을 나타낸 것으로 높을수록 기발하고, 접해보지 못한 영화이고 낮을수록 정형화된 영화이다.

물론 근처에 있으면 안되는 영화: *Annie Hall*과 *Citizen Kane*도 있지만, 차원을 하나 더 추가하면 멀리 떨어진다.

![](4.jpg)

Figure 4는 앞에서 살펴본 방법론을 추가하면서 달라진 RMSE를 보여준다.

# Ⅺ. Conclusion

Matrix factorization 기법은 callaborative filtering 추천 내에서 지배적인 방법론이 되었다. Netflix Prize data 같은 datasets은 MF 기법이 전통적인 NN 기법보다 뛰어난 정확도를 제공한다는 것을 보였다. 동시에 compact한 메모리-효율적인 모델이므로 학습이 상대적으로 쉽다. 이러한 기법을 더 편리하게 만들어 주는 것은 모델이 자연스럽게 데이터의 중요한 측면인 implicit feedback, temporal dynamics, confidence level 등을 통합할 수 있기 때문이다. 


[1]: https://ieeexplore.ieee.org/document/5197422
[2]: https://github.com/c0natus/Paper-review-implements/tree/main/RecSys/MF%2C%20ALS
[3]: https://proceedings.neurips.cc/paper/2007/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf