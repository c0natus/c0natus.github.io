---
title: "Controllable Multi-Interest Framework for Recommendation, (KDD'20)"
categories: [Paper, RecSys]
tags: [Sequential Recommendations, Diversity, Control]
img_path: /assets/img/posts/paper/recsys/comirec/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

## Abstract

Sequential recommendations (SRs)에서 user의 multiple interests를 capture하여 accuracy와 diversity를 control할 수 있는 re-rank 추천 framework를 제안한다.

> 해당 논문은 Alibaba에서 publish한 applied data science (ADs) track paper이다.

Challenges
: SRs에서 user의 behavior sequence로 만든 unified user embedding을 만든다.
Unified user embedding은 behavior에 나타난 user의 multiple interests를 반영하지 못한다.

Address
: - Multi-interest module로 multiple interests를 고려해 candidate items를 생성한다.
- Aggregation module로 accuracy와 diversity의 균형을 control한다.

Contribution
: - Controllability와 multi-interest components를 통합한 framwork를 제안한다.
- Online 추천 상황에서 controllability의 역할을 보여준다.

## 1. Introduction

E-commerce에는 large-scale users와 items이 존재하기 때문에 deep neural network를 사용한 model이 CTR을 예측하기 위해 바로 사용되기 어렵다.
현재 industry에서는 KNN(e.g., Faiss)로 candidate를 생성하고, deep model (e.g., xDeepFM)으로 candidate items에 대한 CTR을 예측한다.

![](1.png)

대부분의 SRs는 user의 과거 interactions sequence로 unified user embedding을 학습한다.
Unified user embedding은 user가 interaction에서 보여준 multiple interests를 충분히 표현하지 못한다.
예를 들어, Fig. 1을 보면 click sequence는 Emma의 서로 다른 3가지 interests를 보여준다.
- Jewelry, handbags, make-ups

저자들은 SRs에서 controllable multi-interest framework인 ComiRec (<span class="text-color-blue">co</span>ntrollable <span class="text-color-blue">m</span>ulti-<span class="text-color-blue">i</span>nterest framework for the sequential <span class="text-color-blue">rec</span>ommendation)을 제안한다.
- Multi-interest module는 user의 multiple interests를 capture하고 candidate items retrieval에 활용된다.
- Aggregation module은 candidate items에 대한 ranking을 매긴다.

전체적인 flow는 다음과 같다.
1. User가 관심이 많은 categories를 파악한다.
2. 각 category에 부합하는 items를 k개 선택해서 candidate items를 생성한다.
3. Candidate items 안에서 accuracy와 diversity를 고려해 추천 list를 만든다.

## 2. Related work

중략

## 3. Methodology

![](3.png)

### 3.1. Problem Formulation

![](2.png)

Latency와 performance 등의 이유로 industry의 추천 시스템은 2가지 stage: matching and ranking로 이뤄져 있다.
Matching stage는 top-N candidate items을 검색하고, ranking state에서는 candiate items을 좀 더 정교한 scores로 sorting한다.

본 논문에서는 matching state의 effectiveness를 향상 시키는데 집중한다.

### 3.2. Multi-Interest Framework

Industry에서는 수백만 개의 item pools이 있기 때문에 matching stage가 중요하다.
Matching stage에서는 user historical behaviors로 user embedding을 계산하고, Faiss로 user embedding에 가까운 candidate item을 선택한다.
그렇기 때문에 user embedding quality가 matching stage에서 중요하다.

기존의 연구에서는 RNN으로 user embedding을 얻는다.
하지만, 이는 unified user embedding(즉, entangled embedding)으로 user의 multiple interests를 표현하지 못한다.

본 논문에서는 multi-interest extraction module로 user의 multiple interests를 생성한다.
Multi-interest extraction module의 방법론으로 다양한 것이 있고, 저자들은 dynamic routing method와 self-attentive method를 활용한다.
전자를 ComiRec-DR, 후자를 ComiRec-SA라고 한다.

#### ComiRec-DR

CapsNet을 활용해 user multi-interest를 파악한다.

(Capsule network를 모르기 때문에 자세한 것은 논문 참고.)

#### ComiRec-SA

User의 behaviros embedding matrix $H \in \mathbb{R}^{d \times n}$이 주어졌을 때, self-attention mechanism으로 weight vector $a \in \mathbb{R}^n$을 얻을 수 있다.

- n: user sequence 길이
- d: item embedding dimension.

$$
a = \text{softmax}(w^\top_2\text{ tanh }(W_1H))^\top
$$

- $w_2 \in \mathbb{R}^{d_a}$
- $W_1 \in \mathbb{R}^{d_a \times d}$

해당 weight를 통해 user representation $v_u = Ha \in \mathbb{R}^d$를 얻을 수 있다.
그리고 d dimension의 trainable positional embedding을 각 item embedding에 더해서 user sequences의 순서를 고려한다.

Head 하나가 user interest 1개를 capture한다고 생각하면, K개의 multi-haed attention을 이용해 multi-interest K개를 파악할 수 있다.

$$
\begin{split}
&A &= \text{softmax}(W^\top_2\text{ tanh }(W_1H))^\top &\\
&V_u &= HA &
\end{split}
$$

- $W_2 \in \mathbb{R}^{d_a \times K}$
- $A \in \mathbb{R}^{n \times K}$
- $V_u \in \mathbb{R}^{d \times K}$

#### Model Training

Interest embeddings $V_u$를 계산한 다음, target item $i$에 해당하는 user interest는 내적값이 가장 큰 것이다.

$$
\text{v}_u = \text{V}_u[:\text{argmax}(\text{V}^\top_u\text{e}_i)]
$$

그리고 user interest embedding $v_u$와 item embedding $e_i$를 내적한 값에 softmax를 적용해 likelihood를 계산한다.

$$
P_\theta(i|u) = \frac{\text{exp}(v_u^\top e_i)}{\sum_{j\in\mathcal{I}}\text{exp}(v_u^\top e_j)}
$$

위의 식을 모든 item에 대해 계산하는 것은 오래걸리므로 sampled softmax를 활용한다.
그리고 objective function으로는 negative log-likelihood를 최소화하는 것으로 설정한다.

$$
loss = \sum_{u\in\mathcal{U}}\sum_{i\in\mathcal{I}_u} - \text{ log }P_\theta(i|u)
$$

#### Online Serving

학습된 multi-interest extraction module로 user의 과거 interaction sequence가 주어졌을 때, user의 multiple interests를 계산한다.
그 다음 multiple interests로 생성된 candidate items를 aggregation module의 입력으로 주고, 높은 점수를 받은 items를 추천해준다.

### 3.3. Aggregation Module

Multiple interest embeddings이 주어지면, 각 interest embedding마다 내적값으로 top-N items를 검색한다.
그결과 총 $K \times N$개의 candidate items이 생성된다.

Candidate items이 생성되었으니, N개의 items를 user에게 추천해줘야 한다.
가장 naive한 방법은 내적값이 큰 items를 추천해주는 것이다.

$$
f(u,i) = \underset{1\le k \le K}{\text{max}}(e_i^\top v_u^{(k)})
$$

- $v_u^{(k)}$: $k$-th interest embedding of the user $u$

해당 방법은 추천 시스템의 accuracy를 위해선 좋은 선택이지만, diversity를 고려한 방법이 아니다.

저자들은 diversity도 고려하기 위해 미리 정의된 함수를 최대화하는 item set $\mathcal{S}$를 찾아야 한다.

$$
\mathcal{Q}(u, \mathcal{S}) = \sum_{i \in \mathcal{S}}f(u,i) + \lambda \sum_{i\in\mathcal{S}}\sum_{j\in\mathcal{S}}g(i,j)
$$

- $f(\cdot)$ : 내적값, accuracy와 관련있다.
- $g(\cdot)$ : diversity function
- $\lambda$ : controllable hyper-parameter, 값이 클수록 추천 결과가 diverse해진다.

$g(i,j) = \delta(\text{CATE}(i)\neq\text{CATE}(j))$로 정의된다.
$\text{CATE}(i)$는 item $i$의 category를 의미하고, $\delta(\cdot)$은 indicator function을 의미한다.

![](4.png)

$\mathcal{Q}(\cdot)$을 구하는 것은 np-hard problem이기 때문에 위의 algorithm처럼 greedy inference로 set $\mathcal{S}$를 구한다.

## 4. Experiments

자세한 실험은 논문을 참고하자.

![](5.png)

$K = 4, \lambda = 0$으로 설정한 뒤, 다른 model과 metric을 비교하였다.

![](6.png)

$\lambda$를 조절하며, accuracy-diversity를 control할 수 있다.
Diversity는 아래와 같이 평가된다.

$$
\text{Diversity@N} = \frac{\sum_{j=1}^N\sum_{k=j+1}^N \delta(\text{CATE}(\hat{i}_{u,j})\neq\text{CATE}(\hat{i}_{u,k}))}{N \times (N-1)/2}
$$

평가 방식을 보면 당연히 $\lambda$가 커질수록 diversity가 올라갈 것이다.

> 추천 성능이 내려가는 것은 user의 multiple interest에도 좋음의 정도 차이가 존재하기 때문이 아닐까?  
> 이것을 고려하는 것이 calibration인가??


[1]: https://arxiv.org/pdf/2005.09347.pdf
[2]: https://github.com/THUDM/ComiRec