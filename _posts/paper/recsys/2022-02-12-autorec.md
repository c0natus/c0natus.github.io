---
title: "AutoRec: Autoencoders Meet Collaborative Filtering, (WWW'15)"
categories: [Paper, RecSys]
tags: [Autoencoder, Collaborative Filtering]
img_path: /assets/img/posts/paper/recsys/autorec/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Implementation][2]{:target="_blank"}|

# Abstract

해당 논문에서는 CF(Collaborative filtering)을 위한 새로운 autoencoder 프레임워크인 `AutoRec`을 제안한다.  
경험적으로, AutoRec은 Movielens와 Netfilx 데이터 셋에서 사용한 최신의 CF model(biased matrix factorization, RBM-CF, LLORMA)을 뛰어넘는 <span class='text-color-yellow'>작고(compact), 효율적으로 훈련가능</span>한 모델이다.

# Ⅰ. Introuction

CF model은 개인화된 추천을 제공하기 위해, 항목(item)에 대한 사용자의 선호 정보를 탐색하는 것을 목표로 한다. Netflix challenge 덕분에, 다양한 CF 모델이 제안되었고 주로 matrix factorization과 neighborhood models을 선택하였다.  
해당 논문에서는 최근 vision과 speech tasks에서 성공적인 결과를 낸 NN model의 autoencoder 패러다임에 기반을 둔 새로운 CF 모델인 AutoRec을 제안한다. AutoRec은 기존의 CF를 위한 NN model보다 <span class="text-color-yellow">표현력과 연산적인 측면에서 이점</span>을 가진다.

# Ⅱ. The AutoRec Model

평점(ratings)에 기반을 두는 CF에는 m 명의 사용자, n 개의 아이템 그리고 m x n user-item rating matrix가 있다.
- **각 사용자** $u \in U = \{1, \cdots, m\}$는 부분적(partially)으로 관찰된 vector $r^{(u)} = (R_{u1}, \cdots , R_{un}) \in \mathbb{R}^n$로 표현될 수 있다.
- 유사하게 **각 항목** $i \in I = \{1, \cdots, n\}$은 부분적으로 관찰된 vector $r^{(i)} = (R_{1i}, \cdots , R_{mi}) \in \mathbb{R}^m$으로 표현될 수 있다.

해당 논문에서는 item-based 또는 user-based autoencoder를 설계하는 것을 목표로 한다.
AutoRec은 부분적으로 관찰된 vector $r^{(i)}(\text{or}\ \ r^{(u)})$를 입력으로 받고, 그것을 저차원의 latent(hidden) space로 투영(project)한다. 그리고 투영된 vector를 output space에서 $r^{(i)}(\text{or}\ \ r^{(u)})$로 복원(reconstruct)한다.  복원을 통해 추천을 목적으로 어떤 항목에 대한 평점을 예측할 수 있다.
일반적으로 autoencoder는 다음 수식을 만족한다.

$$
\underset{\theta}{min}\sum\limits_{r\in S}||r-h(r;\theta)||^2_2, \ \ \ \ S \in \mathbb{R}^d \ \text{and} \ k \in \mathbb{N}_+
$$

## ⅰ.  I-AutoRec(Item-based AutoRec)

![](1.jpg)
_Figure 1: Item-based AutoRec model. We use plate notation to indicate that there are n copies of the neural network (one for each item), where $\boldsymbol{W}$ and $\boldsymbol{V}$ are tied across all copies._

위 그림은 n개의 항목에 적용되는 NN 모델을 plate notation 기법으로 나타냈다. 즉, 모든 항목에 대해 동일한 구조가 사용되고 동일한 weight와 bias가 사용된다. 이를 수식으로 나타내면 아래와 같다.

$$
h(r;\theta) = f(W \cdot g(Vr + \mu) + b)
$$

- $h(r;\theta)$는 input $r \in \mathbb{R}^d$의 *복원(reconstruction)*이다.  
- $\theta = \{W, V, \mu, b\}$는 model의 parameter이다.
- $f$와 $g$는 활성함수이다.
- $W \in \mathbb{R}^{d \times k}, \ V \in \mathbb{R}^{k \times d}$는 각각 encoder와 decoder의 weight, $\mu \in \mathbb{R}^k, \ b \in \mathbb{R}^d$는 각각 encoder와 decoder의 bias이다.

해당 구조는 a single, *k*-dimensional hidden layer를 가지는 auto-associative NN과 유사하다. Parameter $\theta$는 역전파를 사용해 학습된다.

I-AutoRec model은 하나의 항목의 vector ($\in \{r^{(i)}\}^n_{i=1}$)에  autoencoder를 적용하는데, 역전파하는 과정에서 **2가지 중요한 것**이 있다.
1. Matrix factorization과 RBM 방법론과 유사하게, 각 $r^{(i)}$는 역전파하는 동안 <span class="text-color-yellow">관측된 입력과 관련된 weight만</span> 업데이트 함으로써 부분적으로 관측된다.
2. 관찰된 평점에 대한 과도한 피팅을 방지하기 위해 학습된 매개 변수를 <span class="text-color-yellow">정규화</span>한다.

$$
\underset{\theta}{min}\sum\limits_{i=1}^n||r^{(i)} - h(r^{(i)};\theta)||^2_O + \frac{\lambda}{2}\cdot(||W||^2_F + ||V||^2_F)
$$

일반적으로, I-AutoRec의 목적 함수는 위의 수식과 같이 표현된다.
- $\lambda$는 정규화를 얼마나 할지 결정하는 regularization rate이다.
- $\|\|\cdot\|\|_O$는  관측된 평점의 기여(contribution)만 고려한 RMSE를 의미한다. 
- $\|\|\cdot\|\|_F$는 frobenius norm을 의미한다.

I-AutoRec이 학습해야할 parameter 수는 $2mk + m + k$이다. Encoder, decoder가 각각 mk개의 embedding parameter를 갖고, bias를 위해 m, k개의 parameter가 필요하다. <span class="text-color-yellow">기존의 협업필터링에 비하여 굉장히 적은 파라미터가 필요함</span>을 알 수 있다.
- U-AutoRec(User_based AutoRec)도 I-AutoRec과 유사하지만, $\{r^{(i)}\}^n_{i=1}$ 대신 $\{r^{(u)}\}^m_{u=1}$에 대해서 작동한다.

학습된 parameter $\hat{\theta}$가 주어지면, I-AutoRec은 user u에 대한 item i의 평점을 다음과 같이 예측한다.

$$
\hat{R}_{ui} = (h(r^{(i)};\hat{\theta}))_u
$$

Figure 1에서 회색 node는 관측된 평점을 의미하고 실선은 input $r^{(i)}$를 업데이트할 때 영향을 받는다는 것을 의미한다.  
AutoRec은 기존의 CF 방법론들과 구별된다. RBM-CF(RBM-based CF model)과 AutoRec을 비교했을 때, 몇가지의 차이점이 있다.
1. RBM-CF는 제한된 Boltzmann machine에 기반한 **generative, probailistic model**이다.
AutoRec은 autoencodr에 기반한 **discriminative model**이다.
2. RBM-CF는 **log likelihood**를 최대화 하면서 parameter를 학습한다.
AutoRec은 평점 예측의 표준(canonical) 성능인 **RMSE**를 직접 최소화한다.
3. RBM-CF를 훈련하려면 **contrastive divergence**를 사용해야 한다.
AutoRec을 훈련하려면 비교적 빠른 **gradient 기반 역전파**가 필요하다.
4. RBM-CF는 오직 **이산적 평점**에만 적용할 수 있다. 그리고 각 평점 값에 대해 별도의 parameter 세트를 추정한다.
5. $r$개의 관측된 평점이 있을 때, user- (item-) based RBM-CF은 $nkr \ (mkr)$ parameter가 필요하다. AutoRec은 $r$에대해 불가지론(agnostic)하기 때문에 더 적은 parameter가 필요하다. 적은 수의 parameter는 메모리 공간을 덜 차지하고 overfitting되는 경향이 적다는 장점이 있다.  
→ parameter의 수와 overfitting의 관계는 생각해봐야한다. ex) GPT-3

MF(matrix factorization)과 AutoRec을 비교해보자.
- MF는 사용자와 항목을 공유된 latent space로 embed하는 방법론이다. I-AutoRec은 오직 항목만 latent space로 embed한다.
- MF는 선형 잠재 표현(linear latent representation)이다. AutoRec은 활성함수 $g$를 활용하는 비선형 잠재 표현(nonlinear latent representation)이다.

# Ⅲ. EXPERIMENTAL EVALUATION

Movielens 1M, 10M 그리고 Netflix 데이터 셋에 대해 AutoRec과 RBM-CF, Biased MF, LLORMA(Local Low-Rank Matrix Factorization)을 비교하자.  
Train과 test set을 랜덤하게 9:1 비율로 나눴고, train의 10%는 hyperparameter tuning에 사용한다. 이러한 데이터 분할을 5번 반복하고, 신뢰도 95%인, 오차 범위 $\pm 0.003$ 이내의  RMSE의 평균을 구하였다.  
Hyperparameter의 범위는 다음과 같다.
- $\lambda \in \{0.001, 0.01, 0.1, 1, 100, 1000 \}$
- latent dimension $k \in \{10, 20, 40, 80, 100, 200, 300, 400, 500\}$

Autoencoder의 목적함수를 최적화하는 데 있어서 어려운 점은 해당 함수가 non-convexity라는 것이다. 그렇기 때문에 L-BFGS와 성능이 비슷하지만 더 빠른 RProp(resilient propagation)을 사용했다.

## ⅰ. Which is better, item- or user-based autoencoding with RBMs or AutoRec?

![](2.jpg)
_Comparison of the RMSE of I/U-AutoRec and RBM models_

위의 표는 Item 기반이 RBM과 AutoRec에서 User 기반보다 더 좋은 성능을  낸다고 말해준다.
- 항목당 관측되는 평점의 평균 수(the average number of ratings per item)가 사용자당 관측되는 평점의 평균 수(the average number of ratings per user)보다 훨씬 높기 때문이다.
- 사용자간 평가한 평점의 수의 편차가 크기 때문에 U-AutoRec은 상대적으로 I-AutoRec보다 신뢰성이 떨어진다.

I-AutoRec은 모든 RBM model보다 성능이 우수하다.

## ⅱ. How does AutoRec performance vary with linear and nonlinear activation functions

![](3.jpg)
_RMSE for I-AutoRec with choices of linear and nonlinear activation functions, Movielens 1M dataset_

위의 표는 $g$를 통해 비선형 hidden layer를 사용하는 것은 I-AutoRec의 좋은 성능에 필수적이라고 말한다. 그리고 MF보다 잠재적인 장점이 있다는 것을 나타낸다.  
Sigmoid 대신 ReLU(Rectied Linear Units)를 사용하면 성능이 낮아진다. 다른 모든 AutoRec 실험에서 항등 함수 $f$와 sigmoid 함수 $g$를 사용한다.

## ⅲ. How does performance of AutoRec vary with the number of hidden units?

![](4.jpg)
_Figure 2: RMSE of I-AutoRec on Movielens 1M as the number of hidden units k varies._

위의 그림은 hidden unit의 개수에 따른 AutoRec의 성능을 평가한 것이다. AutoRec의 성능은 unit의 수에 따라 꾸준히 증가하지만, 향상되는 폭(returns)은 감소한다.
- 다른 모든 AutoRec 실험에서 $k = 500$으로 설정한다.

## ⅳ. How does AutoRec perform against all baselines?

![](5.jpg)
_Comparison of I-AutoRec with baselines on MovieLens and Netflix datasets_

AutoRec의 성능은 Movielens 10M에 대한 LLORMA 성능을 제외하고, 당시 basline으로 사용되던 model들의 성능보다 우수하다.  
LLORMA과의 성능 비교는 흥미로움을 준다.
- LLORMA는 50개의 다른 local matrix factorization models을 학습(weighting)하는 것을 포함한다.
- AutoRec은 NN autoencoder를 활용한 하나의 latent representation을 사용한다. 즉 AutoRec이 더 빠르다.

## ⅴ. Do deep extensions of AutoRec help?

각 500, 250, 500 unit을 가지고 활성함수로 sigmoid를 가지는 3개의 hidden layer 구조로 I-AutoRec의 deep version을 개발했다.  
Deep version AutoRec을 greedy한 사전학습과 gradient descent로 fine-tuned을 했을 때, Movielens 1M에 대해 RMSE가 0.831에서 0.827로 감소했다.  
이것은 deep AutoRec을 통한 성능 향상이 있을 것으로 기대된다.  

# References

1. [Dive into DL - 16.4. AutoRec: Rating Prediction with Autoencoders](https://d2l.ai/chapter_recommender-systems/autorec.html){:target="_blank"}
2. [Wiki - plate notation](https://en.wikipedia.org/wiki/Plate_notation){:target="_blank"}
3. [Embeddings에 대한 이해 -1 \| 이미지 기반 유사도, 텍스트 기반 유사도에 대해](https://simonezz.tistory.com/43){:target="_blank"}
4. [YouTube - PyTorch Autograd Explained - In-depth Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE){:target="_blank"}

[1]: https://dl.acm.org/doi/abs/10.1145/2740908.2742726
[2]: https://github.com/c0natus/Paper-review-implements/tree/main/RecSys/AutoRec