---
title: "Collaborative Metric Learning, (WWW'17)"
categories: [Paper, RecSys]
tags: [Metric Learning, Matrix Factorization, Collaborative Filtering]
img_path: /assets/img/posts/paper/recsys/cml/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|

# Abstract

Metric learning은 data간 관계를 capture하는 distance metrics를 제공한다.
본 논문에서는 users의 선호도뿐만 아니라 user-user, item-item similarity를 encode하는 joint metric space를 학습하는 Collaborative Metric Learning (CML)을 제안한다.
CML은 metric learning과 collaborative filtering (CF)을 활용한 model이다.

# 1. Introduction

본 논문은 inner product가 triangle inequality property를 만족하지 못한다는 점을 지적한다.
Triangle inequality가 왜 중요할까? 
아래 그림을 통해 살펴보자.

![](triangle_inequality.jpg){: w="500"}
_Figure 1: Example latent vector assignments for matrix factorization_

Matrix factorization (MF)는 prediction을 inner product로 진행한다.
User group $U_1$이 item $v_1$를 좋아하고 $U_2$가 $v_2$를 좋아하고 $U_3$이 둘 다 좋아한다고 했을 때, (무조건은 아니지만) MF를 사용하면 embedding이 Fig. 1과 같이 될 수 있다.
- $U_1 \cdot v_1 = 2, U_2 \cdot v_2 = 2, U_3 \cdot v_1 = U_3 \cdot v_2 = 2$
- $v_1 \cdot v_2 = 0$

중요한 점은 $U_3$이 $v_1, v_2$를 모두 좋아하지만, $v_1, v_2$의 inner product 값이 0이라는 것이다.
이는 <span class="text-color-blue">triangle inequality property를 위반하기 때문에 생기는 문제</span>이다.

> 그림을 보면 triangle inequailty를 만족하는 것처럼 보인다.
> 이는 distance를 euclidean으로 보고 있기 때문이다.
> 맞는 건지 모르겠지만, inner product를 distance로 생각해보자. 
> $d(U_3, v_1) = 2, d(v_1, v_2) = 0, d(U_3, v_2) = 1.95$라고 하면,
> $d(U_3, v_1) > d(v_1, v_2) + d(U_3, v_2)$이므로 triangle inequality를 만족하지 못 한다.

그렇다면 왜 inner product는 triangle inequality를 위반하게 될까?
그 이유 중 하나로 저자들은 inner product가 positive 관계인 $(U_3, v_1)$과 $(U_3, v_2)$ 정보가 $(v_1, v_2)$로 전파되지 않기 때문이라고 한다.
이로 인해, user의 일반적인 선호도는 capture할 수 있지만 정밀한 (finer grained) 선호도를 capture할 수 없게 된다.
그리고 user-user 및 item-item 관계를 stable하게 결정할 수 없게 된다.

> 일반적인 선호도는 $v_1$을 좋아한다는 것과 $v_2$를 좋아한다는 것을 의미한다.  
> 정밀한 선호도는 $v_1, v_2$를 동시에 좋아하니 $v_1, v_2$의 distance가 다른 item보다 가깝다는 것을 의미한다.  
> LightGCN 등에서 graph로 high-order relation을 파악함으로써 얻게 되는 효과와 비슷한 것 같다.

Metric learning은 비슷한 pair는 작은 distance를 가지고, 다른 pair는 큰 distance를 가지도록하는 distance metric을 제공하는 알고리즘이다.
수학적으로 metric은 몇 가지 conditions을 만족해야 하는데, 그 중 triangle inequality는 metric의 일반화에 가장 중요한 property이다.
"$x$가 $y, z$와 유사하다"라는 정보가 주어졌을 때, 학습된 metric은 $d(x, y), d(x,z)$뿐만 아니라 $d(y, z)$도 작게 만들 것이다. 이를 *similarity propagation*이라고 한다.

따라서 논문에서는 이러한 similarity propagation을 위해 metric learning을 활용한 CML을 제안한다.

# 2. Background

## 2.1. Metric Learning for kNN

Dataset을 $\mathcal{X} = $ { $x_1, \cdots, x_n$ } $, x \in \mathbb{R}^m$라 하고, similar pair를 $\mathcal{S}$, dissimilar pair를 $\mathcal{D}$라 하자.

$$
\begin{split}
  \mathcal{S} &= \{ (x_i, x_j)|x_i \text{ and } x_j \text{ are considered similar} \}\\
  \mathcal{D} &= \{ (x_i, x_j)|x_i \text{ and } x_j \text{ are considered dissimilar} \}
\end{split}
$$

Metric을 만드는 방법은 여러 가지가 있다.
가장 일반적인 metric learning은 Mahalanobis distance metric을 학습하는 것이다.

$$
d_A(x_i, x_j) = \sqrt{(x_i - x_j)^{\top}A(x_i - x_j)}, \ \ A \in \mathbb{R}^{m \times m}
$$

그리고 가장 일반적으로 objective는 아래의 convex optimiazation 문제를 global하게 푸는 것이다.

$$
\begin{split}
    &\underset{A}{\text{min }}\sum_{(x_i, x_j) \in \mathcal{S}}d_A(x_i, x_j)^2\\
    &\text{s.t. } \sum_{(x_i, x_j) \in \mathcal{D}}d_A(x_i, x_j)^2 \geq 1 \text{ and } A \succeq 0
\end{split}
$$

하지만 이는 대개 unfeasible하다.

Weinberger et al.은 학습된 metric을 k-nearest neighbor classification에 사용할 거면, 모든 비슷한 object를 cluster하는 것 대신 각 object의 k-nearest neighbors가 같은 label을 가지도록 metric을 학습하는 것만으로도 충분하는 것을 보여주었다. 

> 쉽게 말해서, 수식처럼 모든 것을 완벽히 clustering하는 것 대신
> k개의 nearest neighbors가 같은 label을 가져도 충분하다는 것이다.

따라서 본 논문에서는 이를 사용해 각 user에게 추천하기 위한 kNN items (*target neighbors*)를 찾는 것을 목표로 한다.

![](imposter.jpg)
_Figure 2: An illustration of collaborative metric learning. The hinge loss defined in Eq. 1 creates a gradient that pulls positive items closer to the user and pushes the intruding impostor items (i.e., items that the user did not like) away until they are beyond the safety margin._

다시 말해, $x$의 target neighbors들이 만드는 경계(perimeter)에 침입한 다른 label (*imposter*)의 수를 줄이도록 metric을 학습시킨다.

가장 잘 알려진 model 중 하나가 large margin nearest neighbor (LMNN)이다.
해당 model은 target neighbors는 당기고 (*pull loss*) impostor는 밀어내는 (*push loss*) 두 가지 loss term을 사용한다.

$$
\begin{split}
  \mathcal{L}_{pull}(d) &= \sum_{j \rightsquigarrow i}d(x_i, x_j)^2\\
  \mathcal{L}_{push}(d) &= \sum_{j \rightsquigarrow i}\sum_k (1-y_{ik})[1 + d(x_i, x_j)^2 - d(x_i, x_k)^2]_+\\
  &\text{where } j \rightsquigarrow i \text{ denotes that the input } j \text{ is input } i\text{'s target neighbor}
\end{split}
$$

LMNN은 pull, push loss의 weighted combination을 최종 loss function으로 사용한다.

## 2.2. Implicit Feedback

가장 유명한 CF 방법은 MF이다.
MF는 원래 users의 explicit feedback (ratings)을 model하도록 design되었다.

$$
\underset{\mathbf{u}_*, \mathbf{v}_*}{\text{min }} \sum_{r_{ij}\in\mathcal{K}}(r_{ij} - \mathbf{u}_i^{\top}\mathbf{v}_j)^2 + \lambda_u||\mathbf{u}_i||^2 + \lambda_v||\mathbf{v}_i||^2
$$

Explicit feedback 외에도 클릭, 북마크 등 users의 선호도를 예측하는데 활용할 수 있는 implicit feedback이 있다.
Implicit feedback은 explicit feedback보다 data가 풍부하고 덜 bias되어 있어 많이 연구되고 있다.
하지만, <span class="text-color-blue">implicit feedback을 기존의 MF에 바로 적용시킬 수 없는데 2가지 이유</span>가 있다.
1. 오직 positive feedback만 얻을 수 있다. 관찰되지 않은 user-item interactions을 무시할 수 없다. 만약 무시하면, 모든 latent vector가 한 점을 가리키는 (모두 1로 예측) trivial solution이 될 수 있다.
2. 관찰되지 않은 data를 negative feedback으로 판단할 수 없다. User가 정말 싫어하는 것인지 아니면 인식하지 못했는 지 알 수 없다.

이를 해결하기 위해 Hu te al.과 Pan et al.은 weighted regularized matrix factorization (WRMF)를 제안한다.
관찰되지 않은 모든 user-item interactions을 negative samples로 보는 대신 그것의 영향을 줄이기 위해 case weight $c_{i, j}$를 사용한다.

$$
\underset{\mathbf{u}_*, \mathbf{v}_*}{\text{min }} \sum_{r_{ij}\in\mathcal{K}}c_{ij}(r_{ij} - \mathbf{u}_i^{\top}\mathbf{v}_j)^2 + \lambda_u||\mathbf{u}_i||^2 + \lambda_v||\mathbf{v}_i||^2
$$

이처럼 implicit feedback을 사용하면 rating을 정확히 예측하는 것은 중요하지 않다.
그래서 item에 대한 상대적인 선호도를 model하는 쪽으로 연구가 활발히 진행되고 있는데, Bayesian personalized ranking (BPR)는 그 중 가장 잘 알려진 방법이다.
BPR에도 한 가지 문제가 있는데, low rank인 item에 충분한 penalty를 주지 못한다는 점이다.

> Low rank item은 rank가 낮게 측정되는 positive item item이다.
> 즉, 높은 rank를 가지는 positive item은 penalty를 주지 않아도 되지만,
> 낮은 rank를 가지는 postivie item은 penalty를 많이 줘야 한다.  
> 이러면 noise에 민감할 것 같다. 예로 들어, 실수로 클릭한 item에 높은 rank를 줄 수 있을 것 같다.

이를 개선하는 방법 중 가장 유명한 것은 *weighted ranking loss*이다.
Weighted ranking loss에 대해선 후반부에서 더 살펴보자.

# 3. Collaborative Metric Learning

## 3.1. Model Formulation

CML은 section 2에 있는 방법들을 활용해 metric을 학습한다.

먼저 distance로는 euclidean distance를 사용한다.

$$
d(i,j) = ||\mathbf{u}_i - \mathbf{v}_j||_2
$$

그리고 metric learning을 사용하는데, low rank item에 penalty를 주기 위해 ranking loss weight $w_{ij}$를 사용한다.

$$
\begin{equation}
  \mathcal{L}_m(d) = \sum_{(i,j)\in\mathcal{S}}\sum_{(i,k)\notin\mathcal{S}} w_{i,j}[m + d(i,j)^2 - d(i,k)^2]_+
\end{equation}
$$

- $m>0$은 margin size이다.

위에서 살펴봤던 LMNN과 3가지 다른 점이 있다.

1. User에 관한 target neighbor만 있고 item을 위한 target neighbor는 없다.
2. 한 item을 많은 user가 좋아할 수 있고, 그 item을 많은 users와 가깞게 만드는 것은 unfeasible하기 때문에 pull loss는 없다.
3. Weighted ranking loss를 사용한다.

저자들은 Weston et al.이 제안한 Weighted Approximate-Rank Pairwise (WARP) loss를 사용한다.
Item의 총 개수를 $J$ metric $d$에서 user $i$에 대한 item $j$의 rank를 $rank_d(i,j)$라 하자.
Rank가 높을수록 $rank_d$ 값은 0에 가까워진다.
그러면 다음 식을 통해 positive item $j$를 rank에 기반해 penalize한다.

$$
w_{ij} = \text{log }(rank_d(i,j)+1)
$$

$rank_d$를 구하는 것은 expensive하기 때문에 Weston et al.은 $rank_d$를 추정하는 방법인 sequential sampling procedure를 제안한다. 
Imposter를 찾기 위해 negative를 sample한 횟수를 $N$이라고 하자.
$rank_d(i,j) \approx \lfloor\frac{J}{N}\rfloor$이다.
즉, item $j$가 user $i$와 가깝게 있으면 $j$의 rank가 높다는 전제 하에, non-zero인 Eq. 1을 찾아야 한다.
$j$가 $i$와 멀리 있으면 imposter를 찾기 위해 sample을 적게 하므로 $w_{ij}$ 값이 커진다.
그 결과 해당 item의 loss가 상대적으로 커지게 되면서 embedding 값이 많이 변하게 된다.
논문에서는 GPU의 병렬 처리를 활용하기 위해 변형된 WARP $rank_d(i,j) \approx \lfloor\frac{J \times M}{U}\rfloor$를 사용한다.

## 3.2. Integrating Item Features

![](transformation_function.jpg)
_Figure 3: A learnable transformation function $f$ is used to project item features (e.g., image pixels) into the user-item joint space. The projections are treated as a Gaussian prior for items’ locations._

$\mathbf{x}_j \in \mathbb{R}^m$을 item $j$의 raw feature vector라고 하자.
$f$는 $\mathbf{x}_j$를 joint user-item space $\mathbb{R}^r$에 project하는 것이다.
Projection $f(\mathbf{x}_j)$는 item $j$의 특성을 어느 정도 가져야 한다.
그래서 $f(\mathbf{x}_j)$를 $\mathbf{v}_j$의 Gaussian prior로 설정해 $\mathbf{v}_j$가 $f(\mathbf{x}_j)$를 많이 벗어나지 않도록 한다.

$$
\mathcal{L}_f(\theta, \mathbf{v}_*)=\sum_j ||f(\mathbf{x}_j, \theta) - \mathbf{v}_j||^2
$$

- $f$는 multi-layer perceptron (MLP) with dropout을 사용한다.
- $\theta$는 function $f$의 학습 가능한 parameter이다.

$\mathbf{v}_*$를 통해 $f$는 user의 선호도와 관련된 feature를 선택하도록 학습된다.
$f$를 통해 비슷한 feature를 가지는 items가 cluster를 형성하도록 학습된다.
그 결과, rating이 적은 item에 대한 metric accuracy가 향상된다.

> Item의 feature(*e.g.* category, price, ...)를 projection한 것이 item embedding과 가까운 것을 의미한다.
> Item-item similarity를 더 강화해주는 것 같다.

## 3.3. Regularization

CML에서 적절한 regularization이 중요하다.

**1. Bound all the user/item within a unit sphere**

$$
||\mathbf{u}_*||^2 \leq 1 \text{ and } ||\mathbf{v}_*||^2 \leq 1
$$

High-dimensional space에서 data points가 널리 퍼져있으면 비효율적이다.
따라서 학습된 metric의 robustness를 보장하기 위해 vector 크기가 1이하가 되도록한다.
$L^2$ regularization은 모든 object를 origin으로 향하도록 gradient가 만들어진다.
CML의 metric space에서 origin는 어떤 특별한 의미가 없기 때문에 $L^2$ 정규화는 CML에 적합하지 않다.


**2. Covariance Regularization**

$$
\begin{split}
  C_{ij} &= \frac{1}{N}\sum_n(y^n_i - \mu_i)(y_j^n - \mu_j)\\
  \mathcal{L}_c &= \frac{1}{N}(||C||_f - ||\text{diag}(C)||^2_2)
\end{split}
$$

- $\mathbf{y}^n$: object's latent vector, $n$ indexes the object in a batch of size N.
- $\mu_i = \frac{1}{N}\sum_ny^n_i$
- $\|\| \cdot \|\|_f$: Frobenius norm

Covariance regularization은 deep neural network에서 2개 이상의 hidden unit 사이의 correlation을 줄이기 위해 Cogswell et al.이 제안한 방법이다.
CML에서 학습된 metric의 dimension을 de-correlating하는 것이 유용하다는 사실을 저자들이 발견했다.
Covariances는 dimension 사이의 linear redundancy의 척도로 볼 수 있다.
따라서 각 dimension이 중복 (redundant)되는 것을 방지해 주어진 공간을 좀 더 효율적으로 사용할 수 있게 한다.

> Disentanglement를 높인다고 볼 수 있다.

## 3.4. Training Procedure

$$
\begin{split}
    &\underset{\theta, \mathbf{u}_*, \mathbf{v}_*}{\text{min }}
      \mathcal{L}_m + \lambda_f\mathcal{L}_f + \lambda_c\mathcal{L}_c \\
    &\text{s.t. } ||\mathbf{u}_*||^2 \leq 1 \text{ and } ||\mathbf{v}_*||^2 \leq 1
\end{split}
$$

- $\lambda_f, \lambda_c$: hyper-parameters

자세한 것은 논문 참고.

[1]: https://dl.acm.org/doi/pdf/10.1145/3038912.3052639
