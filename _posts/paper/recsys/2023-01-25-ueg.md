---
title: "User-Event Graph Embedding Learning for Context-Aware Recommendation, (KDD'22)"
categories: [Paper, RecSys]
tags: [CARS, GNN]
img_path: /assets/img/posts/paper/recsys/ueg/
author: gshan
math: true
---

|[Paper Link][1]{:target="_blank"}|[Official Github][2]{:target="_blank"}|

# Abstract

대부분의 context-aware 추천 시스템 (CARS)는 feature interaction에만 집중하고 embedding layer를 간과한다. [FM][3]{:target="_blank"} 등 기존의 CARS는 feature interaction에만 관심이 있고 features의 embedding은 random하게 초기화 한다.

> MF에서 CF signal을 반영해 user, item embedding을 더 좋게하는 NGCF가 나왔듯, FM에서 CF signal을 반영해 더 좋은 user, item context feature embedding을 얻기 위해 UEG-EL가 나온 것 같다.

하지만 random하게 초기화된 embedding layer는 user (또는 item)과 context의 interaction의 sparsity뿐만 아니라 contextual feature의 sparsity으로 인해 학습을 어렵게 만든다.
따라서 본 논문에서는 이러한 <span class="text-color-yellow">두 가지 sparsity를 해결하기 위해 user-event graph embedding learning (UEG-EL) framework를 제안</span>한다.

UEG-EL은 3가지 modules로 이뤄져 있다.
- **Graph construction module.** Users, (user) intents, items로 이뤄진 user-event graph를 생성한다.
- **User-event collaborative graph convolution module.** 모든 feature (user, intents, items)의 정제된 embeddings를 얻는다.
- **Recommendation module.** Feature embedding을 정제된 embedding으로 직접 초기화 하는 기존의 CARS model을 통합하기 위한 module이다.

Basic framework (UEG-EL)는 noise에 민감하다.
그래서 저자들은 간단하지만 효과적인 UEG-EL-V framework를 제안한다.
UEG-EL-V는 contextual features의 propagation을 제거한다.

# Ⅰ. Introduction

Contextual information은 embedding vectors의 latent space로부터 explicit하게 관찰되거나 implicit하게 추론될 수 있다. 
그리고 그것들은 추천 task에서 pre-filtering, post-filtering, 또는 modeling stages에 사용될 수 있다.
대부분의 CARS는 modeling stage에 집중되어 있으며, 채택된 model architecture에 따라 두 가지 line으로 분류할 수 있다.
1. Machine learning 방법을 기반으로 하는 multidimensional settings으로 추천 task를 확장한다.
2. Neural network 구조를 기반으로 higher-order 그리고 nonlinear relationships을 modeling한다. 

기존의 CARS 방법이 좋은 결과를 내었지만, 대부분이 embedding layer를 간과한 채 feature interaction layer를 개선하는 데만 초점을 두고 있다.
Embedding layer를 random하게 초기화하면 user (또는 item)과 context의 interaction의 sparsity뿐만 아니라 contextual feature의 sparsity으로 인해 어려움을 겪는다.
즉, CARS는 contextual features에 가장 많이 의존하는데 현업에서는 수많은 sparse contextual features가 있다. 이는 Fig 1에서 확인할 수 있다.

![](1.jpg)
_Figure 1: The distributions of the number of contextual features associated with each user (left column) and item (middle column), as well as the frequency statistics of the contextual features (right column), on Yelp-NC (top row), Yelp-OH (middle row) and Amazon-Book (bottom row)._

Fig. 1은 본 논문의 experiments에서 쓰인 3개의 dataset에 대해 user, item과 연관된 contextual features의 수와 contextual features의 도수 분포 (frequency distribution)을 시각화한 것이다.

> 해석  
> x축은 각 users, items과 연관된 contextual features의 수, contextual features가 사용된 개수이다.  
> 즉, 대부분의 user는 20 ~ 30개의, item은 10 ~ 20개의 contextual feature와 연관되어 있고, 대부분의 contextual features는 적게 사용되었다.

Fig. 1의 3 번째 column을 살펴보면, 대부분의 contextual features가 low fequency를 가지는 것을 알 수 있다.
이는 기존의 방법들을 사용했을 때 <span class="text-color-yellow">불충분한 training exmaples로 좋은 contextual feature의 embedding을 학습하기 어렵다는 것을 의미</span>한다.
저자들은 이를 **feature sparsity**라고 부른다.

Fig. 1의 1, 2 번째 column을 살펴보면, 각 user (또는 item)과 연관된 feature의 수를 나타내는 분포가 long-tailed 형태를 띠는 것을 확인할 수 있다.
이로 인해, 기존 방식에서 <span class="text-color-yellow">inactive users 또는 unpopular items의 contextual features에 대한 선호도 정보 부족으로 성능 병목 현상이 발생</span>할 수 있다.
저자들은 이를 **interaction sparsity**라고 부른다.

본 논문은 추천 시스템 data의 sparsity에 효과적인 graph representation을 활용한 UEG-EL framework를 제안한다.

먼저, user, item nodes 이외에 user-intent nodes가 추가된 user-event graph를 만든다. 
Contextual features를 사용해 저자들이 제안한 intent-node attention (INA)로 user-intent nodes를 구성한다.
이러한 intent nodes는 users, items, contextual features간의 복잡한 interactions으로 graph를 만드는 과정에서 hub 역할을 한다.

그 다음으로, user-event graph를 활용해 users, items, contextual features의 정제된 embeddings를 얻기 위해 user-event collaborative graph convolution (CGC)을 제안한다.
해당 방법은 intent nodes를 통해 information propagation을 진행한다.
이는 위에서 언급한 두 가지의 sparsity를 가진 dataset에서 users, items, contextual features가 더 많은 synergistic 정보를 얻어 더 나은 embedding을 가지게 해준다.

마지막으로, 모든 features의 정제된 embeddings와 기존의 CARS model을 사용해 prediction을 진행한다.

UEG-EL는 한 가지 문제를 가진다.
바로 관련된 instances가 많은 context features가 noise에 민감하다는 것이다.
본 논문에서는 이를 완화하기 위해 UEG-EL-V framework를 제안한다.

# Ⅱ. Related Work

자세한 내용은 논문을 참고하자.
대부분의 내용이 introduction에서 언급한 것이다.

[GCM][4]과 유사하지만 2가지 차이점이 있다.
1. 본 논문에서는 서로 다른 features를 더 잘 연결하기 위해 intent nodes를 만든다.
2. GCM은 contextual features를 정제하지 않지만, UEG-EL는 contextual features를 포함한 모든 features를 graph embedding learning으로 정제한다.

# Ⅲ. Preliminaries

## ⅰ. Problem Definition

해당 subsection에선 notation을 살펴보자.

CARS에서 dataset은 대부분 $M$명의 user, $N$개의 items, timestamps와 locations 같은 $R$ fields contextual features, $J$ fields user attributes, $K$ field item attributes로 이뤄져있다.
이들의 notation은 순서대로 아래와 같다.

$$
\begin{split}
    \mathcal{U} &= \{ u_1, \cdots, u_M \}\\
    \mathcal{V} &= \{ v_1, \cdots, v_N \}\\
    \mathcal{C} &= \{ \mathcal{C}^1, \cdots, \mathcal{C}^R \}\\
    \mathcal{A} &= \{ \mathcal{A}^1, \cdots, \mathcal{A}^J \}\\
    \mathcal{B} &= \{ \mathcal{B}^1, \cdots, \mathcal{B}^K \}
\end{split}
$$

$\mathcal{S} =$ { $(s_1, y_1), \cdots, (s_I, y_I)$ }를 $I$개의 user-item interactions와 그것들과 대응하는 labels의 집합이라고 하자.
$\mathcal{S}$의 한 instance는 다음과 같이 표현된다.

$$
\begin{equation}
  \mathbf{s}_i = [u^i, v^i, \mathbf{A}_{u^i}, \mathbf{B}_{v^i}, \mathbf{C}^i]
\end{equation}
$$

- $u^i \in \mathcal{U}$: $i$ 번째 instance에 포함된 user
- $v^i \in \mathcal{V}$: $i$ 번째 instance에 포함된 item
- $\mathbf{C}^i \subset \mathcal{C}$: $i$ 번째 instance에 context
- $\mathbf{A}_{u^i} \subset \mathcal{A}$: $u^i$와 연관된 attribute list
- $\mathbf{B}_{v^i} \subset \mathcal{B}$: $v^i$와 연관된 attribute list

이러한 정보는 보통 one-hot 또는 multi-hot vector로 encode된다. 
Item ID, item attributes, contextual information을 예로 들면 아래와 같다.

$$
\begin{equation}
  \underbrace{[0,0, \dots, 1, 0]}_{v: \text{Item ID}},\ \ \ \
  \underbrace{[1,1, \dots, 0, 0]}_{\mathbf{B}_v: \text{Brand & Price}},
  \underbrace{[1,1, \dots, 1, 0]}_{\mathbf{C}: \text{Year & Month & Day}}
\end{equation}
$$

CARS의 목표는 context $\mathbf{C}$ 상황 아래에서 user $u$가 interaction할 확률이 가장 높은 item $i$를 예측하는 것이다.
이때, context $\mathbf{C}$의 통합이 중요하기 때문에 위에서 언급한 context $\mathbf{C}$관한 2가지 sparsity chanllenge를 해결해야 한다.

## ⅱ. Base Model

FM의 효과와 효율성으로 CARS에서 중요한 역할은 한다.
본 논문에서도 정제된 embeddings를 얻은 후에 prediction하는 downstream recommendation model로서 FM을 UEG-EL과 결합한다.

**Initial Embedding.** 
먼저 sparse high-dimensional binary form인 instance $\mathbf{s}_i$를 dense low-dimensional real valued form으로 압축한다.
- One-hot vector (user/item ID embeddings)에서는 하나의 embedding representation vector를 얻는다.
- Multi-hot vector (user/item attribute, contextual information embeddings)에서는 embedding representation ectors의 list를 얻는다.

본 논문에서는 user 또는 item의 잘 세분화된 feature를 탐색하는 것보단, graph embedding learning을 활용해 users, items, contextual features 사이의 복잡한 interactions을 더 잘 modeling하고 representation을 정제하는 것에 더 초점을 맞추고 있다.

> 해석  
> user/item attribute를 사용해 더 좋은 user/item embeddings를 얻어 latent space에서 서로 구분이 될 수 있게 만드는 것보단 users, items, contextual features간 interaction에 더 많은 관심이 있다.
> 따라서 user/item attribute는 단순히 average pooling한다.

따라서 user, item의 모든 features의 embeddings를 단순히 average pooling으로 통합한다.
마지막으로 concatenate하여 한 instance에 대한 representation을 얻는다.

$$
\begin{equation}
  \begin{split}
    &\mathbf{E}_{\mathbf{s}_i} = [\mathbf{e}'_{u^i}, \mathbf{e}'_{v^i}, \mathbf{e}'_{\mathbf{C}^i}]\\
    \text{where } &\mathbf{e}'_{u^i} = average\_pooling([\mathbf{e}_{u^i}, \mathbf{e}_{A_{u^i}}])\\
    &\mathbf{e}'_{v^i} = average\_pooling([\mathbf{e}_{v^i}, \mathbf{e}_{B_{v^i}}])\\
  \end{split}
\end{equation}
$$

**Feature Interaction.**
정제된 하나의 instance의 embedding representation을 얻은 후, feature interaction layer를 통해 user의 선호도를 예측해야 한다.
본 논문에서는 FM의 구조를 활용한다.

$$
\begin{equation}
  \hat{y}(\mathbf{s}_i) 
    = \sigma\big(
      b_g 
      + \sum b_{\star} 
      + \frac{1}{2}[(\sum \mathbf{e}_{\star})^2 - \sum \mathbf{e}_{\star}^{\top}\mathbf{e}_{\star}]
    \big)
\end{equation}
$$

- $\star \in $ { $u^i, v^i, \mathbf{C}^i$ }
- $b_g$: global bias
- $b_{\star}$: feature bias
- $\sigma(\cdot)$: sigmoid activation function

**Model Training**
Objective function으로 point-wise log loss를 사용한다.

$$
\begin{equation}
  \mathcal{L} = -\frac{1}{|\mathcal{S}'|}
    \sum_{(\mathbf{s}_i, y) \in \mathcal{S}'}
    y_i \text{log}\hat{y}(\mathbf{s}_i)
    + (1 - y_i) \text{log}(1 - \hat{y}(\mathbf{s}_i))
\end{equation}
$$

- $\mathcal{S}' = \mathcal{S} \cup \mathcal{S}^-$
- $\mathcal{S}^-$는 random하게 선택된 negative instances의 집합이다.

# Ⅳ. User-Event Graph Embedding Learning

![](2.jpg)
_Figure 2: The architecture of the user-event graph embedding learning (UEG-EL) framework consists of three modules: 1) the graph construction module is used to construct the user-event graph, where intent node attention (INA) is used to obtain the required intent nodes from the original personal graph; 2) the user-event collaborative graph convolution module is used to learn the refined embeddings of the users, items and contextual features; and 3) the recommendation module receives the refined feature embeddings to improve the performance of a downstream recommendation model. Note that the length of the context list is assumed to be 3._

UEG-EL은 위 그림과 같이 3가지 module로 구성되어 있다.

## ⅰ. Graph Construction

**Personal Graph.**
본 논문과 가장 관련있는 [GCM][4]에서 채택한 graph 구조는 Fig 2의 personal graph $\mathcal{G}_{pg}$와 같다고 볼 수 있다.

$$
\begin{split}
  \mathcal{G}_{pg} &= <\mathcal{V}_{pg}, \mathcal{E}_{pg}>\\
  \text{where }
    \mathcal{V}_{pg} &= \{u\} \cup \mathbf{A}_u \cup \mathcal{V} \cup \mathcal{B}\\
    \mathcal{E}_{pg} &= \mathbf{E}_{ua} \cup \mathcal{E}_{vb} \cup \mathcal{E}_{uv} \cup \mathcal{E}_{vv}
\end{split}
$$
 
- $\mathcal{V}_{pg}$: personal vertex
  - User ID ($u$), user attributes ($\mathbf{A}_u$), interacted items ($\mathcal{V}$), their corresponding attributes ($\mathcal{B}$).
- $\mathcal{E}_{pg}$: personal edge
  - User-item interactions, temporal relationships.

기존의 user-item bipartite graph와 다르게, contextual features list가 한 edge의 features로 사용된다.

**User-Event Graph.** 
Contextual features가 edge의 features로 사용되는 것에는 2가지 한계점이 있다.
User, items와 같이 graph embedding learning의 information propagation process를 활용할 수 없다.
그리고 정확한 user의 intent를 파악하기 어렵다.
다시 말해, 현재 contextual information으로부터 어떤 contextual features가 user의 interaction event가 일어나도록 만들었는지 식별하기 어렵다.

위의 2가지 문제를 해결하기 위해, 본 논문에서는 CARS를 위한 user-event graph (UEG) 라는 새로운 graph structure를 제안한다.
UEG를 구성하기 위해 추가적으로 필요한 intent node를 intent node attention (INA) 방법으로 생성한다.
INA도 저자들이 제안한 방법론이다.

한 instance (Eq. 1)의 contextual features list는 $\mathbf{C}^i = $ { $c^i_1, \cdots, c^i_Z$ }로 표기된다.
$Z$는 각 instance에 해당 하는 contextual features의 length이다.
User의 행동은 context뿐만 아니라 이전의 행동에도 영향을 받는다.
따라서 저자들은 가장 최근에 interaction한 item을 $c^i_{Z+1}$로 표기하여 contextual information에 포함시킨다.
한 instance의 INA는 다음과 같다.

$$
\begin{align}
  \alpha^i_z &= \text{Softmax}(
    \mathbf{W}_0^{\top}\text{Relu}(
      \mathbf{W}_1\mathbf{e}'_{u^i}
      + \mathbf{W}_2\mathbf{e}_{c^i_z}
      + \mathbf{b}_1
    )
  )\\
  \mathbf{e}_{t^i} &= \sum_{z=1}^{Z+1}\alpha_z^i\mathbf{e}_{c^i_z}
\end{align}
$$

- $\mathbf{W}_0 \in \mathbb{R}^{d \times 1}$, $\mathbf{W}_1, \mathbf{W}_2 \in \mathbb{R}^{d \times d}$, $\mathbf{b}_1 \in \mathbb{R}^{d \times 1}$은 학습 parameters이고 $d$는 embedding size이다. 
- $\mathbf{e}_{t^i}$는 instance에 해당하는 intent node의 embedding representation이다.

INA로 얻은 intent nodes로 user-event graph $\mathcal{G}_{ueg}$를 만들 수 있다.

$$
\mathcal{G}_{ueg} = <\mathcal{U} \cup \mathcal{V} \cup \mathcal{T}, \mathcal{E}_{ut} \cup \mathcal{E}_{vt}>
$$

Intent node는 서로 다른 contextual features에 대해 더 나은 user의 선호도를 알기 위해 explicit하게 user의 intent를 modeling한다.
그리고 users와 items를 연결하는 hub로써 users, items, contextual features간 복잡한 interactions을 modeling하는 데 도움을 준다.

**Intent-Context Graph**
Graph embedding learning으로 information을 contextual feature에 propagate하기 위한 intent-context graph $\mathcal{G}_{icg}$가 존재한다.

$$
\mathcal{G}_{icg} = <\mathcal{C} \cup \mathcal{T}, \mathcal{E}_{ct}>
$$

각 intent node는 INA로 $Z$개의 contextual features를 가지고 생성된다.
이때, intent node와 contextual feature를 연결한 각 edge는 intent attention ($\alpha^i_z$)을 weight로 가진다.
즉, 큰 weight를 가지면 propagate된 information을 더 많이 반영한다.

## ⅱ. User-Event Collaborative Graph Convolution

Intent node의 존재로 기존의 graph embedding learning 방법을 사용할 수 없다.
따라서 해당 subsection에서 user-event graph를 활용하기 위한 user-event collaborative graph convolution (CGC)을 소개한다. 새로 제안된 graph convolution는 users, items, contextual features간 연결을 탐색하고, context features에서 집중된(focused) users의 subset을 식별하는데 중요한 역할인 intent nodes을 충분히 활용하는 것을 목표로 한다.

> 의문점  
> 집중된 users의 subset이라는 게 특정 context feature에 영향을 많이 받는 users 즉, 그 context feature의 intent attention이 높은 users의 subset을 식별한다는 의미인가...?  
> 아니면 user가 집중을 많이 하는 contextual features의 subset이라는 것인가...?

이렇게 context features가 전달된 information으로 정제된 후, 다시 INA에 feed되어 더 정확한 intent node embedding을 얻을 수 있다. 즉, intent node 관점에서 graph construction module과 CGC module은 서로 도움을 주는 상호보완적인 관계이다.

![](3.jpg)
_Figure 3: An illustration of information propagation for the nodes of users, items and contextual features in user-event collaborative graph convolution._

User, item, context feature에 대한 information propagation은 Fig. 3에서 시각적으로 살펴볼 수 있다.

**Information Propagation for the Users.**
Fig. 3의 왼쪽 부분과 같이 intent nodes는 items, contextual features애 대한 information을 users에게 propagate하기 위한 hub로 사용된다.

$$
\begin{equation}
  \mathbf{p}_{u^i, i}^{(h)} = \mathbf{p}_{v^i}^{(h-1)} + \mathbf{p}_{t^i}^{(h-1)}
\end{equation}
$$

- $\mathbf{p}^{(h)}_{u^i, i}$는 layer $h$에서 user $u^i$에게 전달되는 $i$ 번째 instance와 관련된 information representation이다.
- $\mathbf{p}_{v^i}^{(h-1)}$는 layer $h-1$에서의 item embedding이다.
- $\mathbf{p}_{t^i}^{(h-1)}$는 layer $h-1$에서의 intent node embedding이다.

그 다음, 각 user $u$에 대해 layer $h$에서 관련된 모든 instances에 대한 information을 aggregate (average_pooling)한다.

$$
\begin{equation}
  \mathbf{p}_u^{(h)} = \frac{1}{\sqrt{|\{i|u^i=u\}|}}\sum_{i, u^i=u} \mathbf{p}^{(h)}_{u,i}
\end{equation}
$$

Eq. 9는 user $u$가 어떤 contextual feature에서 어떤 item type과 interact할 지를 포착한다.
마지막으로 user $u$에 대한 모든 layer의 embedding을 평균을 내서 최종 user embedding을 얻는다.

$$
\begin{equation}
  \hat{\mathbf{p}}_u = \frac{1}{H+1}\sum_{h=0}^H \mathbf{p}^{(h)}_u
\end{equation}
$$

**Information Propagation for the Items.**
User관점에서 information propagation하는 것과 유사하다. Fig. 3의 중앙 부분에 해당 한다.

$$
\begin{align}
  \mathbf{p}_{v^i, i}^{(h)} &= \mathbf{p}_{u^i}^{(h-1)} + \mathbf{p}_{t^i}^{(h-1)}\\
  \mathbf{p}_v^{(h)} &= \frac{1}{\sqrt{|\{i|v^i=v\}|}}\sum_{i, v^i=v} \mathbf{p}^{(h)}_{v,i}\\
  \hat{\mathbf{p}}_v &= \frac{1}{H+1}\sum_{h=0}^H \mathbf{p}^{(h)}_v
\end{align}
$$

비슷하게 eq. 12는 item $v$가 어떤 contextual feature에서 어떤 user type과 interact할 지를 포착한다.

**Information Propagation for the Context**
Fig. 3의 오른쪽 부분과 같이 user와 item information을 contextual features에 propagate하기 위해서 먼저 intent node로 user와 item의 information이 전달된다.

$$
\begin{equation}
  \mathbf{p}_{t^i, i}^{(h)} = \mathbf{p}_{u^i}^{(h-1)} + \mathbf{p}_{v^i}^{(h-1)}
\end{equation}
$$

그 다음, contextual features는 attention distribution에 따라 intent nodes로 부터 서로 다른 information을 받는다.

$$
\begin{equation}
  \mathbf{p}_{c^i_z, i}^{(h)} = \alpha_z^i\mathbf{p}_{t^i, i}^{(h)}
\end{equation}
$$

마지막으로, user, item과 유사하게 layer $h$에서 관련된 모든 instances에 대한 information을 aggregate하고, 모든 layer의 embedding을 평균을 내서 최종적으로 정제된 embedding을 얻는다.

$$
\begin{align}
  \mathbf{p}_{c_z}^{(h)} &= \frac{1}{\sqrt{|\{i|c_z^i = c_z\}|}} \sum_{i, c_z^i=d_z} \mathbf{p}_{c_z^i, i}^{(h)}\\
  \hat{\mathbf{p}}_{c_z} &= \frac{1}{H+1}\sum_{h=0}^H \mathbf{p}_{c_z}^{(h)}
\end{align}
$$

Eq. 16은 특정 contextual features와 서로 다른 users, items 사이의 유사성(affinities)를 포착한다.

이때, $\mathbf{p}_{c_z}^{(h)}$를 얻어 contextual feautre가 update되었을 때, intent node도 update되어야 한다.
그리고 이것은 다시 Eq. 8, Eq. 11에 사용된다.

$$
\begin{equation}
  \mathbf{p}_{t^i}^{(h+1)} = \sum \alpha_z^i\mathbf{p}_{c_z^i}^{(h)}
\end{equation}
$$

CGC이후 refined embeddings는 다음과 같다.

$$
\begin{equation}
  \mathbf{P}_{\mathbf{s}_i} = [\hat{\mathbf{p}}_{u^i},\hat{\mathbf{p}}_{v^i},\hat{\mathbf{p}}_{C^i}]
\end{equation}
$$

**Pruning the Information Propagation of Context.**
Contextual features가 너무 많은 instances와 연관되어 있다면, information을 aggregate하는 과정에서 noise에 민감해진다.
이에 대한 emphirical한 결과는 experiments에서 확인할 수 있다.
따라서 저자들은 context의 information propagation을 pruning하는 UEG-EL-V를 제안한다.
1. 각 context $c_z$마다 그것과 관련된 intent node embeddings의 mean vector를 구한다.
2. 해당 mean vector와 $c_z$가 포함된 모든 instances의 intent node간 거리를 구한다.
3. Pruning rate $\theta$만큼 큰 거리를 가지는 instances를 제거한다.

저자들은 각 contextual fexture가 가지는 majority한 user의 intent와 다르게 interaction한 것이 noise할 확률이 크다는 생각으로 위와 같은 pruning idea를 생각해냈다.

> 일반적인 dropout이랑 비교해봤으면 좋았을 것 같다. Training data에 맞춘 pruning이라서 overfitting되는 경향이 있지 않을까...?

## ⅲ. Complexity Analysis

Inference는 recommendation module에 쓰이는 model의 complexity와 같다.
본 논문에서는 recommendation module로 FM을 사용한다.

Training에서는 user-event collaborative graph convolution이 time cost를 가장 많이 차지한다.
따라서 computational complexity는 $\mathcal{O}(Z \cdot \| \mathcal{G}_{ueg} \| \cdot d)$이다.
- $\| \mathcal{G}_{ueg} \|$: UEG의 edge 개수.

자세한 것은 논문을 참고하자.

# Ⅴ. Empirical Evaluations

해당 section에서는 저자들의 의견을 뒷받침하는 다양한 실험이 진행된다.
자세한 것은 논문을 참고하자.

# Review

해당 논문은 novel한 graph 구조와 information propagation을 활용해, contextual feature embeddings를 refine하여 sparsity때문에 일어나는 문제를 완화시켰다.

하지만, instance마다 intent node가 필요하게 되면서 기존의 (GNN을 활용한) 추천 model보다 space complexity가 매우 높아질 것으로 예상된다. 
> Inference를 고려해서 GNN 자체에 non-linear를 반영해, recommendation module에 NFM 등을 사용하지 않고 FM만 사용해도 각 embeddings간 non-linear한 관계를 파악할 순 없을까...?

[1]: https://dl.acm.org/doi/abs/10.1145/3534678.3539458
[2]: https://github.com/dgliu/KDD22_UEG
[3]: https://c0natus.github.io/posts/fm/
[4]: https://c0natus.github.io/posts/gcm/